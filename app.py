# -*- coding: utf-8 -*-
"""
ì½”ì¸ AI ì˜ˆì¸¡ ì‹œìŠ¤í…œ - v2.2.0 (AI Prediction + Position Recommendation)
- TA-Lib ê¸°ë°˜ 61ê°œ ìº”ë“¤ìŠ¤í‹± íŒ¨í„´ ì§€ì›
- ë§¤ë„ ì‹œì  ì˜ˆì¸¡ ê¸°ëŠ¥ (ì–¸ì œ íŒ”ì•„ì•¼ í•˜ëŠ”ì§€)
- ì ì‘í˜• ì§€í‘œ ê³„ì‚°
- ì§ì ‘ ì…ë ¥ ì½”ì¸ ì§€ì›
"""

import pandas as pd
import numpy as np
import yfinance as yf
import datetime
import streamlit as st
from scipy import stats
import os
import logging
import requests
import statsmodels.api as sm
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import TimeSeriesSplit



from sklearn.metrics import brier_score_loss, log_loss
from sklearn.model_selection import TimeSeriesSplit


# ì•™ìƒë¸” ëª¨ë¸ imports
import warnings
warnings.filterwarnings('ignore')

# ë”¥ëŸ¬ë‹ ëª¨ë¸
try:
    import torch
    import torch.nn as nn
    from torch.utils.data import Dataset, DataLoader
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # ë”ë¯¸ í´ë˜ìŠ¤ ì •ì˜ (import ì˜¤ë¥˜ ë°©ì§€)
    class nn:
        class Module:
            pass
        class Linear:
            pass
        class ModuleList:
            pass
        class GRU:
            pass
        class LSTM:
            pass
    class torch:
        @staticmethod
        def relu(x):
            return x
        @staticmethod
        def zeros(*args, **kwargs):
            return None
        class optim:
            class Adam:
                pass
        class utils:
            class data:
                class Dataset:
                    pass
                class DataLoader:
                    pass

# íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸ XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # ë”ë¯¸ ëª¨ë“ˆ
    class xgb:
        class XGBRegressor:
            pass

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("âš ï¸ LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # ë”ë¯¸ ëª¨ë“ˆ
    class lgb:
        class LGBMRegressor:
            pass

# ì‹œê³„ì—´ ëª¨ë¸
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    print("âš ï¸ Prophetì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # ë”ë¯¸ í´ë˜ìŠ¤
    class Prophet:
        pass

from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Keep-Alive ëª¨ë“ˆ (ì„ íƒì )
try:
    from keep_alive import keep_alive
    # Keep-alive ì„œë²„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
    keep_alive()
except ImportError:
    # keep_alive.py íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ
    pass
except Exception as e:
    # Keep-alive ì‹¤íŒ¨ ì‹œì—ë„ ì•±ì€ ì •ìƒ ì‹¤í–‰
    print(f"â„¹ï¸  Keep-alive ë¹„í™œì„±í™”: {e}")

# TA-Lib ì„ íƒì  ì„í¬íŠ¸
try:
    import talib
    TALIB_AVAILABLE = True
except ImportError:
    TALIB_AVAILABLE = False
    # ê²½ê³  ë©”ì‹œì§€ëŠ” ë©”ì¸ UIì—ì„œ í‘œì‹œ (st í•¨ìˆ˜ëŠ” import ì‹œì ì— í˜¸ì¶œ ë¶ˆê°€)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Streamlit í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ì½”ì¸ AI ì˜ˆì¸¡ ì‹œìŠ¤í…œ v2.1",
    layout="wide",
    initial_sidebar_state="expanded"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) CSS ìŠ¤íƒ€ì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
    <style>
    .main { padding: 1rem; }
    
    .section-title {
        font-size: 32px;
        font-weight: bold;
        margin-top: 32px;
        margin-bottom: 16px;
        padding-bottom: 8px;
        border-bottom: 3px solid #3498DB;
        color: #2C3E50;
    }
    
    .stMetric {
        background-color: #F8F9FA;
        border-radius: 12px;
        padding: 16px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .progress-step {
        display: inline-block;
        padding: 8px 16px;
        margin: 4px;
        border-radius: 8px;
        background: #ECF0F1;
        color: #7F8C8D;
        font-size: 14px;
    }
    
    .progress-step.active {
        background: #3498DB;
        color: white;
        font-weight: bold;
    }
    
    .pattern-card {
        background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
        color: white;
        padding: 20px;
        border-radius: 12px;
        margin: 12px 0;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
    }
    
    .pattern-title {
        font-size: 24px;
        font-weight: bold;
        margin-bottom: 12px;
    }
    
    .exit-card {
        background: linear-gradient(135deg, #F093FB 0%, #F5576C 100%);
        color: white;
        padding: 20px;
        border-radius: 12px;
        margin: 12px 0;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
    }
    
    .exit-title {
        font-size: 22px;
        font-weight: bold;
        margin-bottom: 12px;
    }
    </style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CRYPTO_MAP = {
    "ë¹„íŠ¸ì½”ì¸ (BTC)": "BTCUSDT",
    "ì´ë”ë¦¬ì›€ (ETH)": "ETHUSDT",
    "ë¦¬í”Œ (XRP)": "XRPUSDT",
    "ë„ì§€ì½”ì¸ (DOGE)": "DOGEUSDT",
    "ì—ì´ë‹¤ (ADA)": "ADAUSDT",
    "ì†”ë¼ë‚˜ (SOL)": "SOLUSDT"
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 3: ì‹¤ê±°ë˜ ì‹œë®¬ë ˆì´ì…˜ - ê±°ë˜ì†Œ í”„ë¦¬ì…‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ê±°ë˜ì†Œë³„ ìˆ˜ìˆ˜ë£Œ í”„ë¦¬ì…‹
EXCHANGE_PRESETS = {
    'ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼': {
        'maker_fee': 0.0002,  # 0.02%
        'taker_fee': 0.0004,  # 0.04%
        'max_leverage': 125,
        'slippage_rate': 0.0005,  # 0.05% (ê¸°ë³¸ ìŠ¬ë¦¬í”¼ì§€)
        'funding_rate': 0.0001,  # 8ì‹œê°„ë‹¹ 0.01% (í‰ê· )
    },
    'ë°”ì´ë¹„íŠ¸ ì„ ë¬¼': {
        'maker_fee': 0.0002,  # 0.02%
        'taker_fee': 0.0006,  # 0.06%
        'max_leverage': 100,
        'slippage_rate': 0.0006,  # 0.06%
        'funding_rate': 0.0001,
    },
    'ì‚¬ìš©ì ì •ì˜': {
        'maker_fee': 0.0002,
        'taker_fee': 0.0004,
        'max_leverage': 50,
        'slippage_rate': 0.0005,
        'funding_rate': 0.0001,
    }
}


def calculate_effective_leverage(nominal_leverage, stop_loss_pct, volatility):
    """
    ìœ íš¨ ë ˆë²„ë¦¬ì§€ ê³„ì‚°
    
    Parameters:
    -----------
    nominal_leverage : float
        ëª…ëª© ë ˆë²„ë¦¬ì§€
    stop_loss_pct : float
        ì†ì ˆ ë¹„ìœ¨ (%)
    volatility : float
        ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
    
    Returns:
    --------
    dict : ìœ íš¨ ë ˆë²„ë¦¬ì§€ ì •ë³´
        - 'effective': ìœ íš¨ ë ˆë²„ë¦¬ì§€
        - 'risk_adjusted': ë¦¬ìŠ¤í¬ ì¡°ì • ë ˆë²„ë¦¬ì§€
        - 'liquidation_distance': ì²­ì‚° ê±°ë¦¬ (%)
    """
    # ì²­ì‚° ê±°ë¦¬ ê³„ì‚°
    liquidation_distance = 100 / nominal_leverage  # %
    
    # ìœ íš¨ ë ˆë²„ë¦¬ì§€ (ì†ì ˆ ê³ ë ¤)
    effective = min(nominal_leverage, 100 / stop_loss_pct)
    
    # ë¦¬ìŠ¤í¬ ì¡°ì • ë ˆë²„ë¦¬ì§€ (ë³€ë™ì„± ê³ ë ¤)
    risk_adjusted = effective * (1 - min(volatility / 10, 0.5))
    
    return {
        'effective': effective,
        'risk_adjusted': risk_adjusted,
        'liquidation_distance': liquidation_distance
    }


def calculate_expected_fill_price(entry_price, side, slippage_rate, market_impact=0.0):
    """
    ê¸°ëŒ€ ì²´ê²°ê°€ ê³„ì‚° (ìŠ¬ë¦¬í”¼ì§€ ë°˜ì˜)
    
    Parameters:
    -----------
    entry_price : float
        ì§„ì… ê°€ê²©
    side : str
        'long' or 'short'
    slippage_rate : float
        ìŠ¬ë¦¬í”¼ì§€ ë¹„ìœ¨ (0.0005 = 0.05%)
    market_impact : float
        ì‹œì¥ ì¶©ê²© ë¹„ìœ¨ (í° ì£¼ë¬¸ì¼ ê²½ìš° ì¶”ê°€)
    
    Returns:
    --------
    dict : ì²´ê²° ì •ë³´
        - 'expected_price': ê¸°ëŒ€ ì²´ê²°ê°€
        - 'slippage_amount': ìŠ¬ë¦¬í”¼ì§€ ê¸ˆì•¡
        - 'slippage_pct': ìŠ¬ë¦¬í”¼ì§€ í¼ì„¼íŠ¸
    """
    total_slippage = slippage_rate + market_impact
    
    if side == 'long':
        # ë§¤ìˆ˜: ê°€ê²©ì´ ì˜¬ë¼ê°€ë¯€ë¡œ ë¶ˆë¦¬
        expected_price = entry_price * (1 + total_slippage)
        slippage_amount = expected_price - entry_price
    else:  # short
        # ë§¤ë„: ê°€ê²©ì´ ë‚´ë ¤ê°€ë¯€ë¡œ ë¶ˆë¦¬
        expected_price = entry_price * (1 - total_slippage)
        slippage_amount = entry_price - expected_price
    
    slippage_pct = (slippage_amount / entry_price) * 100
    
    return {
        'expected_price': expected_price,
        'slippage_amount': slippage_amount,
        'slippage_pct': slippage_pct
    }


def calculate_trading_costs(position_size, entry_price, exit_price, 
                           leverage, exchange_preset, holding_hours=24):
    """
    ì´ ê±°ë˜ ë¹„ìš© ê³„ì‚° (ìˆ˜ìˆ˜ë£Œ + ìŠ¬ë¦¬í”¼ì§€ + í€ë”© ë¹„ìš©)
    
    Parameters:
    -----------
    position_size : float
        í¬ì§€ì…˜ í¬ê¸° (ì½”ì¸ ìˆ˜ëŸ‰)
    entry_price : float
        ì§„ì…ê°€
    exit_price : float
        ì²­ì‚°ê°€
    leverage : float
        ë ˆë²„ë¦¬ì§€
    exchange_preset : dict
        ê±°ë˜ì†Œ í”„ë¦¬ì…‹
    holding_hours : int
        ë³´ìœ  ì‹œê°„ (ì‹œê°„)
    
    Returns:
    --------
    dict : ë¹„ìš© ë‚´ì—­
    """
    position_value = position_size * entry_price
    
    # 1. ì§„ì… ìˆ˜ìˆ˜ë£Œ (Taker)
    entry_fee = position_value * exchange_preset['taker_fee']
    
    # 2. ì§„ì… ìŠ¬ë¦¬í”¼ì§€
    entry_slip = calculate_expected_fill_price(
        entry_price, 'long', exchange_preset['slippage_rate']
    )
    entry_slippage_cost = position_size * entry_slip['slippage_amount']
    
    # 3. ì²­ì‚° ìˆ˜ìˆ˜ë£Œ (Taker)
    exit_value = position_size * exit_price
    exit_fee = exit_value * exchange_preset['taker_fee']
    
    # 4. ì²­ì‚° ìŠ¬ë¦¬í”¼ì§€
    exit_slip = calculate_expected_fill_price(
        exit_price, 'short', exchange_preset['slippage_rate']
    )
    exit_slippage_cost = position_size * exit_slip['slippage_amount']
    
    # 5. í€ë”© ë¹„ìš© (8ì‹œê°„ë§ˆë‹¤)
    funding_periods = holding_hours / 8
    funding_cost = position_value * exchange_preset['funding_rate'] * funding_periods
    
    total_cost = entry_fee + exit_fee + entry_slippage_cost + exit_slippage_cost + funding_cost
    
    return {
        'entry_fee': entry_fee,
        'exit_fee': exit_fee,
        'entry_slippage': entry_slippage_cost,
        'exit_slippage': exit_slippage_cost,
        'funding_cost': funding_cost,
        'total_cost': total_cost,
        'cost_pct': (total_cost / position_value) * 100
    }


def calibrate_talib_pattern_confidence(pattern_value, candle_range, volatility):
    """
    TA-Lib íŒ¨í„´ ì‹ ë¢°ë„ êµì •
    
    Parameters:
    -----------
    pattern_value : int
        TA-Lib íŒ¨í„´ ê°’ (-100 ~ 100)
    candle_range : float
        ë´‰ ê¸¸ì´ (ê³ ê°€ - ì €ê°€)
    volatility : float
        ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
    
    Returns:
    --------
    float : êµì •ëœ ì‹ ë¢°ë„ (0 ~ 100)
    """
    # 1. ê¸°ë³¸ ì‹ ë¢°ë„ (ì ˆëŒ“ê°’ ë³€í™˜)
    base_confidence = abs(pattern_value)
    
    # 2. ë´‰ ê¸¸ì´ ì •ê·œí™” (ê¸´ ë´‰ì¼ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€)
    avg_candle_range = volatility * 2  # í‰ê·  ë´‰ ê¸¸ì´ ì¶”ì •
    if avg_candle_range > 0:
        range_factor = min(candle_range / avg_candle_range, 2.0)  # ìµœëŒ€ 2ë°°
    else:
        range_factor = 1.0
    
    # 3. ë³€ë™ì„± ëŒ€ë¹„ ìŠ¤ì¼€ì¼ë§
    # ê³ ë³€ë™ì„± ì‹œì¥: íŒ¨í„´ ì‹ ë¢°ë„ ê°ì†Œ
    volatility_factor = 1 / (1 + volatility / 10)
    
    # 4. ìµœì¢… ì‹ ë¢°ë„
    calibrated = base_confidence * range_factor * volatility_factor
    
    return min(calibrated, 100.0)



MAX_LEVERAGE_MAP = {
    "BTCUSDT": 125,
    "ETHUSDT": 100,
    "XRPUSDT": 75,
    "DOGEUSDT": 50,
    "ADAUSDT": 75,
    "SOLUSDT": 50
}

RESOLUTION_MAP = {
    "1ë¶„ë´‰ (1m)": "1m",
    "5ë¶„ë´‰ (5m)": "5m",
    "1ì‹œê°„ë´‰ (1h)": "1h",
    "1ì¼ë´‰ (1d)": "1d"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=3600)
def load_crypto_data(
    symbol: str,
    start: datetime.date,
    end: datetime.date,
    interval: str = '1d'
) -> pd.DataFrame:
    """ì•”í˜¸í™”í ë°ì´í„° ë¡œë“œ"""
    df = pd.DataFrame()
    yf_ticker = symbol[:-4] + "-USD"
    
    days_diff = (end - start).days
    
    interval_limits = {
        '1m': 7,
        '5m': 60,
        '1h': 730,
        '1d': 99999
    }
    
    max_days = interval_limits.get(interval, 99999)
    
    if days_diff > max_days:
        start = end - datetime.timedelta(days=max_days)
    
    try:
        ticker = yf.Ticker(yf_ticker)
        
        if days_diff <= 7:
            period = '7d'
        elif days_diff <= 30:
            period = '1mo'
        elif days_diff <= 90:
            period = '3mo'
        elif days_diff <= 180:
            period = '6mo'
        elif days_diff <= 365:
            period = '1y'
        elif days_diff <= 730:
            period = '2y'
        else:
            period = 'max'
        
        df_hist = ticker.history(period=period, interval=interval, auto_adjust=True, actions=False)
        
        if df_hist is not None and not df_hist.empty:
            df_hist = df_hist[(df_hist.index.date >= start) & (df_hist.index.date <= end)]
            
            if not df_hist.empty:
                df = df_hist.copy()
                if 'Volume' in df.columns:
                    df = df[df['Volume'] > 0].copy()
                if not df.empty:
                    return df
    except Exception as e:
        pass
    
    if df.empty:
        try:
            ticker = yf.Ticker(yf_ticker)
            df_hist = ticker.history(
                start=start,
                end=end + datetime.timedelta(days=1),
                interval=interval,
                auto_adjust=True,
                actions=False
            )
            if df_hist is not None and not df_hist.empty:
                df = df_hist.copy()
                if 'Volume' in df.columns:
                    df = df[df['Volume'] > 0].copy()
                if not df.empty:
                    return df
        except Exception as e:
            pass

    if df.empty:
        try:
            df_max = yf.download(
                yf_ticker,
                period=period if days_diff <= 730 else '2y',
                interval=interval,
                progress=False,
                threads=False,
                auto_adjust=True,
                actions=False
            )
            if df_max is not None and not df_max.empty:
                df = df_max.copy()
                if 'Volume' in df.columns:
                    df = df[df['Volume'] > 0].copy()
        except Exception as e:
            pass

    if df is not None and not df.empty:
        return df
    
    return pd.DataFrame()


def calculate_indicators_wilders(df: pd.DataFrame) -> pd.DataFrame:
    """ì ì‘í˜• ì§€í‘œ ê³„ì‚°"""
    df = df.copy()
    data_len = len(df)
    
    df['ì¼ì¼ìˆ˜ìµë¥ '] = df['Close'].pct_change()

    window_12 = min(12, max(3, data_len // 10))
    window_14 = min(14, max(3, data_len // 8))
    window_20 = min(20, max(5, data_len // 6))
    window_26 = min(26, max(5, data_len // 5))
    window_30 = min(30, max(5, data_len // 4))
    window_50 = min(50, max(10, data_len // 3))
    window_200 = min(200, max(20, data_len // 2))
    
    if data_len >= window_50:
        df['MA50'] = df['Close'].rolling(window=window_50).mean()
        df['EMA50'] = df['Close'].ewm(span=window_50, adjust=False).mean()
    else:
        df['MA50'] = df['Close'].rolling(window=max(3, data_len // 3)).mean()
        df['EMA50'] = df['Close'].ewm(span=max(3, data_len // 3), adjust=False).mean()
    
    if data_len >= window_200:
        df['EMA200'] = df['Close'].ewm(span=window_200, adjust=False).mean()
    else:
        df['EMA200'] = df['Close'].ewm(span=max(10, data_len // 2), adjust=False).mean()
    
    df['EMA12'] = df['Close'].ewm(span=window_12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=window_26, adjust=False).mean()

    # RSI (Wilder's Smoothing)
    delta = df['Close'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    
    period = window_14
    alpha = 1.0 / period
    
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    
    if data_len > period:
        for i in range(period, len(df)):
            avg_gain.iloc[i] = alpha * gain.iloc[i] + (1 - alpha) * avg_gain.iloc[i - 1]
            avg_loss.iloc[i] = alpha * loss.iloc[i] + (1 - alpha) * avg_loss.iloc[i - 1]
    
    rs = avg_gain / (avg_loss + 1e-8)
    df['RSI14'] = 100 - (100 / (1 + rs))

    # ATR (Wilder's Smoothing)
    high = df['High']
    low = df['Low']
    close = df['Close']
    prev_close = close.shift(1)
    
    tr1 = high - low
    tr2 = (high - prev_close).abs()
    tr3 = (low - prev_close).abs()
    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    
    df['TR'] = true_range
    
    atr = true_range.rolling(window=period).mean()
    if data_len > period:
        for i in range(period, len(df)):
            atr.iloc[i] = alpha * true_range.iloc[i] + (1 - alpha) * atr.iloc[i - 1]
    
    df['ATR14'] = atr
    df['Volatility30d'] = df['ì¼ì¼ìˆ˜ìµë¥ '].rolling(window=window_30).std()

    # Stochastic
    df['StochK14'] = 0.0
    if data_len >= window_14:
        low14 = df['Low'].rolling(window=window_14).min()
        high14 = df['High'].rolling(window=window_14).max()
        df['StochK14'] = (df['Close'] - low14) / (high14 - low14 + 1e-8) * 100

    # MFI
    typical_price = (df['High'] + df['Low'] + df['Close']) / 3
    df['MF'] = typical_price * df['Volume']
    # ì¡°ê±´ë¶€ í• ë‹¹ (pandas í˜¸í™˜ì„± ê°œì„ )
    price_change = df['Close'].diff()
    df['PosMF'] = df['MF'].copy()
    df.loc[price_change <= 0, 'PosMF'] = 0
    df['NegMF'] = df['MF'].copy()
    df.loc[price_change >= 0, 'NegMF'] = 0
    roll_pos = df['PosMF'].rolling(window=window_14).sum()
    roll_neg = df['NegMF'].rolling(window=window_14).sum()
    df['MFI14'] = 100 - (100 / (1 + roll_pos / (roll_neg + 1e-8)))

    # VWAP
    df['PV'] = df['Close'] * df['Volume']
    df['Cum_PV'] = df['PV'].cumsum()
    df['Cum_Vol'] = df['Volume'].cumsum()
    df['VWAP'] = df['Cum_PV'] / (df['Cum_Vol'] + 1e-8)

    df['Vol_MA20'] = df['Volume'].rolling(window=window_20).mean()

    # MACD
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']

    # EMA êµì°¨
    df['Cross_Signal'] = 0
    ema50 = df['EMA50']
    ema200 = df['EMA200']
    cond_up = (ema50 > ema200) & (ema50.shift(1) <= ema200.shift(1))
    cond_down = (ema50 < ema200) & (ema50.shift(1) >= ema200.shift(1))
    df.loc[cond_up, 'Cross_Signal'] = 1
    df.loc[cond_down, 'Cross_Signal'] = -1

    essential_cols = ['Close', 'High', 'Low', 'Volume', 'ì¼ì¼ìˆ˜ìµë¥ ']
    df_clean = df.dropna(subset=essential_cols)
    
    optional_cols = ['RSI14', 'ATR14', 'StochK14', 'MFI14', 'MACD', 'MACD_Signal']
    for col in optional_cols:
        if col in df_clean.columns:
            df_clean[col].fillna(0, inplace=True)
    
    return df_clean


def detect_candlestick_patterns_basic(df: pd.DataFrame) -> list:
    """ê¸°ë³¸ 3ê°œ íŒ¨í„´ ê°ì§€ (TA-Lib ì—†ì„ ë•Œ)"""
    patterns = []
    
    if len(df) < 3:
        return []
    
    df_sorted = df.sort_index()
    
    for i in range(2, len(df_sorted)):
        o1, c1, h1, l1 = df_sorted[['Open', 'Close', 'High', 'Low']].iloc[i - 2]
        date1 = df_sorted.index[i - 2]
        
        o2, c2, h2, l2 = df_sorted[['Open', 'Close', 'High', 'Low']].iloc[i - 1]
        date2 = df_sorted.index[i - 1]
        
        o3, c3, h3, l3 = df_sorted[['Open', 'Close', 'High', 'Low']].iloc[i]
        date3 = df_sorted.index[i]

        # Three White Soldiers
        if (c1 > o1) and (c2 > o2) and (c3 > o3) and (c2 > c1) and (c3 > c2):
            patterns.append({
                'name': 'âšª Three White Soldiers',
                'category': '3-ìº”ë“¤',
                'date': date3,
                'conf': 100.0,
                'desc': 'ì„¸ ê°œì˜ ì—°ì† ì–‘ë´‰',
                'impact': 'ê°•ë ¥í•œ ìƒìŠ¹ ì‹ í˜¸',
                'direction': 'ìƒìŠ¹'
            })

        # Morning Star
        body1 = abs(c1 - o1)
        body2 = abs(c2 - o2)
        body3 = abs(c3 - o3)
        range2 = (h2 - l2) if (h2 - l2) != 0 else 1e-8
        if (c1 < o1) and (body2 < range2 * 0.3) and (c2 < c1) and (o2 < c1) and \
           (c3 > o3) and (c3 > (o1 + c1) / 2):
            conf = min((body3 / (h3 - l3 + 1e-8)) * 100, 100.0)
            patterns.append({
                'name': 'ğŸŒ… Morning Star',
                'category': '3-ìº”ë“¤',
                'date': date3,
                'conf': round(conf, 2),
                'desc': 'í•˜ë½ í›„ ë°˜ì „ ì‹ í˜¸',
                'impact': 'ìƒìŠ¹ ì „í™˜ ê°€ëŠ¥ì„±',
                'direction': 'ìƒìŠ¹'
            })

        # Doji
        if abs(o3 - c3) <= (h3 - l3) * 0.1:
            patterns.append({
                'name': 'âœ–ï¸ Doji',
                'category': 'ë‹¨ì¼',
                'date': date3,
                'conf': 100.0,
                'desc': 'ë§¤ìˆ˜/ë§¤ë„ ê· í˜•',
                'impact': 'ì¶”ì„¸ ì „í™˜ ê°€ëŠ¥ì„±',
                'direction': 'ì¤‘ë¦½'
            })

    # ê°™ì€ íŒ¨í„´ëª…ì€ ìµœì‹  1ê°œë§Œ
    unique_patterns = {}
    for pattern in reversed(patterns):
        pattern_name = pattern['name']
        if pattern_name not in unique_patterns:
            unique_patterns[pattern_name] = pattern
    
    result = list(unique_patterns.values())
    result.sort(key=lambda x: x['date'], reverse=True)
    
    return result[:10]


def detect_candlestick_patterns_talib(df: pd.DataFrame) -> list:
    """TA-Lib ê¸°ë°˜ 61ê°œ íŒ¨í„´ ê°ì§€"""
    patterns = []
    
    if len(df) < 5:  # ìµœì†Œ 5ê°œ í•„ìš” (ì¼ë¶€ íŒ¨í„´ì´ 5ë´‰ ìš”êµ¬)
        return []
    
    df_sorted = df.sort_index()
    open_prices = df_sorted['Open'].values
    high_prices = df_sorted['High'].values
    low_prices = df_sorted['Low'].values
    close_prices = df_sorted['Close'].values
    
    # TA-Lib íŒ¨í„´ ì •ì˜ (58ê°œ + ê¸°ì¡´ 3ê°œ = 61ê°œ)
    pattern_functions = {
        # ë‹¨ì¼(1-ìº”ë“¤) - 15ê°œ
        'CDLBELTHOLD': ('ğŸ”¨ Belt Hold', 'ë²¨íŠ¸ í™€ë“œ', 'ë‹¨ì¼'),
        'CDLCLOSINGMARUBOZU': ('ğŸ“Š Closing Marubozu', 'ì¢…ê°€ ë§ˆë£¨ë³´ì¦ˆ', 'ë‹¨ì¼'),
        'CDLMARUBOZU': ('ğŸ“ Marubozu', 'ë§ˆë£¨ë³´ì¦ˆ', 'ë‹¨ì¼'),
        'CDLLONGLINE': ('ğŸ“ Long Line', 'ì¥ëŒ€ë´‰', 'ë‹¨ì¼'),
        'CDLSHORTLINE': ('ğŸ“Œ Short Line', 'ë‹¨ë´‰', 'ë‹¨ì¼'),
        'CDLSPINNINGTOP': ('ğŸŒªï¸ Spinning Top', 'íŒ½ì´í˜•', 'ë‹¨ì¼'),
        'CDLHIGHWAVE': ('ğŸŒŠ High Wave', 'ë†’ì€ íŒŒë™í˜•', 'ë‹¨ì¼'),
        'CDLHAMMER': ('ğŸ”¨ Hammer', 'í•´ë¨¸', 'ë‹¨ì¼'),
        'CDLHANGINGMAN': ('ğŸ‘¤ Hanging Man', 'êµìˆ˜í˜•', 'ë‹¨ì¼'),
        'CDLINVERTEDHAMMER': ('ğŸ”§ Inverted Hammer', 'ì—­ë§ì¹˜', 'ë‹¨ì¼'),
        'CDLSHOOTINGSTAR': ('â­ Shooting Star', 'ìœ ì„±í˜•', 'ë‹¨ì¼'),
        'CDLRICKSHAWMAN': ('ğŸš¶ Rickshaw Man', 'ë¦­ìƒ¤ë§¨', 'ë‹¨ì¼'),
        'CDLTAKURI': ('ğŸ£ Takuri', 'íƒ€ì¿ ë¦¬', 'ë‹¨ì¼'),
        'CDLKICKING': ('ğŸ‘Ÿ Kicking', 'í‚¥í‚¹', 'ë‹¨ì¼'),
        'CDLKICKINGBYLENGTH': ('ğŸ‘¢ Kicking by Length', 'í‚¥í‚¹(ê¸¸ì´ ê¸°ì¤€)', 'ë‹¨ì¼'),
        
        # 2-ìº”ë“¤ - 12ê°œ
        'CDLENGULFING': ('ğŸ«‚ Engulfing', 'í¬ìš©í˜•', '2-ìº”ë“¤'),
        'CDLHARAMI': ('ğŸ¤° Harami', 'í•˜ë¼ë¯¸', '2-ìº”ë“¤'),
        'CDLHARAMICROSS': ('â• Harami Cross', 'í•˜ë¼ë¯¸ í¬ë¡œìŠ¤', '2-ìº”ë“¤'),
        'CDLPIERCING': ('ğŸ¯ Piercing', 'ê´€í†µí˜•', '2-ìº”ë“¤'),
        'CDLDARKCLOUDCOVER': ('â˜ï¸ Dark Cloud Cover', 'ì•”ìš´í˜•', '2-ìº”ë“¤'),
        'CDLCOUNTERATTACK': ('âš”ï¸ Counterattack', 'ë°˜ê²©ì„ ', '2-ìº”ë“¤'),
        'CDLONNECK': ('ğŸ¦¢ On Neck', 'ì˜¨ë„¥', '2-ìº”ë“¤'),
        'CDLINNECK': ('ğŸ¦† In Neck', 'ì¸ë„¥', '2-ìº”ë“¤'),
        'CDLTHRUSTING': ('ğŸ—¡ï¸ Thrusting', 'ìŠ¤ëŸ¬ìŠ¤íŒ…', '2-ìº”ë“¤'),
        'CDLSEPARATINGLINES': ('â†”ï¸ Separating Lines', 'ì„¸í¼ë ˆì´íŒ… ë¼ì¸', '2-ìº”ë“¤'),
        'CDLMATCHINGLOW': ('ğŸ¯ Matching Low', 'ë§¤ì¹­ ë¡œìš°', '2-ìº”ë“¤'),
        'CDLHOMINGPIGEON': ('ğŸ•Šï¸ Homing Pigeon', 'í˜¸ë° í”¼ì „', '2-ìº”ë“¤'),
        
        # 3-ìº”ë“¤ - 11ê°œ
        'CDL2CROWS': ('ğŸ¦ Two Crows', 'íˆ¬ í¬ë¡œìš°ì¦ˆ', '3-ìº”ë“¤'),
        'CDL3INSIDE': ('ğŸ“¦ Three Inside', 'ì‚¼ë‚´ë¶€', '3-ìº”ë“¤'),
        'CDL3OUTSIDE': ('ğŸ“¤ Three Outside', 'ì‚¼ì™¸ë¶€', '3-ìº”ë“¤'),
        'CDL3LINESTRIKE': ('âš¡ Three Line Strike', 'ì“°ë¦¬ ë¼ì¸ ìŠ¤íŠ¸ë¼ì´í¬', '3-ìº”ë“¤'),
        'CDL3BLACKCROWS': ('ğŸ¦â€â¬› Three Black Crows', 'ì„¸ ê²€ì€ ê¹Œë§ˆê·€', '3-ìº”ë“¤'),
        'CDLIDENTICAL3CROWS': ('ğŸ¦… Identical Three Crows', 'ë™ì¼ ì‚¼ê¹Œë§ˆê·€', '3-ìº”ë“¤'),
        'CDLUNIQUE3RIVER': ('ğŸï¸ Unique 3 River', 'ìœ ë‹ˆí¬ ì“°ë¦¬ ë¦¬ë²„', '3-ìº”ë“¤'),
        'CDL3STARSINSOUTH': ('â­ Three Stars in South', 'ë‚¨ìª½ì˜ ì„¸ ë³„', '3-ìº”ë“¤'),
        'CDLUPSIDEGAP2CROWS': ('ğŸ“ˆ Upside Gap Two Crows', 'ì—…ì‚¬ì´ë“œ ê°­ íˆ¬ í¬ë¡œìš°ì¦ˆ', '3-ìº”ë“¤'),
        'CDLEVENINGSTAR': ('ğŸŒ† Evening Star', 'ì„ë³„í˜•', '3-ìº”ë“¤'),
        'CDLTRISTAR': ('âœ¨ Tristar', 'íŠ¸ë¦¬ìŠ¤íƒ€', '3-ìº”ë“¤'),
        
        # ê°­/ì§€ì†/ë³µí•© - 9ê°œ
        'CDLBREAKAWAY': ('ğŸš€ Breakaway', 'ë¸Œë ˆì´í¬ì–´ì›¨ì´', 'ë³µí•©'),
        'CDLRISEFALL3METHODS': ('ğŸ“Š Rising/Falling 3 Methods', 'ìƒìŠ¹í•˜ë½ ì‚¼ë²•', 'ë³µí•©'),
        'CDLMATHOLD': ('ğŸ¤ Mat Hold', 'ë§¤íŠ¸ í™€ë“œ', 'ë³µí•©'),
        'CDLTASUKIGAP': ('ğŸ“ Tasuki Gap', 'íƒ€ìŠ¤í‚¤ ê°­', 'ë³µí•©'),
        'CDLGAPSIDESIDEWHITE': ('â¬œ Gap Side-by-Side White', 'ê°­ ì‚¬ì´ë“œë°”ì´ì‚¬ì´ë“œ', 'ë³µí•©'),
        'CDLXSIDEGAP3METHODS': ('ğŸ“ˆ Gap Three Methods', 'ê°­ ì“°ë¦¬ ë©”ì„œì¦ˆ', 'ë³µí•©'),
        'CDLABANDONEDBABY': ('ğŸ‘¶ Abandoned Baby', 'ì–´ë°´ë˜ë“œ ë² ì´ë¹„', 'ë³µí•©'),
        'CDLCONCEALBABYSWALL': ('ğŸ¦ Concealing Baby Swallow', 'ì»¨ì‹¤ë§ ë² ì´ë¹„', 'ë³µí•©'),
        'CDLLADDERBOTTOM': ('ğŸªœ Ladder Bottom', 'ë˜ë” ë°”í…€', 'ë³µí•©'),
        
        # íŠ¹ìˆ˜ - 5ê°œ
        'CDLADVANCEBLOCK': ('ğŸš§ Advance Block', 'ì „ì§„ ë´‰ì‡„', 'íŠ¹ìˆ˜'),
        'CDLSTALLEDPATTERN': ('â¸ï¸ Stalled Pattern', 'ì •ì²´ íŒ¨í„´', 'íŠ¹ìˆ˜'),
        'CDLSTICKSANDWICH': ('ğŸ¥ª Stick Sandwich', 'ìŠ¤í‹± ìƒŒë“œìœ„ì¹˜', 'íŠ¹ìˆ˜'),
        'CDLHIKKAKE': ('ğŸ£ Hikkake', 'í›ì¹´ì¼€', 'íŠ¹ìˆ˜'),
        'CDLHIKKAKEMOD': ('ğŸ¯ Modified Hikkake', 'ìˆ˜ì • í›ì¹´ì¼€', 'íŠ¹ìˆ˜'),
        
        # ê¸°ì¡´ 3ê°œ (TA-Libì—ë„ ìˆì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€)
        'CDL3WHITESOLDIERS': ('âšª Three White Soldiers', 'ì„¸ ê°œì˜ ì—°ì† ì–‘ë´‰', '3-ìº”ë“¤'),
        'CDLMORNINGSTAR': ('ğŸŒ… Morning Star', 'í•˜ë½ í›„ ë°˜ì „ ì‹ í˜¸', '3-ìº”ë“¤'),
        'CDLDOJI': ('âœ–ï¸ Doji', 'ë§¤ìˆ˜/ë§¤ë„ ê· í˜•', 'ë‹¨ì¼'),
    }
    
    # ê° íŒ¨í„´ ê°ì§€
    for func_name, (emoji_name, korean_name, category) in pattern_functions.items():
        try:
            if not hasattr(talib, func_name):
                continue
                
            pattern_func = getattr(talib, func_name)
            result = pattern_func(open_prices, high_prices, low_prices, close_prices)
            
            # íŒ¨í„´ ë°œìƒ ì§€ì  ì°¾ê¸°
            for i, value in enumerate(result):
                if value != 0:  # 0ì´ ì•„ë‹ˆë©´ íŒ¨í„´ ë°œìƒ
                    # ì‹ ë¢°ë„ ë³€í™˜: -100~100 â†’ 0~100%
                    confidence = abs(value)
                    
                    # ë°©í–¥ íŒë‹¨
                    if value > 0:
                        direction = 'ìƒìŠ¹'
                        impact = 'ìƒìŠ¹ ì‹ í˜¸'
                    elif value < 0:
                        direction = 'í•˜ë½'
                        impact = 'í•˜ë½ ì‹ í˜¸'
                    else:
                        direction = 'ì¤‘ë¦½'
                        impact = 'ì¶”ì„¸ ì „í™˜ ê°€ëŠ¥ì„±'
                    
                    patterns.append({
                        'name': emoji_name,
                        'category': category,
                        'date': df_sorted.index[i],
                        'conf': confidence,
                        'desc': korean_name,
                        'impact': impact,
                        'direction': direction
                    })
        except Exception as e:
            continue
    
    # ê°™ì€ íŒ¨í„´ëª…ì€ ìµœì‹  1ê°œë§Œ
    unique_patterns = {}
    for pattern in reversed(patterns):
        pattern_name = pattern['name']
        if pattern_name not in unique_patterns:
            unique_patterns[pattern_name] = pattern
    
    result = list(unique_patterns.values())
    result.sort(key=lambda x: x['date'], reverse=True)
    
    return result[:10]  # ìµœëŒ€ 10ê°œ


def detect_candlestick_patterns(df: pd.DataFrame) -> list:
    """ìº”ë“¤ìŠ¤í‹± íŒ¨í„´ ê°ì§€ (TA-Lib ìˆìœ¼ë©´ 61ê°œ, ì—†ìœ¼ë©´ 3ê°œ)"""
    if TALIB_AVAILABLE:
        return detect_candlestick_patterns_talib(df)
    else:
        return detect_candlestick_patterns_basic(df)


def calculate_exit_strategy(df: pd.DataFrame, entry_price: float, atr: float, 
                            investment_amount: float, leverage: float) -> dict:
    """
    ë§¤ë„ ì‹œì  ì˜ˆì¸¡
    - ë³´ìˆ˜ì /ì¤‘ë¦½/ê³µê²©ì  ì‹œë‚˜ë¦¬ì˜¤ ì œê³µ
    - ATR ê¸°ë°˜ ë™ì  ì†ì ˆ/ìµì ˆ
    - ì¶”ì„¸ ì „í™˜ ì‹ í˜¸ ê°ì§€
    """
    current_price = df['Close'].iloc[-1]
    rsi = df['RSI14'].iloc[-1]
    ema50 = df['EMA50'].iloc[-1]
    ema200 = df['EMA200'].iloc[-1]
    
    # ì¶”ì„¸ íŒë‹¨
    trend = 'bullish' if ema50 > ema200 else 'bearish'
    
    # 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤
    scenarios = {}
    
    # 1. ë³´ìˆ˜ì  (ë¹ ë¥¸ ìµì ˆ, ì†ì ˆ)
    scenarios['conservative'] = {
        'name': 'ğŸ›¡ï¸ ë³´ìˆ˜ì  ì „ëµ',
        'take_profit': entry_price + (atr * 1.5),
        'stop_loss': entry_price - (atr * 1.0),
        'holding_period': '1-3ì¼',
        'description': 'ë¹ ë¥¸ ìˆ˜ìµ ì‹¤í˜„, ë¦¬ìŠ¤í¬ ìµœì†Œí™”',
        'rr_ratio': 1.5,
        'exit_signals': [
            'RSI > 70 (ê³¼ë§¤ìˆ˜)',
            'EMA50 í•˜í–¥ ëŒíŒŒ',
            'ëª©í‘œ ìˆ˜ìµë¥  5% ë„ë‹¬'
        ]
    }
    
    # 2. ì¤‘ë¦½ì  (ê· í˜•ì¡íŒ ì ‘ê·¼)
    scenarios['neutral'] = {
        'name': 'âš–ï¸ ì¤‘ë¦½ì  ì „ëµ',
        'take_profit': entry_price + (atr * 2.5),
        'stop_loss': entry_price - (atr * 1.5),
        'holding_period': '3-7ì¼',
        'description': 'ë¦¬ìŠ¤í¬-ìˆ˜ìµ ê· í˜•',
        'rr_ratio': 1.67,
        'exit_signals': [
            'RSI > 75 (ê°•í•œ ê³¼ë§¤ìˆ˜)',
            'EMA50/200 ë°ë“œí¬ë¡œìŠ¤',
            'ëª©í‘œ ìˆ˜ìµë¥  10% ë„ë‹¬'
        ]
    }
    
    # 3. ê³µê²©ì  (í° ìˆ˜ìµ ì¶”êµ¬)
    scenarios['aggressive'] = {
        'name': 'ğŸš€ ê³µê²©ì  ì „ëµ',
        'take_profit': entry_price + (atr * 4.0),
        'stop_loss': entry_price - (atr * 2.0),
        'holding_period': '7-14ì¼',
        'description': 'í° ìˆ˜ìµ ì¶”êµ¬, ë†’ì€ ë¦¬ìŠ¤í¬',
        'rr_ratio': 2.0,
        'exit_signals': [
            'RSI > 80 (ê·¹ì‹¬í•œ ê³¼ë§¤ìˆ˜)',
            'ì£¼ìš” ì €í•­ì„  ë„ë‹¬',
            'ëª©í‘œ ìˆ˜ìµë¥  20% ë„ë‹¬'
        ]
    }
    
    # ì¶”ì„¸ ê¸°ë°˜ ì¡°ì •
    if trend == 'bearish':
        # í•˜ë½ ì¶”ì„¸ì—ì„œëŠ” ë” ë³´ìˆ˜ì ìœ¼ë¡œ
        for scenario in scenarios.values():
            scenario['take_profit'] *= 0.8
            scenario['stop_loss'] *= 1.2
    
    # í˜„ì¬ ìƒíƒœ í‰ê°€
    current_status = {
        'current_price': current_price,
        'entry_price': entry_price,
        'unrealized_pnl': (current_price - entry_price) / entry_price * 100,
        'rsi_status': 'overbought' if rsi > 70 else 'oversold' if rsi < 30 else 'neutral',
        'trend': trend,
        'recommendation': None
    }
    
    # ì¦‰ì‹œ ë§¤ë„ ê¶Œì¥ ì¡°ê±´
    if rsi > 80 and current_status['unrealized_pnl'] > 10:
        current_status['recommendation'] = 'âš ï¸ ì¦‰ì‹œ ë§¤ë„ ê³ ë ¤ (ê·¹ì‹¬í•œ ê³¼ë§¤ìˆ˜ + ë†’ì€ ìˆ˜ìµ)'
    elif trend == 'bearish' and current_status['unrealized_pnl'] < -5:
        current_status['recommendation'] = 'âš ï¸ ì†ì ˆ ê³ ë ¤ (í•˜ë½ ì¶”ì„¸ + ì†ì‹¤ í™•ëŒ€)'
    elif current_status['unrealized_pnl'] > 20:
        current_status['recommendation'] = 'âœ… ë¶€ë¶„ ìµì ˆ ê³ ë ¤ (ë†’ì€ ìˆ˜ìµ ë‹¬ì„±)'
    else:
        current_status['recommendation'] = 'â³ í™€ë”© ìœ ì§€'
    
    return {
        'scenarios': scenarios,
        'current_status': current_status,
        'atr': atr,
        'trend': trend
    }


# ê¸°íƒ€ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [ì¶”ê°€ë¨] AI ì˜ˆì¸¡ ë° í¬ì§€ì…˜ ì¶”ì²œ í•¨ìˆ˜ (v2.2.0)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def predict_trend_with_ai(df: pd.DataFrame, current_price: float, 
                          ema_short: float, ema_long: float, 
                          rsi: float, macd: float, macd_signal: float) -> dict:
    """
    AI ê¸°ë°˜ ë‹¨ê¸° ì¶”ì„¸ ì˜ˆì¸¡
    
    Returns:
        dict: {
            'trend': 'bullish' | 'bearish' | 'neutral',
            'confidence': float (0-100),
            'reasoning': str,
            'signal_strength': float (0-100)
        }
    """
    signals = []
    weights = []
    reasons = []
    
    # 1. ì´ë™í‰ê·  ë¶„ì„ (ê°€ì¤‘ì¹˜: 30%)
    if ema_short > ema_long:
        ma_diff_pct = ((ema_short - ema_long) / ema_long) * 100
        if ma_diff_pct > 2:
            signals.append(1.0)
            reasons.append(f"ê³¨ë“ í¬ë¡œìŠ¤ ê°•ì„¸ (ì°¨ì´ {ma_diff_pct:.1f}%)")
        elif ma_diff_pct > 0.5:
            signals.append(0.7)
            reasons.append(f"ê³¨ë“ í¬ë¡œìŠ¤ ({ma_diff_pct:.1f}%)")
        else:
            signals.append(0.5)
            reasons.append("ë‹¨ê¸° ì´í‰ì„  ìš°ìœ„")
        weights.append(0.30)
    else:
        ma_diff_pct = ((ema_long - ema_short) / ema_long) * 100
        if ma_diff_pct > 2:
            signals.append(-1.0)
            reasons.append(f"ë°ë“œí¬ë¡œìŠ¤ ì•½ì„¸ (ì°¨ì´ {ma_diff_pct:.1f}%)")
        elif ma_diff_pct > 0.5:
            signals.append(-0.7)
            reasons.append(f"ë°ë“œí¬ë¡œìŠ¤ ({ma_diff_pct:.1f}%)")
        else:
            signals.append(-0.5)
            reasons.append("ì¥ê¸° ì´í‰ì„  ìš°ìœ„")
        weights.append(0.30)
    
    # 2. RSI ë¶„ì„ (ê°€ì¤‘ì¹˜: 25%)
    if rsi > 70:
        signals.append(-0.8)
        reasons.append(f"ê³¼ë§¤ìˆ˜ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    elif rsi > 60:
        signals.append(0.3)
        reasons.append(f"ê°•ì„¸ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    elif rsi < 30:
        signals.append(0.8)
        reasons.append(f"ê³¼ë§¤ë„ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    elif rsi < 40:
        signals.append(-0.3)
        reasons.append(f"ì•½ì„¸ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    else:
        signals.append(0.0)
        reasons.append(f"ì¤‘ë¦½ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    
    # 3. MACD ë¶„ì„ (ê°€ì¤‘ì¹˜: 25%)
    macd_diff = macd - macd_signal
    if macd_diff > 0:
        if macd > 0:
            signals.append(0.9)
            reasons.append("MACD ìƒìŠ¹ ëª¨ë©˜í…€")
        else:
            signals.append(0.5)
            reasons.append("MACD ë°˜ì „ ì‹ í˜¸")
        weights.append(0.25)
    else:
        if macd < 0:
            signals.append(-0.9)
            reasons.append("MACD í•˜ë½ ëª¨ë©˜í…€")
        else:
            signals.append(-0.5)
            reasons.append("MACD ì•½í™” ì‹ í˜¸")
        weights.append(0.25)
    
    # 4. ê±°ë˜ëŸ‰ ë¶„ì„ (ê°€ì¤‘ì¹˜: 20%)
    if 'Volume' in df.columns and len(df) > 20:
        recent_volume = df['Volume'].iloc[-5:].mean()
        avg_volume = df['Volume'].iloc[-20:].mean()
        volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1.0
        
        if volume_ratio > 1.5:
            current_trend = 1 if ema_short > ema_long else -1
            signals.append(current_trend * 0.7)
            reasons.append(f"ê±°ë˜ëŸ‰ ê¸‰ì¦ ({volume_ratio:.1f}ë°°)")
            weights.append(0.20)
        elif volume_ratio > 1.2:
            current_trend = 1 if ema_short > ema_long else -1
            signals.append(current_trend * 0.4)
            reasons.append(f"ê±°ë˜ëŸ‰ ì¦ê°€ ({volume_ratio:.1f}ë°°)")
            weights.append(0.20)
        elif volume_ratio < 0.7:
            signals.append(0.0)
            reasons.append(f"ê±°ë˜ëŸ‰ ê°ì†Œ ({volume_ratio:.1f}ë°°)")
            weights.append(0.20)
        else:
            signals.append(0.0)
            reasons.append("ê±°ë˜ëŸ‰ í‰ê·  ìˆ˜ì¤€")
            weights.append(0.20)
    
    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    weighted_signal = sum(s * w for s, w in zip(signals, weights)) / sum(weights)
    
    # ì¶”ì„¸ íŒë‹¨
    if weighted_signal > 0.3:
        trend = 'bullish'
        trend_kr = 'ìƒìŠ¹'
    elif weighted_signal < -0.3:
        trend = 'bearish'
        trend_kr = 'í•˜ë½'
    else:
        trend = 'neutral'
        trend_kr = 'ë³´í•©'
    
    # ì‹ ë¢°ë„ ê³„ì‚°
    confidence = min(abs(weighted_signal) * 100, 100)
    signal_strength = (weighted_signal + 1) * 50
    
    top_reasons = reasons[:2] if len(reasons) >= 2 else reasons
    reasoning = " + ".join(top_reasons)
    
    return {
        'trend': trend,
        'trend_kr': trend_kr,
        'confidence': round(confidence, 1),
        'reasoning': reasoning,
        'signal_strength': round(signal_strength, 1),
        'weighted_signal': weighted_signal
    }


def recommend_position(ai_prediction: dict, current_price: float, 
                      stop_loss: float, take_profit: float,
                      volatility: float) -> dict:
    """
    AI ì˜ˆì¸¡ì„ ê¸°ë°˜ìœ¼ë¡œ í¬ì§€ì…˜ ì¶”ì²œ
    """
    trend = ai_prediction['trend']
    confidence = ai_prediction['confidence']
    
    # í¬ì§€ì…˜ ê²°ì •
    if trend == 'bullish' and confidence > 50:
        position = 'LONG'
        position_kr = 'ë¡± í¬ì§€ì…˜'
        probability = 50 + (confidence * 0.5)
        base_reason = ai_prediction['reasoning']
    elif trend == 'bearish' and confidence > 50:
        position = 'SHORT'
        position_kr = 'ìˆ í¬ì§€ì…˜'
        probability = 50 + (confidence * 0.5)
        base_reason = ai_prediction['reasoning']
    else:
        position = 'NEUTRAL'
        position_kr = 'ê´€ë§'
        probability = 50
        base_reason = "ëª…í™•í•œ ì¶”ì„¸ ì—†ìŒ"
    
    # ë¦¬ìŠ¤í¬ ë ˆë²¨
    if volatility > 0.05:
        risk_level = 'HIGH'
        risk_kr = 'ë†’ìŒ'
        risk_adjustment = -5
    elif volatility > 0.03:
        risk_level = 'MEDIUM'
        risk_kr = 'ì¤‘ê°„'
        risk_adjustment = 0
    else:
        risk_level = 'LOW'
        risk_kr = 'ë‚®ìŒ'
        risk_adjustment = +5
    
    final_probability = min(max(probability + risk_adjustment, 45), 85)
    
    if position == 'NEUTRAL':
        reasoning = f"{base_reason}, ì‹œì¥ ë³€ë™ì„± {risk_kr}"
        recommendation_text = "í˜„ì¬ ë°ì´í„° ê¸°ì¤€, **ê´€ë§(ë³´ë¥˜)** ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
    else:
        reasoning = f"{base_reason}, ì‹œì¥ ë³€ë™ì„± {risk_kr}"
        recommendation_text = f"í˜„ì¬ ë°ì´í„° ê¸°ì¤€, **{position_kr}** ì´ ìš°ì„¸(ì•½ **{final_probability:.0f}%**) ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
    
    # ì†ìµë¹„
    if position == 'LONG':
        potential_profit = ((take_profit - current_price) / current_price) * 100
        potential_loss = ((current_price - stop_loss) / current_price) * 100
    elif position == 'SHORT':
        potential_profit = ((current_price - stop_loss) / current_price) * 100
        potential_loss = ((take_profit - current_price) / current_price) * 100
    else:
        potential_profit = 0
        potential_loss = 0
    
    rr_ratio = potential_profit / potential_loss if potential_loss > 0 else 0
    
    return {
        'position': position,
        'position_kr': position_kr,
        'probability': round(final_probability, 1),
        'reasoning': reasoning,
        'risk_level': risk_level,
        'risk_kr': risk_kr,
        'recommendation_text': recommendation_text,
        'potential_profit_pct': round(potential_profit, 2),
        'potential_loss_pct': round(potential_loss, 2),
        'risk_reward_ratio': round(rr_ratio, 2)
    }


def render_ai_prediction(ai_prediction: dict, current_price: float):
    """[ì¶”ê°€ë¨] ğŸ¤– AI ì˜ˆì¸¡ ê²°ê³¼ ì„¹ì…˜"""
    st.markdown("<div class='section-title'>ğŸ¤– AI ì˜ˆì¸¡ ê²°ê³¼</div>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ“Š ë‹¨ê¸° ì¶”ì„¸ ì˜ˆì¸¡")
        trend_emoji = {'bullish': 'ğŸ“ˆ', 'bearish': 'ğŸ“‰', 'neutral': 'â¡ï¸'}
        trend_color = {'bullish': 'green', 'bearish': 'red', 'neutral': 'gray'}
        trend = ai_prediction['trend']
        st.markdown(f"<h2 style='color:{trend_color[trend]};'>{trend_emoji[trend]} {ai_prediction['trend_kr']}</h2>", 
                   unsafe_allow_html=True)
    
    with col2:
        st.markdown("### ğŸ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„")
        confidence = ai_prediction['confidence']
        if confidence >= 70:
            bar_color = 'green'
            conf_text = 'ë†’ìŒ'
        elif confidence >= 50:
            bar_color = 'orange'
            conf_text = 'ì¤‘ê°„'
        else:
            bar_color = 'red'
            conf_text = 'ë‚®ìŒ'
        st.markdown(f"""
        <div style='background-color: #f0f0f0; border-radius: 10px; padding: 10px;'>
            <div style='background-color: {bar_color}; width: {confidence}%; height: 30px; 
                        border-radius: 5px; text-align: center; line-height: 30px; color: white; font-weight: bold;'>
                {confidence:.1f}%
            </div>
            <p style='text-align: center; margin-top: 5px; color: #666;'>{conf_text}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### ğŸ’¡ ì˜ˆì¸¡ ê·¼ê±°")
        st.info(ai_prediction['reasoning'])
    
    signal_strength = ai_prediction['signal_strength']
    if signal_strength > 60:
        gauge_color = 'linear-gradient(90deg, #28a745 0%, #218838 100%)'
        gauge_text = 'ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸'
    elif signal_strength > 55:
        gauge_color = 'linear-gradient(90deg, #90EE90 0%, #28a745 100%)'
        gauge_text = 'ë§¤ìˆ˜ ì‹ í˜¸'
    elif signal_strength >= 45:
        gauge_color = 'linear-gradient(90deg, #FFA500 0%, #FF8C00 100%)'
        gauge_text = 'ì¤‘ë¦½'
    elif signal_strength >= 40:
        gauge_color = 'linear-gradient(90deg, #FF6347 0%, #FFA500 100%)'
        gauge_text = 'ë§¤ë„ ì‹ í˜¸'
    else:
        gauge_color = 'linear-gradient(90deg, #dc3545 0%, #c82333 100%)'
        gauge_text = 'ê°•í•œ ë§¤ë„ ì‹ í˜¸'
    
    st.markdown(f"""
    <div style='background-color: #e0e0e0; border-radius: 20px; height: 40px; position: relative; overflow: hidden; margin-top: 20px;'>
        <div style='background: {gauge_color}; width: {signal_strength}%; height: 100%; border-radius: 20px;'></div>
        <div style='position: absolute; top: 0; left: 0; right: 0; text-align: center; 
                    line-height: 40px; color: white; font-weight: bold; text-shadow: 1px 1px 2px rgba(0,0,0,0.5);'>
            {gauge_text} ({signal_strength:.0f}/100)
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("---")


def render_position_recommendation(position_rec: dict):
    """[ì¶”ê°€ë¨] í¬ì§€ì…˜ ì¶”ì²œ (ë§¤ë§¤ ì „ëµ ë‚´ë¶€)"""
    st.markdown("#### ğŸ¯ í¬ì§€ì…˜ ì¶”ì²œ")
    position = position_rec['position']
    if position == 'LONG':
        bg_color = '#d4edda'
        border_color = '#28a745'
        icon = 'ğŸ“ˆ'
    elif position == 'SHORT':
        bg_color = '#f8d7da'
        border_color = '#dc3545'
        icon = 'ğŸ“‰'
    else:
        bg_color = '#fff3cd'
        border_color = '#ffc107'
        icon = 'â¸ï¸'
    
    st.markdown(f"""
    <div style='background-color: {bg_color}; border-left: 5px solid {border_color}; 
                padding: 20px; border-radius: 10px; margin: 10px 0;'>
        <h3 style='margin: 0; color: {border_color};'>{icon} {position_rec['recommendation_text']}</h3>
        <p style='margin: 10px 0 0 0; color: #666;'>
            <strong>ì¶”ì²œ ì´ìœ :</strong> {position_rec['reasoning']}
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(label="í¬ì§€ì…˜", value=position_rec['position_kr'])
    with col2:
        st.metric(label="í™•ë¥ ", value=f"{position_rec['probability']:.0f}%")
    with col3:
        st.metric(label="ë¦¬ìŠ¤í¬", value=position_rec['risk_kr'])
    with col4:
        if position != 'NEUTRAL':
            st.metric(label="ì†ìµë¹„", value=f"{position_rec['risk_reward_ratio']:.2f}")
    
    if position != 'NEUTRAL':
        st.markdown("##### ğŸ’° ì˜ˆìƒ ì†ìµ")
        col_profit, col_loss = st.columns(2)
        with col_profit:
            st.success(f"**ëª©í‘œ ìˆ˜ìµ:** +{position_rec['potential_profit_pct']:.2f}%")
        with col_loss:
            st.error(f"**ìµœëŒ€ ì†ì‹¤:** -{position_rec['potential_loss_pct']:.2f}%")
    
    st.warning("""
    âš ï¸ **ì£¼ì˜ì‚¬í•­**  
    - ì´ ì¶”ì²œì€ ê³¼ê±° ë°ì´í„° ê¸°ë°˜ í™•ë¥ ì  ì˜ˆì¸¡ì´ë©°, íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤.  
    - ì‹¤ì œ íˆ¬ì ì‹œ ë³¸ì¸ì˜ ë¦¬ìŠ¤í¬ í—ˆìš© ë²”ìœ„ ë‚´ì—ì„œ ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.  
    - ì‹œì¥ ìƒí™©ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€í•˜ë¯€ë¡œ, ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.
    """)


def calculate_optimized_leverage(investment_amount: float, volatility: float, 
                                 atr_ratio: float, confidence: float, max_leverage: int, 
                                 crypto_name: str = "BTC") -> dict:
    """
    ë ˆë²„ë¦¬ì§€ ìµœì í™” (v2.3.0)
    
    Returns:
        dict: {
            'recommended': ê¶Œì¥ ë ˆë²„ë¦¬ì§€,
            'maximum': ìµœëŒ€ ë ˆë²„ë¦¬ì§€,
            'risk_level': ë¦¬ìŠ¤í¬ ë ˆë²¨
        }
    """
    base_leverage = 10
    
    # [ì¶”ê°€ë¨] v2.3.0: ì½”ì¸ë³„ ë¦¬ìŠ¤í¬ íŒ©í„° (ë³€ë™ì„± ê¸°ë°˜)
    crypto_risk_factors = {
        'BTC': 1.0,   # ë¹„íŠ¸ì½”ì¸: ê¸°ì¤€ (ê°€ì¥ ì•ˆì •ì )
        'ETH': 1.1,   # ì´ë”ë¦¬ì›€: ì•½ê°„ ë†’ì€ ë³€ë™ì„±
        'BNB': 1.2,   # ë°”ì´ë‚¸ìŠ¤: ì¤‘ê°„ ë³€ë™ì„±
        'XRP': 1.3,   # ë¦¬í”Œ: ë†’ì€ ë³€ë™ì„±
        'ADA': 1.3,   # ì¹´ë¥´ë‹¤ë…¸: ë†’ì€ ë³€ë™ì„±
        'SOL': 1.4,   # ì†”ë¼ë‚˜: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
        'DOGE': 1.5,  # ë„ì§€ì½”ì¸: ê·¹ì‹¬í•œ ë³€ë™ì„±
        'MATIC': 1.4, # í´ë¦¬ê³¤: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
        'DOT': 1.3,   # í´ì¹´ë‹·: ë†’ì€ ë³€ë™ì„±
        'AVAX': 1.4,  # ì•„ë°œë€ì²´: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
    }
    
    # ì½”ì¸ ì´ë¦„ì—ì„œ ê¸°í˜¸ ì¶”ì¶œ (ì˜ˆ: "Bitcoin (BTC)" -> "BTC")
    crypto_symbol = crypto_name
    for symbol in crypto_risk_factors.keys():
        if symbol in crypto_name.upper():
            crypto_symbol = symbol
            break
    
    crypto_factor = crypto_risk_factors.get(crypto_symbol, 1.2)  # ê¸°ë³¸ê°’: ì¤‘ê°„ ë¦¬ìŠ¤í¬
    
    # [ì¶”ê°€ë¨] v2.3.0: íˆ¬ì ê¸ˆì•¡ì— ë”°ë¥¸ ì„¸ë¶„í™”ëœ íŒ©í„°
    # ëŒ€ëŸ‰ íˆ¬ìì â†’ ë¦¬ìŠ¤í¬ ê°ìˆ˜ ëŠ¥ë ¥ ë†’ìŒ â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    # ì†Œì•¡ íˆ¬ìì â†’ ì†ì‹¤ íšŒë³µ ì–´ë ¤ì›€ â†’ ë³´ìˆ˜ì  ë ˆë²„ë¦¬ì§€
    if investment_amount >= 50000:
        investment_factor = 1.3  # ì´ˆëŒ€ëŸ‰ íˆ¬ì â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    elif investment_amount >= 20000:
        investment_factor = 1.2  # ëŒ€ëŸ‰ íˆ¬ì â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    elif investment_amount >= 10000:
        investment_factor = 1.1  # ìƒë‹¹ íˆ¬ì â†’ ì•½ê°„ ì—¬ìœ 
    elif investment_amount >= 5000:
        investment_factor = 1.0  # ê¸°ì¤€
    elif investment_amount >= 2000:
        investment_factor = 0.9  # ì¤‘ê°„ â†’ ì•½ê°„ ì‹ ì¤‘
    elif investment_amount >= 1000:
        investment_factor = 0.8  # ì†Œì•¡ â†’ ì‹ ì¤‘
    else:
        investment_factor = 0.6  # ê·¹ì†Œì•¡ â†’ ë§¤ìš° ë³´ìˆ˜ì 
    
    # ë³€ë™ì„± íŒ©í„°
    if volatility < 0.02:
        volatility_factor = 1.5  # ë‚®ì€ ë³€ë™ì„± â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    elif volatility < 0.05:
        volatility_factor = 1.2  # ì¤‘ê°„ ë³€ë™ì„±
    elif volatility < 0.10:
        volatility_factor = 0.9  # ë†’ì€ ë³€ë™ì„±
    else:
        volatility_factor = 0.7  # ê·¹ì‹¬í•œ ë³€ë™ì„± â†’ ë³´ìˆ˜ì 
    
    confidence_factor = confidence / 100.0
    atr_factor = 1.0 / (atr_ratio + 0.5)
    
    # [ì¶”ê°€ë¨] v2.3.0: ê¶Œì¥ ë ˆë²„ë¦¬ì§€ ê³„ì‚° (ë³´ìˆ˜ì )
    recommended_leverage = base_leverage * investment_factor * volatility_factor * confidence_factor * atr_factor / crypto_factor
    recommended_leverage = max(1.0, min(recommended_leverage, float(max_leverage) * 0.7))  # ìµœëŒ€ ë ˆë²„ë¦¬ì§€ì˜ 70%ê¹Œì§€
    recommended_leverage = round(recommended_leverage, 1)
    
    # [ì¶”ê°€ë¨] v2.3.0: ìµœëŒ€ ë ˆë²„ë¦¬ì§€ ê³„ì‚° (ê³µê²©ì )
    maximum_leverage = recommended_leverage * 1.5  # ê¶Œì¥ì˜ 1.5ë°°
    maximum_leverage = max(recommended_leverage + 1, min(maximum_leverage, float(max_leverage)))
    maximum_leverage = round(maximum_leverage, 1)
    
    # [ì¶”ê°€ë¨] v2.3.0: ë¦¬ìŠ¤í¬ ë ˆë²¨ íŒë‹¨
    risk_score = crypto_factor * volatility * 100
    if risk_score < 3:
        risk_level = "ì¤‘ê°„"
    elif risk_score < 6:
        risk_level = "ì¤‘ê°„"
    else:
        risk_level = "ì¤‘ê°„"
    
    return {
        'recommended': recommended_leverage,
        'maximum': maximum_leverage,
        'risk_level': risk_level
    }





# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 2: ì›Œí¬-í¬ì›Œë“œ ê²€ì¦ (Walk-Forward Validation)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def walk_forward_validation(data, n_splits=5, forecast_horizon=3, seasonal_period=7, seasonal_type='add'):
    """
    ì›Œí¬-í¬ì›Œë“œ ê²€ì¦ (ì‹œê³„ì—´ êµì°¨ ê²€ì¦)
    
    Parameters:
    -----------
    data : pd.Series
        ì‹œê³„ì—´ ë°ì´í„°
    n_splits : int
        ë¶„í•  ê°œìˆ˜ (ê¸°ë³¸ 5)
    forecast_horizon : int
        ì˜ˆì¸¡ ê¸°ê°„ (ê¸°ë³¸ 3)
    seasonal_period : int
        ê³„ì ˆì„± ì£¼ê¸°
    seasonal_type : str
        ê³„ì ˆì„± íƒ€ì… ('add' or 'mul')
    
    Returns:
    --------
    dict : ê²€ì¦ ê²°ê³¼
        - 'scores': ê° í´ë“œë³„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
        - 'mean_score': í‰ê·  ì ìˆ˜
        - 'std_score': í‘œì¤€í¸ì°¨
        - 'direction_accuracy': ë°©í–¥ ì •í™•ë„ ë¦¬ìŠ¤íŠ¸
        - 'mean_direction': í‰ê·  ë°©í–¥ ì •í™•ë„
    """
    from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing
    
    tscv = TimeSeriesSplit(n_splits=n_splits)
    
    mase_scores = []
    direction_accuracies = []
    
    for train_idx, test_idx in tscv.split(data):
        train_data = data.iloc[train_idx]
        test_data = data.iloc[test_idx]
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì˜ˆì¸¡ ê¸°ê°„ë³´ë‹¤ ì‘ìœ¼ë©´ ìŠ¤í‚µ
        if len(test_data) < forecast_horizon:
            continue
        
        # ìµœì‹  500ê°œ ë°ì´í„°ë§Œ ì‚¬ìš© (ì„±ëŠ¥ ìµœì í™”)
        if len(train_data) > 500:
            train_data = train_data[-500:]
        
        try:
            # ê³„ì ˆì„± ëª¨ë¸ ì‹œë„
            if seasonal_period and len(train_data) >= 2 * seasonal_period:
                model = ExponentialSmoothing(
                    train_data,
                    seasonal_periods=seasonal_period,
                    trend='add',
                    seasonal=seasonal_type,
                    initialization_method="estimated"
                )
                fitted = model.fit()
            else:
                # ë¹„ê³„ì ˆ ëª¨ë¸
                model = SimpleExpSmoothing(train_data, initialization_method="estimated")
                fitted = model.fit()
            
            # ì˜ˆì¸¡
            forecast = fitted.forecast(steps=forecast_horizon)
            actual = test_data.iloc[:forecast_horizon]
            
            # MASE ê³„ì‚°
            naive_errors = np.abs(np.diff(train_data))
            scale = np.mean(naive_errors)
            
            if scale > 0:
                errors = np.abs(actual.values - forecast.values)
                mase = np.mean(errors) / scale
                mase_scores.append(mase)
            
            # ë°©í–¥ ì •í™•ë„ ê³„ì‚°
            if len(actual) > 1:
                actual_direction = (actual.values[1:] > actual.values[:-1]).astype(int)
                forecast_direction = (forecast.values[1:] > forecast.values[:-1]).astype(int)
                direction_acc = np.mean(actual_direction == forecast_direction) * 100
                direction_accuracies.append(direction_acc)
        
        except Exception as e:
            continue
    
    if not mase_scores:
        return None
    
    return {
        'scores': mase_scores,
        'mean_score': np.mean(mase_scores),
        'std_score': np.std(mase_scores),
        'direction_accuracy': direction_accuracies,
        'mean_direction': np.mean(direction_accuracies) if direction_accuracies else 0.0
    }


def calculate_brier_score(actual_direction, predicted_probs):
    """
    Brier Score ê³„ì‚° (í™•ë¥  ì˜ˆì¸¡ ì •í™•ë„)
    
    Parameters:
    -----------
    actual_direction : array-like
        ì‹¤ì œ ë°©í–¥ (0: í•˜ë½, 1: ìƒìŠ¹)
    predicted_probs : array-like
        ì˜ˆì¸¡ í™•ë¥  (0~1 ì‚¬ì´)
    
    Returns:
    --------
    float : Brier Score (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, 0~1)
    """
    try:
        score = brier_score_loss(actual_direction, predicted_probs)
        return score
    except Exception as e:
        return None


def calculate_log_loss_score(actual_direction, predicted_probs):
    """
    Log Loss ê³„ì‚° (í™•ë¥  ì˜ˆì¸¡ ì†ì‹¤)
    
    Parameters:
    -----------
    actual_direction : array-like
        ì‹¤ì œ ë°©í–¥ (0: í•˜ë½, 1: ìƒìŠ¹)
    predicted_probs : array-like
        ì˜ˆì¸¡ í™•ë¥  (0~1 ì‚¬ì´)
    
    Returns:
    --------
    float : Log Loss (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    """
    try:
        # í™•ë¥ ì„ 0.01~0.99ë¡œ í´ë¦¬í•‘ (log(0) ë°©ì§€)
        predicted_probs = np.clip(predicted_probs, 0.01, 0.99)
        score = log_loss(actual_direction, predicted_probs)
        return score
    except Exception as e:
        return None


def calculate_direction_metrics(actual, predicted):
    """
    ë°©í–¥ ì˜ˆì¸¡ ë©”íŠ¸ë¦­ ì¢…í•© ê³„ì‚°
    
    Parameters:
    -----------
    actual : array-like
        ì‹¤ì œ ê°€ê²© ì‹œê³„ì—´
    predicted : array-like
        ì˜ˆì¸¡ ê°€ê²© ì‹œê³„ì—´
    
    Returns:
    --------
    dict : ë°©í–¥ ë©”íŠ¸ë¦­
        - 'direction_accuracy': ë°©í–¥ ì •í™•ë„ (%)
        - 'brier_score': Brier Score
        - 'log_loss': Log Loss
        - 'up_accuracy': ìƒìŠ¹ ë°©í–¥ ì •í™•ë„ (%)
        - 'down_accuracy': í•˜ë½ ë°©í–¥ ì •í™•ë„ (%)
    """
    if len(actual) < 2 or len(predicted) < 2:
        return None
    
    # ë°©í–¥ ê³„ì‚° (1: ìƒìŠ¹, 0: í•˜ë½)
    actual_direction = (actual[1:] > actual[:-1]).astype(int)
    predicted_direction = (predicted[1:] > predicted[:-1]).astype(int)
    
    # ë°©í–¥ ì •í™•ë„
    direction_accuracy = np.mean(actual_direction == predicted_direction) * 100
    
    # í™•ë¥  ê³„ì‚° (ì˜ˆì¸¡ê°’ì˜ ë³€í™”ìœ¨ì„ ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜)
    predicted_change_rate = (predicted[1:] - predicted[:-1]) / (predicted[:-1] + 1e-10)
    predicted_probs = 1 / (1 + np.exp(-predicted_change_rate * 10))  # ì‹œê·¸ëª¨ì´ë“œ
    
    # Brier Score & Log Loss
    brier = calculate_brier_score(actual_direction, predicted_probs)
    logloss = calculate_log_loss_score(actual_direction, predicted_probs)
    
    # ìƒìŠ¹/í•˜ë½ ë³„ ì •í™•ë„
    up_mask = (actual_direction == 1)
    down_mask = (actual_direction == 0)
    
    up_accuracy = (
        np.mean(predicted_direction[up_mask] == 1) * 100 
        if np.sum(up_mask) > 0 else 0.0
    )
    down_accuracy = (
        np.mean(predicted_direction[down_mask] == 0) * 100 
        if np.sum(down_mask) > 0 else 0.0
    )
    
    return {
        'direction_accuracy': direction_accuracy,
        'brier_score': brier,
        'log_loss': logloss,
        'up_accuracy': up_accuracy,
        'down_accuracy': down_accuracy
    }




# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.5.0: ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. N-BEATS ëª¨ë¸ (Neural Basis Expansion Analysis for Time Series)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class NBeatsBlock(nn.Module):
    """N-BEATSì˜ ê¸°ë³¸ ë¸”ë¡"""
    def __init__(self, input_size, theta_size, hidden_size=256):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, hidden_size)
        self.fc4 = nn.Linear(hidden_size, hidden_size)
        
        # Backcast and Forecast heads
        self.backcast_fc = nn.Linear(hidden_size, input_size)
        self.forecast_fc = nn.Linear(hidden_size, theta_size)
        
    def forward(self, x):
        h = torch.relu(self.fc1(x))
        h = torch.relu(self.fc2(h))
        h = torch.relu(self.fc3(h))
        h = torch.relu(self.fc4(h))
        
        backcast = self.backcast_fc(h)
        forecast = self.forecast_fc(h)
        
        return backcast, forecast


class NBeatsModel(nn.Module):
    """N-BEATS ì „ì²´ ëª¨ë¸"""
    def __init__(self, input_size, forecast_size, num_blocks=3, hidden_size=256):
        super().__init__()
        self.blocks = nn.ModuleList([
            NBeatsBlock(input_size, forecast_size, hidden_size)
            for _ in range(num_blocks)
        ])
        
    def forward(self, x):
        residuals = x
        forecast = torch.zeros(x.size(0), self.blocks[0].forecast_fc.out_features).to(x.device)
        
        for block in self.blocks:
            backcast, block_forecast = block(residuals)
            residuals = residuals - backcast
            forecast = forecast + block_forecast
        
        return forecast


def train_nbeats(data, forecast_days=3, lookback=180, epochs=50):
    """N-BEATS ëª¨ë¸ í•™ìŠµ"""
    if not TORCH_AVAILABLE:
        return None, None
    
    # ë°ì´í„° ì •ê·œí™”
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data.values.reshape(-1, 1)).flatten()
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(scaled_data) - forecast_days):
        X.append(scaled_data[i-lookback:i])
        y.append(scaled_data[i:i+forecast_days])
    
    if len(X) < 10:
        return None, scaler
    
    X = torch.FloatTensor(X)
    y = torch.FloatTensor(y)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = NBeatsModel(lookback, forecast_days, num_blocks=3, hidden_size=128)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # í•™ìŠµ
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        output = model(X)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()
    
    model.eval()
    return model, scaler


def predict_nbeats(model, scaler, last_sequence, forecast_days=3):
    """N-BEATS ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence.reshape(-1, 1)).flatten()
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        forecast_original = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. TFT (Temporal Fusion Transformer) - ê°„ì†Œí™” ë²„ì „
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SimpleTFT(nn.Module):
    """ê°„ì†Œí™”ëœ TFT ëª¨ë¸ (í•µì‹¬ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜)"""
    def __init__(self, input_size, hidden_size=128, num_heads=4, forecast_size=3):
        super().__init__()
        self.embedding = nn.Linear(input_size, hidden_size)
        self.attention = nn.MultiheadAttention(hidden_size, num_heads, batch_first=True)
        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, forecast_size)
        
    def forward(self, x):
        # x shape: (batch, seq_len, features)
        embedded = self.embedding(x)
        
        # Self-attention
        attn_out, _ = self.attention(embedded, embedded, embedded)
        
        # LSTM
        lstm_out, _ = self.lstm(attn_out)
        
        # Take last timestep
        last_output = lstm_out[:, -1, :]
        
        # Forecast
        forecast = self.fc(last_output)
        
        return forecast


def train_tft(data, features_df, forecast_days=3, lookback=90, epochs=50):
    """TFT ëª¨ë¸ í•™ìŠµ (ë‹¤ë³€ëŸ‰)"""
    if not TORCH_AVAILABLE:
        return None, None
    
    # ê°€ê²© + ì§€í‘œ ê²°í•©
    combined_data = features_df[['Close', 'RSI14', 'MACD', 'Volume']].iloc[-len(data):].values
    
    # ì •ê·œí™”
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(combined_data)
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(scaled_data) - forecast_days):
        X.append(scaled_data[i-lookback:i])
        y.append(scaled_data[i:i+forecast_days, 0])  # Closeë§Œ ì˜ˆì¸¡
    
    if len(X) < 10:
        return None, scaler
    
    X = torch.FloatTensor(X)
    y = torch.FloatTensor(y)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = SimpleTFT(input_size=combined_data.shape[1], hidden_size=64, 
                      num_heads=4, forecast_size=forecast_days)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # í•™ìŠµ
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        output = model(X)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()
    
    model.eval()
    return model, scaler


def predict_tft(model, scaler, last_sequence, forecast_days=3):
    """TFT ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence)
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        
        # ì—­ë³€í™˜ (Closeë§Œ)
        dummy = np.zeros((forecast.shape[0], scaler.n_features_in_))
        dummy[:, 0] = forecast
        forecast_original = scaler.inverse_transform(dummy)[:, 0]
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. XGBoost
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_xgboost(data, features_df, forecast_days=3, lookback=60):
    """XGBoost ëª¨ë¸ í•™ìŠµ"""
    if not XGBOOST_AVAILABLE:
        return None, None
    
    # íŠ¹ì§• ì„ íƒ (ê¸°ìˆ ì  ì§€í‘œ)
    feature_cols = ['RSI14', 'MACD', 'StochK14', 'MFI14', 'ATR14']
    X_features = features_df[feature_cols].iloc[-len(data):].values
    
    # ì‹œê³„ì—´ íŠ¹ì§• ì¶”ê°€ (ê³¼ê±° ê°€ê²©)
    X, y = [], []
    for i in range(lookback, len(data) - forecast_days):
        past_prices = data.iloc[i-lookback:i].values
        past_features = X_features[i-lookback:i].mean(axis=0)  # í‰ê·  ì§€í‘œ
        X.append(np.concatenate([past_prices[-10:], past_features]))  # ìµœê·¼ 10ê°œ ê°€ê²© + ì§€í‘œ
        y.append(data.iloc[i+forecast_days-1])  # forecast_days í›„ ê°€ê²©
    
    if len(X) < 10:
        return None, None
    
    X = np.array(X)
    y = np.array(y)
    
    # XGBoost í•™ìŠµ
    model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
    model.fit(X, y)
    
    return model, (lookback, feature_cols)


def predict_xgboost(model, metadata, data, features_df, forecast_days=3):
    """XGBoost ì˜ˆì¸¡"""
    if model is None or not XGBOOST_AVAILABLE:
        return None
    
    lookback, feature_cols = metadata
    X_features = features_df[feature_cols].values
    
    # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤
    past_prices = data.iloc[-lookback:].values
    past_features = X_features[-lookback:].mean(axis=0)
    X_pred = np.concatenate([past_prices[-10:], past_features]).reshape(1, -1)
    
    forecast = model.predict(X_pred)
    
    # ë°˜ë³µ ì˜ˆì¸¡ (ë‹¨ì¼ ìŠ¤í…ì”©)
    forecasts = [forecast[0]]
    for _ in range(1, forecast_days):
        # ì´ì „ ì˜ˆì¸¡ì„ í¬í•¨í•˜ì—¬ ë‹¤ìŒ ì˜ˆì¸¡
        new_prices = np.append(past_prices[1-10:], forecasts[-1])
        X_pred = np.concatenate([new_prices, past_features]).reshape(1, -1)
        forecasts.append(model.predict(X_pred)[0])
    
    return np.array(forecasts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. GRU (Gated Recurrent Unit)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class GRUModel(nn.Module):
    """GRU ëª¨ë¸"""
    def __init__(self, input_size=1, hidden_size=64, num_layers=2, forecast_size=3):
        super().__init__()
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_size, forecast_size)
        
    def forward(self, x):
        out, _ = self.gru(x)
        out = self.fc(out[:, -1, :])
        return out


def train_gru(data, forecast_days=3, lookback=120, epochs=50):
    """GRU ëª¨ë¸ í•™ìŠµ"""
    if not TORCH_AVAILABLE:
        return None, None
    
    # ë°ì´í„° ì •ê·œí™”
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data.values.reshape(-1, 1))
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(scaled_data) - forecast_days):
        X.append(scaled_data[i-lookback:i])
        y.append(scaled_data[i:i+forecast_days].flatten())
    
    if len(X) < 10:
        return None, scaler
    
    X = torch.FloatTensor(X)
    y = torch.FloatTensor(y)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = GRUModel(input_size=1, hidden_size=64, num_layers=2, forecast_size=forecast_days)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # í•™ìŠµ
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        output = model(X)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()
    
    model.eval()
    return model, scaler


def predict_gru(model, scaler, last_sequence, forecast_days=3):
    """GRU ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence.reshape(-1, 1))
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        forecast_original = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. LightGBM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_lightgbm(data, features_df, forecast_days=3, lookback=60):
    """LightGBM ëª¨ë¸ í•™ìŠµ"""
    if not LIGHTGBM_AVAILABLE:
        return None, None
    
    # íŠ¹ì§• ì„ íƒ
    feature_cols = ['RSI14', 'MACD', 'StochK14', 'MFI14', 'ATR14', 'BB_upper', 'BB_lower']
    X_features = features_df[feature_cols].iloc[-len(data):].values
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(data) - forecast_days):
        past_prices = data.iloc[i-lookback:i].values
        past_features = X_features[i-lookback:i].mean(axis=0)
        X.append(np.concatenate([past_prices[-10:], past_features]))
        y.append(data.iloc[i+forecast_days-1])
    
    if len(X) < 10:
        return None, None
    
    X = np.array(X)
    y = np.array(y)
    
    # LightGBM í•™ìŠµ
    model = lgb.LGBMRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42,
        verbose=-1
    )
    model.fit(X, y)
    
    return model, (lookback, feature_cols)


def predict_lightgbm(model, metadata, data, features_df, forecast_days=3):
    """LightGBM ì˜ˆì¸¡"""
    if model is None or not LIGHTGBM_AVAILABLE:
        return None
    
    lookback, feature_cols = metadata
    X_features = features_df[feature_cols].values
    
    # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤
    past_prices = data.iloc[-lookback:].values
    past_features = X_features[-lookback:].mean(axis=0)
    X_pred = np.concatenate([past_prices[-10:], past_features]).reshape(1, -1)
    
    forecasts = [model.predict(X_pred)[0]]
    for _ in range(1, forecast_days):
        new_prices = np.append(past_prices[1-10:], forecasts[-1])
        X_pred = np.concatenate([new_prices, past_features]).reshape(1, -1)
        forecasts.append(model.predict(X_pred)[0])
    
    return np.array(forecasts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Prophet (ê°„ë‹¨í•œ ë˜í¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_prophet(data, forecast_days=3):
    """Prophet ëª¨ë¸ í•™ìŠµ"""
    if not PROPHET_AVAILABLE:
        return None
    
    # Prophet í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    df_prophet = pd.DataFrame({
        'ds': data.index,
        'y': data.values
    })
    
    model = Prophet(
        daily_seasonality=True,
        weekly_seasonality=True,
        yearly_seasonality=False,
        changepoint_prior_scale=0.05
    )
    
    model.fit(df_prophet)
    
    return model


def predict_prophet(model, forecast_days=3):
    """Prophet ì˜ˆì¸¡"""
    if model is None or not PROPHET_AVAILABLE:
        return None
    
    future = model.make_future_dataframe(periods=forecast_days)
    forecast = model.predict(future)
    
    return forecast['yhat'].iloc[-forecast_days:].values


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. LSTM (ê¸°ì¡´ë³´ë‹¤ ê°•í™”ëœ ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LSTMModel(nn.Module):
    """LSTM ëª¨ë¸"""
    def __init__(self, input_size=1, hidden_size=128, num_layers=3, forecast_size=3):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.fc = nn.Linear(hidden_size, forecast_size)
        
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out


def train_lstm(data, forecast_days=3, lookback=120, epochs=50):
    """LSTM ëª¨ë¸ í•™ìŠµ"""
    if not TORCH_AVAILABLE:
        return None, None
    
    # ë°ì´í„° ì •ê·œí™”
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data.values.reshape(-1, 1))
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(scaled_data) - forecast_days):
        X.append(scaled_data[i-lookback:i])
        y.append(scaled_data[i:i+forecast_days].flatten())
    
    if len(X) < 10:
        return None, scaler
    
    X = torch.FloatTensor(X)
    y = torch.FloatTensor(y)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    model = LSTMModel(input_size=1, hidden_size=128, num_layers=3, forecast_size=forecast_days)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # í•™ìŠµ
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        output = model(X)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()
    
    model.eval()
    return model, scaler


def predict_lstm(model, scaler, last_sequence, forecast_days=3):
    """LSTM ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence.reshape(-1, 1))
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        forecast_original = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. ì•™ìƒë¸” ì¡°í•© ë° ìë™ ì„ íƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_ensemble_config(interval):
    """
    ì‹œê°„ í”„ë ˆì„ì— ë”°ë¥¸ ì•™ìƒë¸” ëª¨ë¸ ìë™ ì„ íƒ
    
    Parameters:
    -----------
    interval : str
        ì‹œê°„ í”„ë ˆì„ ('1m', '5m', '1h', '1d')
    
    Returns:
    --------
    dict : ì•™ìƒë¸” ì„¤ì •
        - 'models': ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
        - 'weights': ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜
        - 'lookback': í•™ìŠµ ìœˆë„ìš° í¬ê¸°
        - 'epochs': í•™ìŠµ ì—í­ ìˆ˜
    """
    if interval in ['1m', '5m']:
        # ì´ˆë‹¨íƒ€ íŠ¸ë ˆì´ë”©: N-BEATS + TFT + XGBoost
        return {
            'models': ['nbeats', 'tft', 'xgboost'],
            'weights': [0.40, 0.35, 0.25],
            'lookback': {'nbeats': 180, 'tft': 90, 'xgboost': 60},
            'epochs': 30,
            'description': 'ì´ˆë‹¨íƒ€ íŠ¸ë ˆì´ë”© (N-BEATS 40% + TFT 35% + XGBoost 25%)'
        }
    elif interval == '1h':
        # ë‹¨ê¸° íŠ¸ë ˆì´ë”© ìƒë‹¨: N-BEATS + TFT + XGBoost (ì‹œê°„ë´‰ë„ ë¹ ë¥¸ í¸)
        return {
            'models': ['nbeats', 'tft', 'xgboost'],
            'weights': [0.40, 0.35, 0.25],
            'lookback': {'nbeats': 240, 'tft': 120, 'xgboost': 90},
            'epochs': 40,
            'description': 'ì‹œê°„ë´‰ íŠ¸ë ˆì´ë”© (N-BEATS 40% + TFT 35% + XGBoost 25%)'
        }
    elif interval == '1d':
        # ë‹¨ê¸° íŠ¸ë ˆì´ë”©: LightGBM + GRU + Prophet
        return {
            'models': ['gru', 'lightgbm', 'prophet'],
            'weights': [0.40, 0.35, 0.25],
            'lookback': {'gru': 120, 'lightgbm': 60, 'prophet': None},
            'epochs': 50,
            'description': 'ì¼ë´‰ íŠ¸ë ˆì´ë”© (GRU 40% + LightGBM 35% + Prophet 25%)'
        }
    else:
        # ì¤‘ê¸° íŠ¸ë ˆì´ë”© (ì£¼ë´‰ ì´ìƒ): XGBoost + LSTM + Holt-Winters
        return {
            'models': ['lstm', 'xgboost', 'holtwinters'],
            'weights': [0.45, 0.30, 0.25],
            'lookback': {'lstm': 150, 'xgboost': 90, 'holtwinters': None},
            'epochs': 50,
            'description': 'ì¤‘ê¸° íŠ¸ë ˆì´ë”© (LSTM 45% + XGBoost 30% + Holt-Winters 25%)'
        }


def train_ensemble_models(data, features_df, interval, forecast_days=3):
    """
    ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
    
    Parameters:
    -----------
    data : pd.Series
        ê°€ê²© ë°ì´í„°
    features_df : pd.DataFrame
        ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„°
    interval : str
        ì‹œê°„ í”„ë ˆì„
    forecast_days : int
        ì˜ˆì¸¡ ì¼ìˆ˜
    
    Returns:
    --------
    dict : í•™ìŠµëœ ëª¨ë¸ë“¤ê³¼ ë©”íƒ€ë°ì´í„°
    """
    config = get_ensemble_config(interval)
    models = {}
    
    st.info(f"ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ ì„ íƒ: {config['description']}")
    
    progress_bar = st.progress(0)
    total_models = len(config['models'])
    
    for idx, model_name in enumerate(config['models']):
        try:
            lookback = config['lookback'].get(model_name, 90)
            epochs = config['epochs']
            
            st.text(f"í•™ìŠµ ì¤‘: {model_name.upper()} ({idx+1}/{total_models})")
            
            if model_name == 'nbeats':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_nbeats(data, forecast_days, lookback, epochs)
                    models['nbeats'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'tft':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_tft(data, features_df, forecast_days, lookback, epochs)
                    models['tft'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'xgboost':
                if not XGBOOST_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: XGBoost ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, metadata = train_xgboost(data, features_df, forecast_days, lookback)
                    models['xgboost'] = {'model': model, 'metadata': metadata}
            
            elif model_name == 'gru':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_gru(data, forecast_days, lookback, epochs)
                    models['gru'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'lightgbm':
                if not LIGHTGBM_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶€0ê°€: LightGBM ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, metadata = train_lightgbm(data, features_df, forecast_days, lookback)
                    models['lightgbm'] = {'model': model, 'metadata': metadata}
            
            elif model_name == 'prophet':
                if not PROPHET_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶€0ê°€: Prophet ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model = train_prophet(data, forecast_days)
                    models['prophet'] = {'model': model}
            
            elif model_name == 'lstm':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶€0ê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_lstm(data, forecast_days, lookback, epochs)
                    models['lstm'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'holtwinters':
                # Holt-WintersëŠ” ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©
                hw_model, seasonality_info, window_size = fit_hw_model_robust(data, max_window=500)
                models['holtwinters'] = {'model': hw_model, 'seasonality': seasonality_info}
            
            progress_bar.progress((idx + 1) / total_models)
        
        except Exception as e:
            st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨: {e}")
            models[model_name] = None
    
    progress_bar.empty()
    
    return models, config


def predict_ensemble(models, config, data, features_df, forecast_days=3):
    """
    ì•™ìƒë¸” ì˜ˆì¸¡
    
    Parameters:
    -----------
    models : dict
        í•™ìŠµëœ ëª¨ë¸ë“¤
    config : dict
        ì•™ìƒë¸” ì„¤ì •
    data : pd.Series
        ê°€ê²© ë°ì´í„°
    features_df : pd.DataFrame
        ê¸°ìˆ ì  ì§€í‘œ
    forecast_days : int
        ì˜ˆì¸¡ ì¼ìˆ˜
    
    Returns:
    --------
    np.array : ì•™ìƒë¸” ì˜ˆì¸¡ê°’
    dict : ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’
    """
    predictions = {}
    weights = {}
    
    for model_name, weight in zip(config['models'], config['weights']):
        if models.get(model_name) is None:
            continue
        
        try:
            model_data = models[model_name]
            lookback = config['lookback'].get(model_name, 90)
            
            if model_name == 'nbeats':
                pred = predict_nbeats(
                    model_data['model'], 
                    model_data['scaler'], 
                    data.iloc[-lookback:].values, 
                    forecast_days
                )
            
            elif model_name == 'tft':
                last_features = features_df[['Close', 'RSI14', 'MACD', 'Volume']].iloc[-lookback:].values
                pred = predict_tft(
                    model_data['model'], 
                    model_data['scaler'], 
                    last_features, 
                    forecast_days
                )
            
            elif model_name == 'xgboost':
                pred = predict_xgboost(
                    model_data['model'], 
                    model_data['metadata'], 
                    data, 
                    features_df, 
                    forecast_days
                )
            
            elif model_name == 'gru':
                pred = predict_gru(
                    model_data['model'], 
                    model_data['scaler'], 
                    data.iloc[-lookback:].values, 
                    forecast_days
                )
            
            elif model_name == 'lightgbm':
                pred = predict_lightgbm(
                    model_data['model'], 
                    model_data['metadata'], 
                    data, 
                    features_df, 
                    forecast_days
                )
            
            elif model_name == 'prophet':
                pred = predict_prophet(model_data['model'], forecast_days)
            
            elif model_name == 'lstm':
                pred = predict_lstm(
                    model_data['model'], 
                    model_data['scaler'], 
                    data.iloc[-lookback:].values, 
                    forecast_days
                )
            
            elif model_name == 'holtwinters':
                hw_forecast = model_data['model'].forecast(steps=forecast_days)
                pred = hw_forecast.values
            
            if pred is not None and len(pred) == forecast_days:
                predictions[model_name] = pred
                weights[model_name] = weight
        
        except Exception as e:
            st.warning(f"âš ï¸ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    # ê°€ì¤‘ í‰ê· 
    if not predictions:
        return None, {}
    
    # ê°€ì¤‘ì¹˜ ì •ê·œí™”
    total_weight = sum(weights.values())
    normalized_weights = {k: v/total_weight for k, v in weights.items()}
    
    # ì•™ìƒë¸” ì˜ˆì¸¡
    ensemble_forecast = np.zeros(forecast_days)
    for model_name, pred in predictions.items():
        ensemble_forecast += pred * normalized_weights[model_name]
    
    return ensemble_forecast, predictions


def detect_seasonality_auto(series: pd.Series, max_period: int = 30) -> tuple:
    """
    ìë™ ê³„ì ˆì„± ê°ì§€ (v2.4.0)
    
    Returns:
        tuple: (has_seasonality: bool, optimal_period: int, seasonality_type: str)
    """
    from scipy import stats
    
    if len(series) < 20:
        return False, None, None
    
    # 1. ACF ê¸°ë°˜ ê³„ì ˆì„± ê°ì§€
    try:
        from statsmodels.tsa.stattools import acf
        acf_values = acf(series, nlags=min(max_period, len(series) // 2), fft=True)
        
        # ACF í”¼í¬ ì°¾ê¸° (ì²« ë²ˆì§¸ ì§€ì—° ì œì™¸)
        peaks = []
        for i in range(2, len(acf_values)):
            if acf_values[i] > 0.3:  # ì„ê³„ê°’
                peaks.append((i, acf_values[i]))
        
        if peaks:
            # ê°€ì¥ ê°•í•œ í”¼í¬ ì„ íƒ
            optimal_period = max(peaks, key=lambda x: x[1])[0]
            has_seasonality = True
        else:
            has_seasonality = False
            optimal_period = None
    except:
        has_seasonality = False
        optimal_period = None
    
    # 2. ë³€ë™ì„± ê¸°ë°˜ ê³„ì ˆì„± íƒ€ì… ê²°ì •
    if has_seasonality:
        volatility = series.pct_change().std()
        if volatility > 0.05:
            seasonality_type = 'mul'  # ë³€ë™ì„± ë†’ìœ¼ë©´ multiplicative
        else:
            seasonality_type = 'add'  # ë³€ë™ì„± ë‚®ìœ¼ë©´ additive
    else:
        seasonality_type = None
    
    return has_seasonality, optimal_period, seasonality_type


def fit_hw_model_robust(series: pd.Series, max_window: int = 500) -> tuple:
    """
    ê°•ê±´í•œ Holt-Winters ëª¨ë¸ í•™ìŠµ (v2.4.0)
    
    Features:
    - ìë™ ê³„ì ˆì„± ê°ì§€
    - ìµœì‹  ìœˆë„ìš° ì œí•œ (ì„±ëŠ¥ ê°œì„ )
    - í´ë°± ì „ëµ
    
    Returns:
        tuple: (model, seasonality_info: dict, training_window_size: int)
    """
    import statsmodels.api as sm
    
    # ìµœì‹  ë°ì´í„°ë§Œ ì‚¬ìš© (ì„±ëŠ¥ ê°œì„ )
    if len(series) > max_window:
        series_windowed = series.iloc[-max_window:]
        original_index = series.index
        window_used = max_window
    else:
        series_windowed = series
        original_index = series.index
        window_used = len(series)
    
    # ê³„ì ˆì„± ìë™ ê°ì§€
    has_seasonality, optimal_period, seasonality_type = detect_seasonality_auto(
        series_windowed, 
        max_period=min(30, len(series_windowed) // 3)
    )
    
    seasonality_info = {
        'detected': has_seasonality,
        'period': optimal_period,
        'type': seasonality_type,
        'window_size': window_used
    }
    
    # ëª¨ë¸ í•™ìŠµ (ê³„ì¸µì  í´ë°±)
    model = None
    error_log = []
    
    # Try 1: ê°ì§€ëœ ê³„ì ˆì„± ì‚¬ìš©
    if has_seasonality and optimal_period and optimal_period >= 2:
        try:
            model = sm.tsa.ExponentialSmoothing(
                series_windowed,
                trend='add',
                seasonal=seasonality_type,
                seasonal_periods=optimal_period,
                initialization_method="estimated"
            ).fit(optimized=True)
            seasonality_info['model_type'] = f'{seasonality_type}_seasonal'
            return model, seasonality_info, window_used
        except Exception as e:
            error_log.append(f"Seasonal model failed: {str(e)[:50]}")
    
    # Try 2: ë‹¨ìˆœ ê³„ì ˆì„± (period=7)
    if len(series_windowed) >= 14:
        try:
            model = sm.tsa.ExponentialSmoothing(
                series_windowed,
                trend='add',
                seasonal='add',
                seasonal_periods=7,
                initialization_method="estimated"
            ).fit(optimized=True)
            seasonality_info['model_type'] = 'default_seasonal'
            seasonality_info['period'] = 7
            return model, seasonality_info, window_used
        except Exception as e:
            error_log.append(f"Default seasonal failed: {str(e)[:50]}")
    
    # Try 3: ë¹„ê³„ì ˆ ëª¨ë¸ (í´ë°±)
    try:
        model = sm.tsa.ExponentialSmoothing(
            series_windowed,
            trend='add',
            seasonal=None,
            initialization_method="estimated"
        ).fit(optimized=True)
        seasonality_info['model_type'] = 'non_seasonal'
        seasonality_info['detected'] = False
        return model, seasonality_info, window_used
    except Exception as e:
        error_log.append(f"Non-seasonal failed: {str(e)[:50]}")
    
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
    raise ValueError(f"All model fitting attempts failed: {'; '.join(error_log)}")


def forecast_with_offset_scaling(model, steps: int, last_actual_value: float, 
                                  recent_trend: float) -> np.ndarray:
    """
    ì˜¤í”„ì…‹ ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡ (v2.4.0)
    
    ì ˆëŒ€ê°€ê²© ëŒ€ì‹  ì°¨ë¶„(difference) ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í•˜ì—¬ í•˜ë½ ì¶”ì„¸ ë³´ì •
    
    Args:
        model: í•™ìŠµëœ HW ëª¨ë¸
        steps: ì˜ˆì¸¡ ìŠ¤í… ìˆ˜
        last_actual_value: ë§ˆì§€ë§‰ ì‹¤ì œ ê°€ê²©
        recent_trend: ìµœê·¼ ì¶”ì„¸ (ì´ë™í‰ê·  ê¸°ìš¸ê¸°)
    
    Returns:
        np.ndarray: ë³´ì •ëœ ì˜ˆì¸¡ê°’
    """
    # ëª¨ë¸ ì˜ˆì¸¡ (ì°¨ë¶„ ê³µê°„)
    raw_forecast = model.forecast(steps=steps)
    
    # ì˜¤í”„ì…‹ ë³´ì •
    # 1. ì²« ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ ê³„ì‚°
    offset = last_actual_value - raw_forecast.iloc[0]
    
    # 2. ì¶”ì„¸ ë³´ì • (ìµœê·¼ ì¶”ì„¸ ë°˜ì˜)
    trend_correction = np.linspace(0, recent_trend * steps, steps)
    
    # 3. ìµœì¢… ì˜ˆì¸¡ê°’ = ì›ë³¸ ì˜ˆì¸¡ + ì˜¤í”„ì…‹ + ì¶”ì„¸ ë³´ì •
    corrected_forecast = raw_forecast + offset + trend_correction
    
    return corrected_forecast




def perform_timeseries_cv(df: pd.DataFrame, n_splits: int = 5) -> pd.DataFrame:
    """TimeSeriesSplit ê²€ì¦"""
    if len(df) < n_splits * 10:
        return pd.DataFrame({
            'Fold': [1],
            'Accuracy': ['N/A (ë°ì´í„° ë¶€ì¡±)'],
            'MASE': ['N/A'],
            'Mean_Error': ['N/A'],
            'Train_Size': [len(df)],
            'Test_Size': [0]
        })
    
    tscv = TimeSeriesSplit(n_splits=n_splits)
    results = []
    
    close_values = df['Close'].values
    
    for fold, (train_idx, test_idx) in enumerate(tscv.split(close_values), 1):
        train_data = close_values[train_idx]
        test_data = close_values[test_idx]
        
        if len(train_data) < 20:
            results.append({
                'Fold': fold,
                'Accuracy': 'N/A',
                'MASE': 'N/A',
                'Mean_Error': 'N/A',
                'Train_Size': len(train_data),
                'Test_Size': len(test_data)
            })
            continue
        
        try:
            seasonal_periods = min(7, len(train_data) // 3)
            
            if seasonal_periods >= 2:
                hw_model = sm.tsa.ExponentialSmoothing(
                    train_data,
                    trend='add',
                    seasonal='add',
                    seasonal_periods=seasonal_periods,
                    initialization_method="estimated"
                ).fit(optimized=True)
            else:
                hw_model = sm.tsa.ExponentialSmoothing(
                    train_data,
                    trend='add',
                    seasonal=None,
                    initialization_method="estimated"
                ).fit(optimized=True)
            
            forecast = hw_model.forecast(steps=len(test_data))
            
            if len(test_data) > 1:
                actual_direction = np.sign(np.diff(test_data))
                pred_direction = np.sign(np.diff(forecast))
                accuracy = (actual_direction == pred_direction).mean() * 100
            else:
                accuracy = 0.0
            
            mase = calculate_mase(test_data[1:], forecast[1:], train_data)
            mean_error = np.abs(test_data - forecast).mean()
            
            results.append({
                'Fold': fold,
                'Accuracy': f"{accuracy:.2f}%",
                'MASE': f"{mase:.4f}",
                'Mean_Error': f"${mean_error:.2f}",
                'Train_Size': len(train_data),
                'Test_Size': len(test_data)
            })
        except Exception as e:
            results.append({
                'Fold': fold,
                'Accuracy': 'N/A',
                'MASE': 'N/A',
                'Mean_Error': 'N/A',
                'Train_Size': len(train_data),
                'Test_Size': len(test_data)
            })
    
    return pd.DataFrame(results)


def calculate_mase(actual, forecast, train_data):
    """MASE ê³„ì‚°"""
    try:
        mae = np.mean(np.abs(actual - forecast))
        naive_mae = np.mean(np.abs(np.diff(train_data)))
        if naive_mae == 0:
            return 999.0
        mase = mae / naive_mae
        return mase
    except:
        return 999.0


def calculate_rr_ratio(entry_price: float, take_profit: float, stop_loss: float) -> float:
    """Risk-Reward Ratio ê³„ì‚°"""
    reward = abs(take_profit - entry_price)
    risk = abs(entry_price - stop_loss)
    
    if risk == 0:
        return 999.0
    
    return reward / risk


def render_progress_bar(step: int, total: int = 6):
    """ì§„í–‰ ìƒíƒœ"""
    steps = ['ë°ì´í„° ë¡œë“œ', 'ì§€í‘œ ê³„ì‚°', 'AI í•™ìŠµ', 'íŒ¨í„´ ë¶„ì„', 'ê²€ì¦', 'ê²°ê³¼ ìƒì„±']
    progress_html = '<div style="margin: 20px 0;">'
    for i, step_name in enumerate(steps[:total], 1):
        if i <= step:
            progress_html += f'<span class="progress-step active">{i}. {step_name}</span>'
        else:
            progress_html += f'<span class="progress-step">{i}. {step_name}</span>'
    progress_html += '</div>'
    return progress_html


def render_data_summary(df: pd.DataFrame, selected_crypto: str, interval_name: str):
    """ë°ì´í„° ìš”ì•½"""
    st.markdown("<div class='section-title'>ğŸ“Š ë°ì´í„° ê°œìš”</div>", unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    current_price = df['Close'].iloc[-1]
    daily_change = df['ì¼ì¼ìˆ˜ìµë¥ '].iloc[-1] * 100
    avg_volume = df['Volume'].mean()
    total_periods = len(df)
    
    with col1:
        st.metric(
            label=f"í˜„ì¬ê°€ (USD)",
            value=f"${current_price:,.2f}",
            delta=f"{daily_change:+.2f}%"
        )
    
    with col2:
        period_text = f"{total_periods} ê¸°ê°„"
        st.metric(
            label=f"ë¶„ì„ ê¸°ê°„ ({interval_name})",
            value=period_text
        )
    
    with col3:
        st.metric(
            label="í‰ê·  ê±°ë˜ëŸ‰",
            value=f"{avg_volume:,.0f}"
        )
    
    with col4:
        volatility = df['Volatility30d'].iloc[-1] * 100
        st.metric(
            label="ë³€ë™ì„± (30ê¸°ê°„)",
            value=f"{volatility:.2f}%"
        )


def render_ai_forecast(future_df: pd.DataFrame, hw_confidence: float):
    """AI ì˜ˆì¸¡"""
    st.markdown("<div class='section-title'>ğŸ¤– AI ì˜ˆì¸¡ (Holt-Winters Seasonal)</div>", unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=future_df.index,
            y=future_df['ì˜ˆì¸¡ ì¢…ê°€'],
            mode='lines+markers',
            name='ì˜ˆì¸¡ ì¢…ê°€',
            line=dict(color='#667EEA', width=3),
            marker=dict(size=8)
        ))
        
        fig.update_layout(
            title="í–¥í›„ 30ì¼ ì˜ˆì¸¡",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ì˜ˆì¸¡ ê°€ê²© (USD)",
            template="plotly_white",
            height=400,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ“ˆ ì˜ˆì¸¡ ìš”ì•½")
        st.metric(
            label="30ì¼ í›„ ì˜ˆìƒê°€",
            value=f"${future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[-1]:,.2f}",
            delta=f"{((future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[-1] / future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[0]) - 1) * 100:+.2f}%"
        )
        
        st.metric(
            label="ëª¨ë¸ ì‹ ë¢°ë„",
            value=f"{hw_confidence:.1f}%"
        )
        
        predicted_change = ((future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[-1] / future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[0]) - 1) * 100
        
        if predicted_change > 5:
            st.success("ğŸš€ ê°•í•œ ìƒìŠ¹ ì˜ˆìƒ")
        elif predicted_change > 0:
            st.info("ğŸ“ˆ ì†Œí­ ìƒìŠ¹ ì˜ˆìƒ")
        elif predicted_change > -5:
            st.warning("ğŸ“‰ ì†Œí­ í•˜ë½ ì˜ˆìƒ")
        else:
            st.error("âš ï¸ ê°•í•œ í•˜ë½ ì˜ˆìƒ")


def render_patterns(patterns: list):
    """íŒ¨í„´ ë¶„ì„ (ê°œì„ ëœ ë ˆì´ì•„ì›ƒ)"""
    st.markdown("<div class='section-title'>ğŸ•¯ï¸ ìº”ë“¤ìŠ¤í‹± íŒ¨í„´</div>", unsafe_allow_html=True)
    
    if not patterns:
        st.info("ìµœê·¼ ì£¼ìš” íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # íŒ¨í„´ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    categories = {}
    for pattern in patterns:
        cat = pattern.get('category', 'ê¸°íƒ€')
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(pattern)
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    st.markdown(f"**ì´ {len(patterns)}ê°œ íŒ¨í„´ ê°ì§€** | ì¹´í…Œê³ ë¦¬: {', '.join([f'{k}({len(v)})' for k, v in categories.items()])}")
    
    for pattern in patterns:
        with st.container():
            date_str = pattern['date'].strftime('%Y-%m-%d %H:%M') if hasattr(pattern['date'], 'strftime') else str(pattern['date'])
            
            st.markdown(f"""
                <div class='pattern-card'>
                    <div class='pattern-title'>{pattern['name']} [{pattern.get('category', 'ê¸°íƒ€')}]</div>
                    <table style='width: 100%; color: white; border-collapse: collapse;'>
                        <tr>
                            <td style='width: 50%; padding: 8px 0;'>ğŸ“… ë°œìƒì¼: {date_str}</td>
                            <td style='width: 50%; padding: 8px 0;'>ğŸ“ ì„¤ëª…: {pattern['desc']}</td>
                        </tr>
                        <tr>
                            <td style='padding: 8px 0;'>ğŸ¯ ì‹ ë¢°ë„: {pattern['conf']}%</td>
                            <td style='padding: 8px 0;'>ğŸ’¡ ì˜í–¥: {pattern['impact']}</td>
                        </tr>
                    </table>
                </div>
            """, unsafe_allow_html=True)


def render_exit_strategy(exit_strategy: dict, entry_price: float, investment_amount: float, leverage: float):
    """ë§¤ë„ ì „ëµ (ì‹ ê·œ)"""
    st.markdown("<div class='section-title'>ğŸ’° ë§¤ë„ ì‹œì  ì˜ˆì¸¡ (ì–¸ì œ íŒ”ì•„ì•¼ í•˜ëŠ”ê°€?)</div>", unsafe_allow_html=True)
    
    current_status = exit_strategy['current_status']
    scenarios = exit_strategy['scenarios']
    
    # í˜„ì¬ ìƒíƒœ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ì§„ì…ê°€",
            value=f"${entry_price:,.2f}"
        )
    
    with col2:
        st.metric(
            label="í˜„ì¬ê°€",
            value=f"${current_status['current_price']:,.2f}",
            delta=f"{current_status['unrealized_pnl']:+.2f}%"
        )
    
    with col3:
        rsi_color = "ğŸ”´" if current_status['rsi_status'] == 'overbought' else "ğŸŸ¢" if current_status['rsi_status'] == 'oversold' else "âšª"
        st.metric(
            label="RSI ìƒíƒœ",
            value=f"{rsi_color} {current_status['rsi_status'].upper()}"
        )
    
    with col4:
        trend_color = "ğŸ“ˆ" if current_status['trend'] == 'bullish' else "ğŸ“‰"
        st.metric(
            label="ì¶”ì„¸",
            value=f"{trend_color} {current_status['trend'].upper()}"
        )
    
    # ê¶Œì¥ì‚¬í•­
    if current_status['recommendation']:
        if 'ì¦‰ì‹œ' in current_status['recommendation']:
            st.error(current_status['recommendation'])
        elif 'ê³ ë ¤' in current_status['recommendation']:
            st.warning(current_status['recommendation'])
        else:
            st.info(current_status['recommendation'])
    
    st.markdown("---")
    
    # 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤
    st.markdown("### ğŸ¯ ë§¤ë„ ì‹œë‚˜ë¦¬ì˜¤")
    
    for scenario_key, scenario in scenarios.items():
        with st.container():
            profit_pct = ((scenario['take_profit'] - entry_price) / entry_price) * 100
            loss_pct = ((entry_price - scenario['stop_loss']) / entry_price) * 100
            
            profit_amount = investment_amount * leverage * (profit_pct / 100)
            loss_amount = investment_amount * leverage * (loss_pct / 100)
            
            st.markdown(f"""
                <div class='exit-card'>
                    <div class='exit-title'>{scenario['name']}</div>
                    <table style='width: 100%; color: white; border-collapse: collapse;'>
                        <tr>
                            <td style='width: 33%; padding: 8px 0;'>ğŸ¯ ìµì ˆê°€: ${scenario['take_profit']:,.2f} (+{profit_pct:.2f}%)</td>
                            <td style='width: 33%; padding: 8px 0;'>ğŸ›‘ ì†ì ˆê°€: ${scenario['stop_loss']:,.2f} (-{loss_pct:.2f}%)</td>
                            <td style='width: 34%; padding: 8px 0;'>â±ï¸ ë³´ìœ ê¸°ê°„: {scenario['holding_period']}</td>
                        </tr>
                        <tr>
                            <td style='padding: 8px 0;'>ğŸ’µ ëª©í‘œ ìˆ˜ìµ: ${profit_amount:,.2f}</td>
                            <td style='padding: 8px 0;'>ğŸ’¸ ìµœëŒ€ ì†ì‹¤: ${loss_amount:,.2f}</td>
                            <td style='padding: 8px 0;'>ğŸ“Š RR Ratio: {scenario['rr_ratio']:.2f}</td>
                        </tr>
                        <tr>
                            <td colspan='3' style='padding: 8px 0;'>ğŸ“ {scenario['description']}</td>
                        </tr>
                    </table>
                    <div style='margin-top: 12px; padding-top: 12px; border-top: 1px solid rgba(255,255,255,0.3);'>
                        <strong>ë§¤ë„ ì‹ í˜¸:</strong><br/>
                        {'<br/>'.join(['â€¢ ' + signal for signal in scenario['exit_signals']])}
                    </div>
                </div>
            """, unsafe_allow_html=True)


def render_validation_results(cv_results: pd.DataFrame):
    """ëª¨ë¸ ê²€ì¦"""
    st.markdown("<div class='section-title'>âœ… ëª¨ë¸ ê²€ì¦ (TimeSeriesSplit)</div>", unsafe_allow_html=True)
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.dataframe(
            cv_results,
            use_container_width=True,
            hide_index=True
        )
    
    with col2:
        st.markdown("### ğŸ“Š ê²€ì¦ ì§€í‘œ ì„¤ëª…")
        st.markdown("""
        - **Accuracy**: ë°©í–¥ì„± ì˜ˆì¸¡ ì •í™•ë„
        - **MASE**: ì˜ˆì¸¡ ì˜¤ì°¨ (1.0 ë¯¸ë§Œì´ ìš°ìˆ˜)
        - **Mean_Error**: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
        - **Train/Test Size**: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
        """)
        
        try:
            accuracies = []
            for acc in cv_results['Accuracy']:
                if isinstance(acc, str) and '%' in acc:
                    accuracies.append(float(acc.replace('%', '')))
            
            if accuracies:
                avg_accuracy = np.mean(accuracies)
                st.metric(
                    label="í‰ê·  ë°©í–¥ì„± ì •í™•ë„",
                    value=f"{avg_accuracy:.2f}%"
                )
        except:
            pass



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [ì¶”ê°€ë¨] v2.3.1: ê°œë³„ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_candlestick_chart(df: pd.DataFrame, symbol: str):
    """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # ìº”ë“¤ìŠ¤í‹±
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df['Open'],
            high=df['High'],
            low=df['Low'],
            close=df['Close'],
            name='ê°€ê²©',
            increasing_line_color='#26a69a',
            decreasing_line_color='#ef5350'
        )
    )
    
    # EMA50
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['EMA50'],
            name='EMA50',
            line=dict(color='orange', width=2)
        )
    )
    
    # EMA200
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['EMA200'],
            name='EMA200',
            line=dict(color='purple', width=2)
        )
    )
    
    fig.update_layout(
        title=f'{symbol} ê°€ê²© ì°¨íŠ¸',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ê°€ê²© (USD)',
        template='plotly_white',
        height=600,
        hovermode='x unified',
        xaxis_rangeslider_visible=False
    )
    
    return fig


def create_volume_chart(df: pd.DataFrame):
    """ê±°ë˜ëŸ‰ ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # ê±°ë˜ëŸ‰ ë§‰ëŒ€ (ìƒìŠ¹/í•˜ë½ì— ë”°ë¼ ìƒ‰ìƒ êµ¬ë¶„)
    colors = ['#26a69a' if close >= open_ else '#ef5350' 
              for close, open_ in zip(df['Close'], df['Open'])]
    
    fig.add_trace(
        go.Bar(
            x=df.index,
            y=df['Volume'],
            name='ê±°ë˜ëŸ‰',
            marker_color=colors
        )
    )
    
    # ê±°ë˜ëŸ‰ ì´ë™í‰ê·  (20ì¼)
    volume_ma20 = df['Volume'].rolling(window=20).mean()
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=volume_ma20,
            name='ê±°ë˜ëŸ‰ MA20',
            line=dict(color='blue', width=2)
        )
    )
    
    fig.update_layout(
        title='ê±°ë˜ëŸ‰ ì°¨íŠ¸',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ê±°ë˜ëŸ‰',
        template='plotly_white',
        height=600,
        hovermode='x unified'
    )
    
    return fig


def create_rsi_chart(df: pd.DataFrame):
    """RSI ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # RSI ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['RSI14'],
            name='RSI (14)',
            line=dict(color='blue', width=2)
        )
    )
    
    # ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ë¼ì¸
    fig.add_hline(y=70, line_dash="dash", line_color="red", 
                  annotation_text="ê³¼ë§¤ìˆ˜ (70)")
    fig.add_hline(y=50, line_dash="dot", line_color="gray")
    fig.add_hline(y=30, line_dash="dash", line_color="green", 
                  annotation_text="ê³¼ë§¤ë„ (30)")
    
    # ë°°ê²½ ìƒ‰ìƒ ì˜ì—­
    fig.add_hrect(y0=70, y1=100, fillcolor="red", opacity=0.1, line_width=0)
    fig.add_hrect(y0=0, y1=30, fillcolor="green", opacity=0.1, line_width=0)
    
    fig.update_layout(
        title='RSI (Relative Strength Index)',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='RSI',
        template='plotly_white',
        height=600,
        hovermode='x unified',
        yaxis=dict(range=[0, 100])
    )
    
    return fig


def create_macd_chart(df: pd.DataFrame):
    """MACD ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # MACD ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['MACD'],
            name='MACD',
            line=dict(color='blue', width=2)
        )
    )
    
    # Signal ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['MACD_Signal'],
            name='Signal',
            line=dict(color='red', width=2)
        )
    )
    
    # Histogram
    colors = ['#26a69a' if val >= 0 else '#ef5350' for val in df['MACD_Hist']]
    fig.add_trace(
        go.Bar(
            x=df.index,
            y=df['MACD_Hist'],
            name='Histogram',
            marker_color=colors
        )
    )
    
    # 0ì„ 
    fig.add_hline(y=0, line_dash="dash", line_color="gray")
    
    fig.update_layout(
        title='MACD (Moving Average Convergence Divergence)',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='MACD',
        template='plotly_white',
        height=600,
        hovermode='x unified'
    )
    
    return fig


def render_trading_strategy(current_price: float, leverage_info: dict, entry_price: float,
                           stop_loss: float, take_profit: float, position_size: float,
                           rr_ratio: float, investment_amount: float):
    """ë§¤ë§¤ ì „ëµ (v2.3.0: ë ˆë²„ë¦¬ì§€ í‘œì‹œ ê°œì„ )"""
    st.markdown("<div class='section-title'>ğŸ¯ ë§¤ë§¤ ì „ëµ</div>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ“ ì§„ì… ì„¤ì •")
        # [ìˆ˜ì •ë¨] v2.3.0: ê¶Œì¥/ìµœëŒ€ ë ˆë²„ë¦¬ì§€ ë¶„ë¦¬ í‘œì‹œ
        st.markdown(f"""
        <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
            <p style='margin: 0; font-size: 14px; color: #666;'>âš™ï¸ ë ˆë²„ë¦¬ì§€ ìµœì í™”</p>
            <div style='display: flex; justify-content: space-between; margin-top: 5px;'>
                <div>
                    <p style='margin: 0; font-size: 12px; color: #888;'>ê¶Œì¥ ë ˆë²„ë¦¬ì§€</p>
                    <p style='margin: 0; font-size: 24px; font-weight: bold; color: #1f77b4;'>{leverage_info['recommended']}ë°°</p>
                </div>
                <div>
                    <p style='margin: 0; font-size: 12px; color: #888;'>ìµœëŒ€ ë ˆë²„ë¦¬ì§€</p>
                    <p style='margin: 0; font-size: 24px; font-weight: bold; color: #ff7f0e;'>{leverage_info['maximum']}ë°°</p>
                </div>
            </div>
            <p style='margin: 5px 0 0 0; font-size: 11px; color: #888; text-align: center;'>
                ë¦¬ìŠ¤í¬ ë ˆë²¨: <strong>{leverage_info['risk_level']}</strong>
            </p>
        </div>
        """, unsafe_allow_html=True)
        st.metric(label="ì§„ì…ê°€", value=f"${entry_price:,.2f}")
        st.metric(label="í¬ì§€ì…˜ í¬ê¸°", value=f"{position_size:.4f} ì½”ì¸")
    
    with col2:
        st.markdown("### ğŸ›‘ ë¦¬ìŠ¤í¬ ê´€ë¦¬")
        st.metric(label="ì†ì ˆê°€", value=f"${stop_loss:,.2f}")
        st.metric(label="ëª©í‘œê°€", value=f"${take_profit:,.2f}")
        st.metric(label="RR Ratio", value=f"{rr_ratio:.2f}")
    
    with col3:
        st.markdown("### ğŸ’° ì˜ˆìƒ ì†ìµ")
        expected_profit = position_size * (take_profit - entry_price)
        expected_loss = position_size * (entry_price - stop_loss)
        
        st.metric(
            label="ëª©í‘œ ìˆ˜ìµ",
            value=f"${expected_profit:,.2f}",
            delta=f"{(expected_profit / investment_amount) * 100:.2f}%"
        )
        st.metric(
            label="ìµœëŒ€ ì†ì‹¤",
            value=f"-${expected_loss:,.2f}",
            delta=f"-{(expected_loss / investment_amount) * 100:.2f}%"
        )
    
    if rr_ratio >= 3:
        st.success(f"âœ… ìš°ìˆ˜í•œ RR Ratio ({rr_ratio:.2f}) - ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ë†’ì€ ìˆ˜ìµ ê°€ëŠ¥")
    elif rr_ratio >= 2:
        st.info(f"ğŸ“Š ì ì •í•œ RR Ratio ({rr_ratio:.2f}) - ê· í˜•ì¡íŒ ì „ëµ")
    else:
        st.warning(f"âš ï¸ ë‚®ì€ RR Ratio ({rr_ratio:.2f}) - ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµì´ ì‘ìŒ")


def render_technical_indicators(df: pd.DataFrame):
    """ê¸°ìˆ ì  ì§€í‘œ"""
    st.markdown("<div class='section-title'>ğŸ“Š ê¸°ìˆ ì  ì§€í‘œ</div>", unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        rsi = df['RSI14'].iloc[-1]
        rsi_signal = "ê³¼ë§¤ìˆ˜" if rsi > 70 else "ê³¼ë§¤ë„" if rsi < 30 else "ì¤‘ë¦½"
        st.metric(label="RSI (14)", value=f"{rsi:.2f}", delta=rsi_signal)
    
    with col2:
        stoch = df['StochK14'].iloc[-1]
        stoch_signal = "ê³¼ë§¤ìˆ˜" if stoch > 80 else "ê³¼ë§¤ë„" if stoch < 20 else "ì¤‘ë¦½"
        st.metric(label="Stochastic (14)", value=f"{stoch:.2f}", delta=stoch_signal)
    
    with col3:
        mfi = df['MFI14'].iloc[-1]
        mfi_signal = "ê³¼ë§¤ìˆ˜" if mfi > 80 else "ê³¼ë§¤ë„" if mfi < 20 else "ì¤‘ë¦½"
        st.metric(label="MFI (14)", value=f"{mfi:.2f}", delta=mfi_signal)
    
    with col4:
        macd_hist = df['MACD_Hist'].iloc[-1]
        macd_signal = "ìƒìŠ¹" if macd_hist > 0 else "í•˜ë½"
        st.metric(label="MACD Histogram", value=f"{macd_hist:.2f}", delta=macd_signal)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("# ğŸš€ ì„¤ì •")
    st.markdown("---")
    
    # TA-Lib ìƒíƒœ í‘œì‹œ
    if TALIB_AVAILABLE:
        st.success("âœ… TA-Lib ì‚¬ìš© ê°€ëŠ¥ (61ê°œ íŒ¨í„´)")
    else:
        st.warning("âš ï¸ TA-Lib ë¯¸ì„¤ì¹˜ (ê¸°ë³¸ 3ê°œ íŒ¨í„´)")
    
    st.markdown("## 1ï¸âƒ£ ë¶„í•´ëŠ¥ ì„ íƒ")
    resolution_choice = st.selectbox(
        "ğŸ“ˆ ì‹œê°„ í”„ë ˆì„",
        list(RESOLUTION_MAP.keys()),
        index=3,
        help="ì§§ì€ ê¸°ê°„ì¼ìˆ˜ë¡ ìµœì‹  ë°ì´í„°ë§Œ ì œê³µë©ë‹ˆë‹¤"
    )
    interval = RESOLUTION_MAP[resolution_choice]
    interval_name = resolution_choice
    
    interval_info = {
        '1m': 'â±ï¸ 1ë¶„ë´‰: ìµœê·¼ **7ì¼**ë§Œ ì§€ì› (ì´ˆë‹¨íƒ€ ë§¤ë§¤ìš©)',
        '5m': 'â±ï¸ 5ë¶„ë´‰: ìµœê·¼ **60ì¼**ë§Œ ì§€ì› (ë‹¨íƒ€ ë§¤ë§¤ìš©)',
        '1h': 'â±ï¸ 1ì‹œê°„ë´‰: ìµœê·¼ **2ë…„**ë§Œ ì§€ì› (ìŠ¤ìœ™ íŠ¸ë ˆì´ë”©ìš©)',
        '1d': 'â±ï¸ 1ì¼ë´‰: **ì „ì²´ ê¸°ê°„** ì§€ì› (ì¤‘ì¥ê¸° íˆ¬ììš©)'
    }
    
    st.info(interval_info.get(interval, ''))
    
    st.markdown("---")
    st.markdown("## 2ï¸âƒ£ ì½”ì¸ ì„ íƒ")
    
    coin_input_method = st.radio(
        "ğŸ”§ ì…ë ¥ ë°©ì‹",
        ["ëª©ë¡ì—ì„œ ì„ íƒ", "ì§ì ‘ ì…ë ¥"],
        horizontal=True
    )
    
    if coin_input_method == "ëª©ë¡ì—ì„œ ì„ íƒ":
        crypto_choice = st.selectbox(
            "ğŸ’ ì•”í˜¸í™”í",
            list(CRYPTO_MAP.keys())
        )
        selected_crypto = CRYPTO_MAP[crypto_choice]
    else:
        custom_symbol = st.text_input(
            "ğŸ’ ì½”ì¸ ì‹¬ë³¼ ì…ë ¥",
            value="BTCUSDT",
            help="ì˜ˆ: BTCUSDT, ETHUSDT, BNBUSDT ë“± (USDT í˜ì–´ë§Œ ì§€ì›)"
        ).upper().strip()
        
        if not custom_symbol.endswith("USDT"):
            st.warning("âš ï¸ USDT í˜ì–´ë§Œ ì§€ì›ë©ë‹ˆë‹¤. ì‹¬ë³¼ ëì— 'USDT'ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            custom_symbol = custom_symbol + "USDT" if custom_symbol else "BTCUSDT"
        
        selected_crypto = custom_symbol
        st.info(f"ì„ íƒëœ ì½”ì¸: **{selected_crypto}** ({selected_crypto[:-4]}-USD)")
    
    st.markdown("---")
    st.markdown("## 3ï¸âƒ£ ë¶„ì„ ê¸°ê°„")
    
    period_choice = st.radio(
        "ğŸ“… ê¸°ê°„ ì„¤ì •",
        ["ìë™ (ë¶„í•´ëŠ¥ì— ìµœì í™”)", "ìˆ˜ë™ ì„¤ì •"],
        help="ìë™ ëª¨ë“œëŠ” ë¶„í•´ëŠ¥ë³„ ì œí•œì„ ìë™ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤"
    )
    
    if period_choice == "ìë™ (ë¶„í•´ëŠ¥ì— ìµœì í™”)":
        today = datetime.date.today()
        
        interval_periods = {
            '1m': 7,
            '5m': 60,
            '1h': 730,
            '1d': 365 * 5
        }
        
        days_back = interval_periods.get(interval, 180)
        START = today - datetime.timedelta(days=days_back)
        
        listing_dates = {
            "BTCUSDT": datetime.date(2017, 8, 17),
            "ETHUSDT": datetime.date(2017, 8, 17),
            "XRPUSDT": datetime.date(2018, 5, 14),
            "DOGEUSDT": datetime.date(2021, 5, 6),
            "ADAUSDT": datetime.date(2018, 4, 17),
            "SOLUSDT": datetime.date(2021, 8, 11)
        }
        
        listing_date = listing_dates.get(selected_crypto, START)
        
        if START < listing_date:
            START = listing_date
        
        END = today
        st.info(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {START} ~ {END} ({(END - START).days}ì¼)")
    else:
        col_s, col_e = st.columns(2)
        with col_s:
            START = st.date_input(
                "ì‹œì‘ì¼",
                value=datetime.date.today() - datetime.timedelta(days=180)
            )
        with col_e:
            END = st.date_input(
                "ì¢…ë£Œì¼",
                value=datetime.date.today()
            )
        
        if START >= END:
            st.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()
    
    st.markdown("---")
    st.markdown("## 4ï¸âƒ£ íˆ¬ì ì„¤ì •")
    
    
    # ì˜ˆì¸¡ ì¼ìˆ˜ ì„¤ì •
    forecast_days = st.slider(
        "ğŸ”® ì˜ˆì¸¡ ê¸°ê°„",
        min_value=1,
        max_value=30,
        value=3,
        step=1,
        help="ëª‡ ì¼ í›„ì˜ ê°€ê²©ì„ ì˜ˆì¸¡í• ì§€ ì„ íƒí•˜ì„¸ìš”"
    )
    st.session_state['forecast_days'] = forecast_days

    investment_amount = st.number_input(
        "ğŸ’° íˆ¬ì ê¸ˆì•¡ (USDT)",
        min_value=1.0,
        value=1000.0,
        step=50.0
    )
    
    risk_per_trade_pct = st.slider(
        "âš ï¸ ë¦¬ìŠ¤í¬ ë¹„ìœ¨ (%)",
        min_value=0.5,
        max_value=5.0,
        value=2.0,
        step=0.5,
        help="í•œ ê±°ë˜ë‹¹ ìµœëŒ€ ì†ì‹¤ í—ˆìš© í¼ì„¼íŠ¸"
    ) / 100.0
    
    stop_loss_k = st.number_input(
        "ğŸ›‘ ì†ì ˆ ë°°ìˆ˜ (Ïƒ ê¸°ì¤€)",
        min_value=1.0,
        max_value=3.0,
        value=2.0,
        step=0.5
    )
    
    default_max_lev = MAX_LEVERAGE_MAP.get(selected_crypto, 50)
    leverage_ceiling = st.number_input(
        "ğŸ“Š ìµœëŒ€ ë ˆë²„ë¦¬ì§€",
        min_value=1,
        max_value=500,
        value=int(default_max_lev),
        step=1
    )
    
    st.markdown("---")
    bt = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

# ë©”ì¸ ë¡œì§
if bt:
    try:
        progress_placeholder = st.empty()
        status_text = st.empty()
        
        progress_placeholder.markdown(render_progress_bar(1, 6), unsafe_allow_html=True)
        status_text.info(f"ğŸ” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘... (ë¶„í•´ëŠ¥: {interval_name})")
        
        raw_df = load_crypto_data(selected_crypto, START, END, interval)
        
        if raw_df.empty:
            yf_ticker = selected_crypto[:-4] + "-USD"
            st.error(f"âŒ {yf_ticker} ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.warning(f"""
            **ê°€ëŠ¥í•œ ì›ì¸**:
            - ì„ íƒí•œ ê¸°ê°„({START} ~ {END})ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤
            - ë¶„í•´ëŠ¥({interval_name})ì´ í•´ë‹¹ ê¸°ê°„ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
            - yfinance API ì¼ì‹œì  ì˜¤ë¥˜
            
            **í•´ê²° ë°©ë²•**:
            1. ë” ìµœê·¼ ê¸°ê°„ ì„ íƒ
            2. ë¶„í•´ëŠ¥ì„ 1ì¼ë´‰ìœ¼ë¡œ ë³€ê²½
            3. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
            4. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
            """)
            
            if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™” í›„ ì¬ì‹œë„"):
                st.cache_data.clear()
                st.rerun()
            st.stop()
        
        min_required = 20
        if len(raw_df) < min_required:
            st.error(f"âŒ ìµœì†Œ {min_required} ê¸°ê°„ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(raw_df)})")
            st.warning("""
            **í•´ê²° ë°©ë²•**:
            1. ë” ê¸´ ê¸°ê°„ ì„ íƒ
            2. ë‹¤ë¥¸ ë¶„í•´ëŠ¥ ì„ íƒ (1ì¼ë´‰ ê¶Œì¥)
            3. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
            """)
            st.stop()
        
        progress_placeholder.markdown(render_progress_bar(2, 6), unsafe_allow_html=True)
        status_text.info("ğŸ“Š ì ì‘í˜• ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘...")
        
        df = calculate_indicators_wilders(raw_df)
        
        if df.empty:
            st.error("âŒ ì§€í‘œ ê³„ì‚° í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.warning(f"""
            **ë¬¸ì œ ë¶„ì„**:
            - ì›ë³¸ ë°ì´í„°: {len(raw_df)}ê°œ
            - ì§€í‘œ ê³„ì‚° í›„: {len(df)}ê°œ (ëª¨ë‘ NaN ì œê±°ë¨)
            
            **í•´ê²° ë°©ë²•**:
            1. ë” ê¸´ ê¸°ê°„ ì„ íƒ (ìµœì†Œ 50ê°œ ì´ìƒ ê¶Œì¥)
            2. 1ì¼ë´‰ ì„ íƒ (ë” ë§ì€ ë°ì´í„° í™•ë³´)
            """)
            st.stop()
        
        if len(df) < 10:
            st.warning(f"""
            âš ï¸ ìœ íš¨í•œ ë°ì´í„°ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤ ({len(df)}ê°œ).
            
            ë¶„ì„ì€ ì§„í–‰ë˜ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            ë” ê¸´ ê¸°ê°„ì„ ì„ íƒí•˜ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
            """)
        
        progress_placeholder.markdown(render_progress_bar(3, 6), unsafe_allow_html=True)
        status_text.info("ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘...")
        
        close_series = df['Close']
        
        if len(close_series) < 10:
            st.error("âŒ ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            st.stop()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v2.5.0: ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ (ì‹œê°„ í”„ë ˆì„ ê¸°ë°˜ ìë™ ì„ íƒ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            ensemble_models, ensemble_config = train_ensemble_models(
                data=close_series,
                features_df=df,
                interval=interval,
                forecast_days=forecast_days
            )
            
            if not ensemble_models:
                st.error("âŒ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()
            
            st.success(f"âœ… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {ensemble_config['description']}")
            
        except Exception as e:
            st.error(f"âŒ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            st.text(traceback.format_exc())
            st.stop()
        
        close_series = df['Close']
        
        if len(close_series) < 10:
            st.error("âŒ ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            st.stop()
        
        # [ê°œì„ ë¨] v2.4.0: ê°•ê±´í•œ ëª¨ë¸ í•™ìŠµ ë° ìë™ ê³„ì ˆì„± ê°ì§€
        try:
            hw_model, seasonality_info, window_size = fit_hw_model_robust(
                close_series, 
                max_window=500  # ìµœì‹  500ê°œ ë°ì´í„°ë§Œ ì‚¬ìš© (ì„±ëŠ¥ ê°œì„ )
            )
            
            # ê³„ì ˆì„± ì •ë³´ í‘œì‹œ
            if seasonality_info['detected']:
                st.info(f"âœ… ê³„ì ˆì„± ê°ì§€: ì£¼ê¸° {seasonality_info['period']}, "
                       f"íƒ€ì… {seasonality_info['type']}, "
                       f"í•™ìŠµ ë°ì´í„°: {window_size}ê°œ")
            else:
                st.info(f"â„¹ï¸ ë¹„ê³„ì ˆ ëª¨ë¸ ì‚¬ìš© (í•™ìŠµ ë°ì´í„°: {window_size}ê°œ)")
        
        except Exception as e:
            st.error(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            st.warning("""
            **í•´ê²° ë°©ë²•**:
            1. ë” ê¸´ ê¸°ê°„ ì„ íƒ
            2. 1ì¼ë´‰ìœ¼ë¡œ ë³€ê²½
            3. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
            """)
            st.stop()
        
        pred_in_sample = hw_model.fittedvalues
        
        # [ê°œì„ ë¨] v2.4.0: ì˜¤í”„ì…‹ ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡
        forecast_steps = min(30, len(close_series) // 2)
        last_actual_value = close_series.iloc[-1]
        
        # ìµœê·¼ ì¶”ì„¸ ê³„ì‚° (ìµœê·¼ 20ê°œ ë°ì´í„°ì˜ ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°)
        recent_window = min(20, len(close_series))
        recent_prices = close_series.iloc[-recent_window:].values
        recent_trend = np.polyfit(range(recent_window), recent_prices, 1)[0]
        
        future_forecast = forecast_with_offset_scaling(
            hw_model, 
            forecast_steps, 
            last_actual_value, 
            recent_trend
        )
        
        last_date = df.index[-1]
        future_dates = [last_date + pd.Timedelta(days=i + 1) for i in range(forecast_steps)]
        future_df = pd.DataFrame({'ì˜ˆì¸¡ ì¢…ê°€': future_forecast.values}, index=future_dates)
        
        progress_placeholder.markdown(render_progress_bar(4, 6), unsafe_allow_html=True)
        status_text.info("ğŸ•¯ï¸ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì¤‘...")
        
        patterns = detect_candlestick_patterns(df)
        
        progress_placeholder.markdown(render_progress_bar(5, 6), unsafe_allow_html=True)
        status_text.info("âœ… ëª¨ë¸ì„ ê²€ì¦í•˜ëŠ” ì¤‘...")
        
        cv_results = perform_timeseries_cv(df, n_splits=min(5, len(df) // 20))
        
        progress_placeholder.markdown(render_progress_bar(6, 6), unsafe_allow_html=True)
        status_text.info("ğŸ¯ ë§¤ë§¤ ì „ëµì„ ìƒì„±í•˜ëŠ” ì¤‘...")
        
        current_price = df['Close'].iloc[-1]
        atr = df['ATR14'].iloc[-1]
        volatility = df['Volatility30d'].iloc[-1]
        atr_ratio = atr / current_price if current_price != 0 else 0.01
        
        hw_confidence = 75.0
        
        # [ìˆ˜ì •ë¨] v2.3.0: ë ˆë²„ë¦¬ì§€ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°›ìŒ
        leverage_info = calculate_optimized_leverage(
            investment_amount=investment_amount,
            volatility=volatility,
            atr_ratio=atr_ratio,
            confidence=hw_confidence,
            max_leverage=leverage_ceiling,
            crypto_name=selected_crypto  # [ì¶”ê°€ë¨] ì½”ì¸ ì´ë¦„ ì „ë‹¬
        )
        
        entry_price = current_price
        stop_loss = entry_price - (atr * stop_loss_k)
        take_profit = entry_price + (atr * stop_loss_k * 2)
        
        # [ìˆ˜ì •ë¨] v2.3.0: ê¶Œì¥ ë ˆë²„ë¦¬ì§€ ì‚¬ìš©
        risk_amount = investment_amount * risk_per_trade_pct
        position_size = (risk_amount * leverage_info['recommended']) / (entry_price - stop_loss)
        
        rr_ratio = calculate_rr_ratio(entry_price, take_profit, stop_loss)
        
        # ë§¤ë„ ì „ëµ ê³„ì‚°
        exit_strategy = calculate_exit_strategy(df, entry_price, atr, investment_amount, leverage_info['recommended'])
        
        progress_placeholder.empty()
        status_text.empty()
        
        st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ê²°ê³¼ ì¶œë ¥
        render_data_summary(df, selected_crypto, interval_name)
        render_ai_forecast(future_df, hw_confidence)
        render_patterns(patterns)
        render_technical_indicators(df)
        render_validation_results(cv_results)
        # [ì¶”ê°€ë¨] v2.2.1: AI ì˜ˆì¸¡ì— í•„ìš”í•œ ë³€ìˆ˜ ì¶”ì¶œ
        ema_short = df['EMA50'].iloc[-1]
        ema_long = df['EMA200'].iloc[-1]
        rsi = df['RSI14'].iloc[-1]
        macd = df['MACD'].iloc[-1]
        macd_signal = df['MACD_Signal'].iloc[-1]
        
        # [ì¶”ê°€ë¨] AI ì˜ˆì¸¡ ì‹¤í–‰
        ai_prediction = predict_trend_with_ai(
            df=df,
            current_price=current_price,
            ema_short=ema_short,
            ema_long=ema_long,
            rsi=rsi,
            macd=macd,
            macd_signal=macd_signal
        )
        
        # [ì¶”ê°€ë¨] AI ì˜ˆì¸¡ ê²°ê³¼ ë Œë”ë§ (ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë‹¤ìŒ)
        render_ai_prediction(ai_prediction, current_price)
        
        # [ì¶”ê°€ë¨] í¬ì§€ì…˜ ì¶”ì²œ ê³„ì‚°
        position_recommendation = recommend_position(
            ai_prediction=ai_prediction,
            current_price=current_price,
            stop_loss=stop_loss,
            take_profit=take_profit,
            volatility=volatility
        )
        
        render_trading_strategy(current_price, leverage_info, entry_price,
                               stop_loss, take_profit, position_size,
                               rr_ratio, investment_amount)
        
        # [ì¶”ê°€ë¨] í¬ì§€ì…˜ ì¶”ì²œ ë Œë”ë§ (ë§¤ë§¤ ì „ëµ ì§í›„)
        render_position_recommendation(position_recommendation)
        
        # ë§¤ë„ ì „ëµ (ì‹ ê·œ)
        render_exit_strategy(exit_strategy, entry_price, investment_amount, leverage_info['recommended'])
        
        # ê°€ê²© ì°¨íŠ¸
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ì°¨íŠ¸")
        
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¹ ìº”ë“¤ìŠ¤í‹±", "ğŸ“Š ê±°ë˜ëŸ‰", "ğŸ”µ RSI", "ğŸ“‰ MACD"])
        
        with tab1:
            fig = create_candlestick_chart(df, selected_crypto)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            fig = create_volume_chart(df)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab3:
            fig = create_rsi_chart(df)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            fig = create_macd_chart(df)
            st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.warning("""
        **ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•**:
        1. ìºì‹œ ì´ˆê¸°í™” í›„ ì¬ì‹œë„
        2. ë” ê¸´ ê¸°ê°„ ì„ íƒ (ìµœì†Œ 30ì¼ ì´ìƒ)
        3. 1ì¼ë´‰ìœ¼ë¡œ ë³€ê²½
        4. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
        5. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
        """)
        
        if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”"):
            st.cache_data.clear()
            st.rerun()
        
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ (ê°œë°œììš©)"):
            st.code(str(e))
            import traceback
            st.code(traceback.format_exc())
