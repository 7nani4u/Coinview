# -*- coding: utf-8 -*-
"""
ì½”ì¸ AI ì˜ˆì¸¡ ì‹œìŠ¤í…œ - v2.9.4 WORKS (ì‹¤ì‹œê°„ ìë™ ë¶„ì„)
âœ¨ ì£¼ìš” ê¸°ëŠ¥:
- ì‹œì¥ ì‹¬ë¦¬ ì§€ìˆ˜ (Fear & Greed Index)
- í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ (ì„ íƒí•œ ì½”ì¸)
- ì•™ìƒë¸” ì˜ˆì¸¡ (8ê°œ ëª¨ë¸)
- ì ì‘í˜• ì§€í‘œ ê³„ì‚°

ğŸŸ¢ v2.8.0 ì‹ ê·œ ê¸°ëŠ¥:
1. Kelly Criterion: AI ì‹ ë¢°ë„ ê¸°ë°˜ ìµœì  Position Size
3. Monte Carlo ì‹œë®¬ë ˆì´ì…˜: í™•ë¥ ì  ì†ìµ ë¶„ì„
4. Position Sizing ì „ëµ ë¹„êµ: 4ê°€ì§€ ì „ëµ ì„±ê³¼ ë¹„êµ
5. í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬: ë‹¤ì¤‘ í¬ì§€ì…˜ í†µí•© ë¶„ì„
6. ë°±í…ŒìŠ¤íŒ… ê°œì„ : ì „ëµë³„ ì„±ê³¼ ì¸¡ì •

ğŸ”´ v2.7.2 ìˆ˜ì • ì‚¬í•­ (CRITICAL):
- Position Size ê³„ì‚° ë¡œì§ ìˆ˜ì • (ë ˆë²„ë¦¬ì§€ ì˜¤ë¥˜ ìˆ˜ì •)
- Stop Loss ë¡±/ìˆ êµ¬ë¶„ ì¶”ê°€
- ì¦ê±°ê¸ˆ ì •ë³´ í‘œì‹œ ì¶”ê°€
- 0 ë‚˜ëˆ„ê¸° ë³´í˜¸ ì¶”ê°€
- ê°€ê²© ìœ íš¨ì„± ê²€ì¦ ì¶”ê°€

ğŸ”µ v2.8.1 ìµœì í™” (Optimization):

ğŸŸ¢ v2.9.0 ê¸€ë¡œë²Œ ë°ì´í„° í†µí•©:
- Monte Carlo ì‹œë®¬ë ˆì´ì…˜ ì œê±° (ë‹¨ìˆœ ì‹œë®¬ë ˆì´ì…˜ â†’ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
- CryptoPanic API: ì‹¤ì‹œê°„ ê¸€ë¡œë²Œ ë‰´ìŠ¤ ë° ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
- FRED API: ë¯¸êµ­ CPI ê²½ì œ ì§€í‘œ ì‹¤ì‹œê°„ ì—°ë™
- ë¹„íŠ¸ì½”ì¸ ë„ë¯¸ë„ŒìŠ¤, ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„, í€ë”©ë¹„ ì˜¨ì²´ì¸ ë¶„ì„
- ì¢…í•© ì‹œì¥ ìŠ¤ì½”ì–´ë§: ë‰´ìŠ¤+ë§¤í¬ë¡œ+ì˜¨ì²´ì¸ í†µí•© (0-100ì )
- Dead Code ì œê±°: detect_candlestick_patterns_basic() ì‚­ì œ
- ë¯¸ì‚¬ìš© Validation í•¨ìˆ˜ ì œê±° (4ê°œ)
- ë¯¸ì‚¬ìš© imports ì œê±° (seaborn, BytesIO, sklearn validation)
- Risk Management í•¨ìˆ˜ ë…¼ë¦¬ì  ìˆœì„œë¡œ ì¬ë°°ì¹˜
- ML Models ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í™”

ğŸš€ v2.9.2 ë¶„ì„ ê°•í™” (DeepSeek ë°©ë²•ë¡ ):
- 3ë¶„ë´‰ + 4ì‹œê°„ë´‰ ìë™ ë¡œë“œ ë° ë“€ì–¼ ë¶„ì„
- 4ì‹œê°„ë´‰ EMA20/50 ì°¨íŠ¸ ì‹œê°í™”
- Open Interest íˆìŠ¤í† ë¦¬ ì°¨íŠ¸ ë° ê¸‰ì¦/ê¸‰ê° ì•Œë¦¼
- Chain-of-Thought ìƒì„¸ ë¶„ì„ ê³¼ì • í‘œì‹œ
- DeepSeek ìŠ¤íƒ€ì¼ ë°±í…ŒìŠ¤íŒ… (ê³ R/R ì „ëµ vs ì¼ë°˜ ì „ëµ)
- ì¤‘ë³µ ì£¼ì„ ì •ë¦¬ (-269 ë¼ì¸, 5.0% ê°ì†Œ)

ğŸ¯ v2.9.4 WORKS ì‹¤ì‹œê°„ ìë™ ë¶„ì„:
- ì¢…í•© ì‹ í˜¸ ì ìˆ˜ ì‹œìŠ¤í…œ: íŒ¨í„´ê°•ë„ + ì¶”ì„¸í•„í„° + ë³€ë™ì„±í•„í„°
- ì‹¤ì‹œê°„ ë§¤ë§¤ ë¹„ìœ¨ & ê¸°ê°„ë³„ ìˆ˜ìµë¥ : 1ì£¼ì¼, 1ê°œì›”, 3ê°œì›”
- â­ 30ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨: ê°€ê²© ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸
- ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ êµ¬ì¡° (Squeeze ì—†ìŒ)
"""


import pandas as pd
import numpy as np
import yfinance as yf
import datetime
import streamlit as st
from scipy import stats
import os
import logging
import requests
import statsmodels.api as sm
import plotly.graph_objects as go
from plotly.subplots import make_subplots
# v2.9.0.1: TimeSeriesSplit ë³µì› (ì‚¬ìš©ë¨)
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import brier_score_loss, log_loss

# v2.6.0: ì¶”ê°€ ë¶„ì„ ë„êµ¬
from datetime import timedelta
from typing import Dict, List, Optional, Tuple

# ì•™ìƒë¸” ëª¨ë¸ imports
import warnings
warnings.filterwarnings('ignore')

# ë”¥ëŸ¬ë‹ ëª¨ë¸
try:
    import torch
    import torch.nn as nn
    from torch.utils.data import Dataset, DataLoader
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    # PyTorch ë¯¸ì„¤ì¹˜ ì‹œ ë¡œê·¸ (UIì—ì„œ í‘œì‹œ)
    # ë”ë¯¸ í´ë˜ìŠ¤ ì •ì˜ (import ì˜¤ë¥˜ ë°©ì§€)
    class nn:
        class Module:
            pass
        class Linear:
            pass
        class ModuleList:
            pass
        class GRU:
            pass
        class LSTM:
            pass
    class torch:
        @staticmethod
        def relu(x):
            return x
        @staticmethod
        def zeros(*args, **kwargs):
            return None
        class optim:
            class Adam:
                pass
        class utils:
            class data:
                class Dataset:
                    pass
                class DataLoader:
                    pass

# íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    # XGBoost ë¯¸ì„¤ì¹˜ ì‹œ ë¡œê·¸ (UIì—ì„œ í‘œì‹œ)
    # ë”ë¯¸ ëª¨ë“ˆ
    class xgb:
        class XGBRegressor:
            pass

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    # LightGBM ë¯¸ì„¤ì¹˜ ì‹œ ë¡œê·¸ (UIì—ì„œ í‘œì‹œ)
    # ë”ë¯¸ ëª¨ë“ˆ
    class lgb:
        class LGBMRegressor:
            pass

# ì‹œê³„ì—´ ëª¨ë¸
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False
    # Prophet ë¯¸ì„¤ì¹˜ ì‹œ ë¡œê·¸ (UIì—ì„œ í‘œì‹œ)
    # ë”ë¯¸ í´ë˜ìŠ¤
    class Prophet:
        pass

from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Keep-Alive ì‹œìŠ¤í…œ - ì ˆëŒ€ ì‹œê³„ ê¸°ì¤€ 15ë¶„ ê°„ê²© (00, 15, 30, 45ë¶„)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import datetime
import threading
import requests
import os

def get_next_keepalive_time():
    '''ë‹¤ìŒ keep-alive ì‹¤í–‰ ì‹œê° ê³„ì‚° (ë§¤ì‹œ 00, 15, 30, 45ë¶„)'''
    now = datetime.datetime.now()
    minute = now.minute
    
    # ë‹¤ìŒ 15ë¶„ ë°°ìˆ˜ ì‹œê° ê³„ì‚°
    if minute < 15:
        next_minute = 15
    elif minute < 30:
        next_minute = 30
    elif minute < 45:
        next_minute = 45
    else:
        next_minute = 0
    
    # ë‹¤ìŒ ì‹¤í–‰ ì‹œê° ìƒì„±
    if next_minute == 0:
        # ë‹¤ìŒ ì‹œê°„ëŒ€ì˜ 00ë¶„
        next_time = now.replace(minute=0, second=0, microsecond=0) + datetime.timedelta(hours=1)
    else:
        next_time = now.replace(minute=next_minute, second=0, microsecond=0)
    
    return next_time

def keepalive_scheduler():
    '''ì ˆëŒ€ ì‹œê³„ ê¸°ì¤€ Keep-Alive ìŠ¤ì¼€ì¤„ëŸ¬'''
    while True:
        # ë‹¤ìŒ ì‹¤í–‰ ì‹œê° ê³„ì‚°
        next_time = get_next_keepalive_time()
        now = datetime.datetime.now()
        
        # ëŒ€ê¸° ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)
        wait_seconds = (next_time - now).total_seconds()
        
        # ëŒ€ê¸°
        if wait_seconds > 0:
            threading.Event().wait(wait_seconds)
        
        # Keep-Alive ì‹¤í–‰
        try:
            # ìê¸° ìì‹ ì—ê²Œ ping ìš”ì²­ (Streamlit ì•± í™œì„± ìƒíƒœ ìœ ì§€)
            app_url = os.environ.get('REPL_SLUG')  # Replit í™˜ê²½ ë³€ìˆ˜
            if app_url:
                response = requests.get(f"https://{app_url}.repl.co", timeout=5)
                print(f"[Keep-Alive] {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Status: {response.status_code}")
            else:
                # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ë‹¨ìˆœ ë¡œê·¸ë§Œ
                print(f"[Keep-Alive] {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - Heartbeat")
        except Exception as e:
            print(f"[Keep-Alive] Error: {e}")

# TA-Lib ì„ íƒì  ì„í¬íŠ¸
try:
    import talib
    TALIB_AVAILABLE = True
except ImportError:
    TALIB_AVAILABLE = False
    # ê²½ê³  ë©”ì‹œì§€ëŠ” ë©”ì¸ UIì—ì„œ í‘œì‹œ (st í•¨ìˆ˜ëŠ” import ì‹œì ì— í˜¸ì¶œ ë¶ˆê°€)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Streamlit í˜ì´ì§€ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ì½”ì¸ AI ì˜ˆì¸¡ ì‹œìŠ¤í…œ v2.9.4",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Keep-Alive ìŠ¤ë ˆë“œ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
if 'keepalive_started' not in st.session_state:
    st.session_state.keepalive_started = True
    
    keepalive_thread = threading.Thread(target=keepalive_scheduler, daemon=True)
    keepalive_thread.start()
    
    # ì²« ì‹¤í–‰ ì‹œê° í‘œì‹œ (ë””ë²„ê¹…ìš©)
    next_run = get_next_keepalive_time()
    print(f"[Keep-Alive] Started - Next run at {next_run.strftime('%Y-%m-%d %H:%M:%S')}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1.5) â­ ì‹¤ì‹œê°„ ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import time

if 'last_refresh' not in st.session_state:
    st.session_state.last_refresh = time.time()

current_time = time.time()
if current_time - st.session_state.last_refresh >= 30:
    st.session_state.last_refresh = current_time
    st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) CSS ìŠ¤íƒ€ì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
    <style>
    .main { padding: 1rem; }
    
    .section-title {
        font-size: 32px;
        font-weight: bold;
        margin-top: 32px;
        margin-bottom: 16px;
        padding-bottom: 8px;
        border-bottom: 3px solid #3498DB;
        color: #2C3E50;
    }
    
    .stMetric {
        background-color: #F8F9FA;
        border-radius: 12px;
        padding: 16px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .progress-step {
        display: inline-block;
        padding: 8px 16px;
        margin: 4px;
        border-radius: 8px;
        background: #ECF0F1;
        color: #7F8C8D;
        font-size: 14px;
    }
    
    .progress-step.active {
        background: #3498DB;
        color: white;
        font-weight: bold;
    }
    
    .pattern-card {
        background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
        color: white;
        padding: 20px;
        border-radius: 12px;
        margin: 12px 0;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
    }
    
    .pattern-title {
        font-size: 24px;
        font-weight: bold;
        margin-bottom: 12px;
    }
    
    .exit-card {
        background: linear-gradient(135deg, #F093FB 0%, #F5576C 100%);
        color: white;
        padding: 20px;
        border-radius: 12px;
        margin: 12px 0;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
    }
    
    .exit-title {
        font-size: 22px;
        font-weight: bold;
        margin-bottom: 12px;
    }
    </style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CRYPTO_MAP = {
    "ë¹„íŠ¸ì½”ì¸ (BTC)": "BTCUSDT",
    "ì´ë”ë¦¬ì›€ (ETH)": "ETHUSDT",
    "ë¦¬í”Œ (XRP)": "XRPUSDT",
    "ë„ì§€ì½”ì¸ (DOGE)": "DOGEUSDT",
    "ì—ì´ë‹¤ (ADA)": "ADAUSDT",
    "ì†”ë¼ë‚˜ (SOL)": "SOLUSDT"
}


@st.cache_data(ttl=3600)


# ==============================================================================
# v2.9.4 ì‹ ê·œ ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ (Squeeze ì—†ìŒ)
# ==============================================================================

def calculate_signal_score(df, current_price):
    """ì¢…í•© ì‹ í˜¸ ì ìˆ˜ ê³„ì‚°"""
    import pandas as pd
    import numpy as np
    
    if df.empty or len(df) < 100:
        return {
            'total_score': 50,
            'pattern_strength': 0,
            'trend_filter': 0,
            'volatility_filter': 0,
            'signal': 'NEUTRAL',
            'confidence': 0
        }
    
    # 1. íŒ¨í„´ ê°•ë„ (40%)
    rsi = df['RSI'].iloc[-1] if 'RSI' in df.columns else 50
    if rsi < 30:
        pattern_score = 80
    elif rsi < 40:
        pattern_score = 60
    elif rsi > 70:
        pattern_score = 20
    elif rsi > 60:
        pattern_score = 40
    else:
        pattern_score = 50
    
    # 2. ì¶”ì„¸ í•„í„° (40%)
    close = df['Close'].iloc[-1]
    ema20 = df['Close'].ewm(span=20).mean().iloc[-1]
    ema50 = df['Close'].ewm(span=50).mean().iloc[-1]
    
    if close > ema20 > ema50:
        trend_score = 80
    elif close > ema20:
        trend_score = 60
    elif close < ema20 < ema50:
        trend_score = 20
    elif close < ema20:
        trend_score = 40
    else:
        trend_score = 50
    
    # 3. ë³€ë™ì„± í•„í„° (20%)
    volatility_score = 50
    
    # ì¢…í•© ì ìˆ˜
    total_score = (pattern_score * 0.4 + trend_score * 0.4 + volatility_score * 0.2)
    
    # ì‹ í˜¸ ê²°ì •
    if total_score >= 70:
        signal = 'STRONG_BUY'
    elif total_score >= 55:
        signal = 'BUY'
    elif total_score >= 45:
        signal = 'NEUTRAL'
    elif total_score >= 30:
        signal = 'SELL'
    else:
        signal = 'STRONG_SELL'
    
    return {
        'total_score': total_score,
        'pattern_strength': pattern_score,
        'trend_filter': trend_score,
        'volatility_filter': volatility_score,
        'signal': signal,
        'confidence': abs(total_score - 50) * 2
    }


@st.cache_data(ttl=300, show_spinner=False)  # 5ë¶„ ìºì‹± (ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­)
def calculate_trading_metrics(symbol):
    """ì‹¤ì‹œê°„ ë§¤ë§¤ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    import yfinance as yf
    from datetime import datetime, timedelta
    
    try:
        yf_symbol = symbol.replace('USDT', '-USD')
        ticker = yf.Ticker(yf_symbol)
        
        # 3ê°œì›” ë°ì´í„°
        end_date = datetime.now()
        start_date = end_date - timedelta(days=100)
        hist = ticker.history(start=start_date, end=end_date)
        
        if hist.empty:
            raise Exception("ë°ì´í„° ì—†ìŒ")
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        returns = {}
        current_price = hist['Close'].iloc[-1]
        
        # 1ì£¼ì¼
        if len(hist) >= 7:
            week_ago = hist['Close'].iloc[-7]
            returns['1week'] = ((current_price - week_ago) / week_ago) * 100
        else:
            returns['1week'] = 0
        
        # 1ê°œì›”
        if len(hist) >= 30:
            month_ago = hist['Close'].iloc[-30]
            returns['1month'] = ((current_price - month_ago) / month_ago) * 100
        else:
            returns['1month'] = 0
        
        # 3ê°œì›”
        if len(hist) >= 90:
            months_ago = hist['Close'].iloc[-90]
            returns['3months'] = ((current_price - months_ago) / months_ago) * 100
        else:
            returns['3months'] = 0
        
        # ë§¤ìˆ˜/ë§¤ë„ ë¹„ìœ¨ (ê±°ë˜ëŸ‰ ê¸°ë°˜ ì¶”ì •)
        recent_volume = hist['Volume'].iloc[-5:].mean()
        avg_volume = hist['Volume'].mean()
        buy_ratio = min(100, max(0, 50 + (recent_volume / avg_volume - 1) * 50))
        
        # ì‹œì¥ ì‹¬ë¦¬
        if buy_ratio > 60:
            sentiment = 'BULLISH'
        elif buy_ratio < 40:
            sentiment = 'BEARISH'
        else:
            sentiment = 'NEUTRAL'
        
        return {
            'returns': returns,
            'buy_sell_ratio': buy_ratio,
            'sentiment': sentiment,
            'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
    
    except Exception as e:
        return {
            'returns': {'1week': 0, '1month': 0, '3months': 0},
            'buy_sell_ratio': 50,
            'sentiment': 'NEUTRAL',
            'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'error': str(e)
        }


def render_signal_score(score_result):
    """ì‹ í˜¸ ì ìˆ˜ UI ë Œë”ë§"""
    import streamlit as st
    
    total_score = score_result['total_score']
    signal = score_result['signal']
    
    # ì‹ í˜¸ë³„ ìƒ‰ìƒ
    if signal == 'STRONG_BUY':
        color = '#00ff00'
        emoji = 'ğŸŸ¢'
    elif signal == 'BUY':
        color = '#7fff00'
        emoji = 'ğŸ”µ'
    elif signal == 'NEUTRAL':
        color = '#ffff00'
        emoji = 'âšª'
    elif signal == 'SELL':
        color = '#ff7f00'
        emoji = 'ğŸŸ '
    else:
        color = '#ff0000'
        emoji = 'ğŸ”´'
    
    # ì¢…í•© ì ìˆ˜ í‘œì‹œ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown(f"### {emoji} ì¢…í•© ì‹ í˜¸: **{signal}**")
        st.progress(total_score / 100)
        st.metric("ì¢…í•© ì ìˆ˜", f"{total_score:.1f} / 100")
    
    with col2:
        st.markdown("#### ì„¸ë¶€ ì ìˆ˜")
        st.text(f"íŒ¨í„´ ê°•ë„: {score_result['pattern_strength']:.0f}")
        st.text(f"ì¶”ì„¸ í•„í„°: {score_result['trend_filter']:.0f}")
        st.text(f"ë³€ë™ì„± í•„í„°: {score_result['volatility_filter']:.0f}")


def render_trading_metrics(metrics):
    """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ UI ë Œë”ë§"""
    import streamlit as st
    
    st.markdown("### ğŸ“Š ê¸°ê°„ë³„ ìˆ˜ìµë¥ ")
    
    returns = metrics['returns']
    col1, col2, col3 = st.columns(3)
    
    with col1:
        ret_1w = returns['1week']
        st.metric(
            label="1ì£¼ì¼",
            value=f"{ret_1w:+.2f}%",
            delta="ìƒìŠ¹" if ret_1w > 0 else "í•˜ë½"
        )
    
    with col2:
        ret_1m = returns['1month']
        st.metric(
            label="1ê°œì›”",
            value=f"{ret_1m:+.2f}%",
            delta="ìƒìŠ¹" if ret_1m > 0 else "í•˜ë½"
        )
    
    with col3:
        ret_3m = returns['3months']
        st.metric(
            label="3ê°œì›”",
            value=f"{ret_3m:+.2f}%",
            delta="ìƒìŠ¹" if ret_3m > 0 else "í•˜ë½"
        )
    
    st.markdown("### ğŸ¯ ì˜ˆìƒ ë§¤ë§¤ ë¹„ìœ¨")
    
    buy_ratio = metrics['buy_sell_ratio']
    sell_ratio = 100 - buy_ratio
    
    col1, col2 = st.columns([buy_ratio, sell_ratio] if sell_ratio > 0 else [1, 0.01])
    
    with col1:
        st.success(f"ë§¤ìˆ˜: {buy_ratio:.0f}%")
    
    with col2:
        if sell_ratio > 0:
            st.error(f"ë§¤ë„: {sell_ratio:.0f}%")
    
    st.markdown(f"**ì‹œì¥ ì‹¬ë¦¬**: {metrics['sentiment']}")
    st.caption(f"ğŸ• ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {metrics['last_update']}")

@st.cache_data(ttl=3600, show_spinner=False)  # 1ì‹œê°„ ìºì‹± (ì½”ì¸ ëª©ë¡ì€ ìì£¼ ë°”ë€”ì§€ ì•ŠìŒ)
def get_all_binance_usdt_pairs():
    """
    ë°”ì´ë‚¸ìŠ¤ì—ì„œ ê±°ë˜ ê°€ëŠ¥í•œ ëª¨ë“  USDT í˜ì–´ ê°€ì ¸ì˜¤ê¸°
    
    Returns:
    --------
    list : USDT í˜ì–´ ë¦¬ìŠ¤íŠ¸ [("ë¹„íŠ¸ì½”ì¸ (BTC)", "BTCUSDT"), ...]
    """
    try:
        url = "https://api.binance.com/api/v3/exchangeInfo"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        usdt_pairs = []
        
        for symbol_info in data['symbols']:
            symbol = symbol_info['symbol']
            status = symbol_info['status']
            
            # USDT í˜ì–´ì´ê³  ê±°ë˜ ê°€ëŠ¥í•œ ê²ƒë§Œ í•„í„°ë§
            if symbol.endswith('USDT') and status == 'TRADING':
                base_asset = symbol_info['baseAsset']
                
                # í•œê¸€ ì´ë¦„ ë§¤í•‘ (ì£¼ìš” ì½”ì¸)
                korean_names = {
                    'BTC': 'ë¹„íŠ¸ì½”ì¸',
                    'ETH': 'ì´ë”ë¦¬ì›€',
                    'BNB': 'ë°”ì´ë‚¸ìŠ¤ì½”ì¸',
                    'XRP': 'ë¦¬í”Œ',
                    'ADA': 'ì¹´ë‹¤ë…¸',
                    'SOL': 'ì†”ë¼ë‚˜',
                    'DOGE': 'ë„ì§€ì½”ì¸',
                    'DOT': 'í´ì¹´ë‹·',
                    'MATIC': 'í´ë¦¬ê³¤',
                    'SHIB': 'ì‹œë°”ì´ëˆ„',
                    'AVAX': 'ì•„ë°œë€ì²´',
                    'UNI': 'ìœ ë‹ˆìŠ¤ì™‘',
                    'LINK': 'ì²´ì¸ë§í¬',
                    'ATOM': 'ì½”ìŠ¤ëª¨ìŠ¤',
                    'LTC': 'ë¼ì´íŠ¸ì½”ì¸',
                    'ETC': 'ì´ë”ë¦¬ì›€í´ë˜ì‹',
                    'XLM': 'ìŠ¤í…”ë¼ë£¨ë©˜',
                    'NEAR': 'ë‹ˆì–´í”„ë¡œí† ì½œ',
                    'APT': 'ì•±í† ìŠ¤',
                    'FIL': 'íŒŒì¼ì½”ì¸',
                    'ARB': 'ì•„ë¹„íŠ¸ëŸ¼',
                    'OP': 'ì˜µí‹°ë¯¸ì¦˜',
                    'SUI': 'ìˆ˜ì´',
                    'TRX': 'íŠ¸ë¡ ',
                    'BCH': 'ë¹„íŠ¸ì½”ì¸ìºì‹œ',
                    'ALGO': 'ì•Œê³ ëœë“œ',
                    'VET': 'ë¹„ì²´ì¸',
                    'ICP': 'ì¸í„°ë„·ì»´í“¨í„°',
                    'FTM': 'íŒ¬í…€',
                    'XMR': 'ëª¨ë„¤ë¡œ',
                    'SAND': 'ìƒŒë“œë°•ìŠ¤',
                    'MANA': 'ë””ì„¼íŠ¸ëŸ´ëœë“œ',
                    'AXS': 'ì•¡ì‹œì¸í”¼ë‹ˆí‹°',
                    'THETA': 'ì„íƒ€',
                    'XTZ': 'í…Œì¡°ìŠ¤',
                    'AAVE': 'ì—ì´ë¸Œ',
                    'GRT': 'ë”ê·¸ë˜í”„',
                    'EOS': 'ì´ì˜¤ìŠ¤',
                    'MKR': 'ë©”ì´ì»¤',
                    'RUNE': 'í† ë¥´ì²´ì¸',
                    'KSM': 'ì¿ ì‚¬ë§ˆ',
                    'CAKE': 'íŒ¬ì¼€ì´í¬ìŠ¤ì™‘',
                    'CRV': 'ì»¤ë¸Œ',
                    'WAVES': 'ì›¨ì´ë¸Œ',
                    'ZEC': 'ì§€ìºì‹œ',
                    'DASH': 'ëŒ€ì‹œ',
                    'COMP': 'ì»´íŒŒìš´ë“œ',
                    'YFI': 'ì—°íŒŒì´ë‚¸ìŠ¤',
                    'SNX': 'ì‹ ì„¸í‹±ìŠ¤',
                    'BAT': 'ë² ì´ì§ì–´í…ì…˜í† í°',
                    'ENJ': 'ì—”ì§„ì½”ì¸',
                    'SUSHI': 'ìŠ¤ì‹œìŠ¤ì™‘',
                    '1INCH': 'ì›ì¸ì¹˜',
                    'CHZ': 'ì¹ ë¦¬ì¦ˆ',
                    'HBAR': 'í—¤ë°ë¼',
                    'HOT': 'í™€ë¡œì²´ì¸',
                    'ZIL': 'ì§ˆë¦¬ì¹´',
                    'ONT': 'ì˜¨í†¨ë¡œì§€',
                    'ICX': 'ì•„ì´ì½˜',
                    'QNT': 'í€€íŠ¸',
                    'LRC': 'ë£¨í”„ë§',
                    'CELO': 'ì…€ë¡œ',
                    'ANKR': 'ì•µì»¤',
                    'KAVA': 'ì¹´ë°”',
                    'BAND': 'ë°´ë“œí”„ë¡œí† ì½œ',
                    'SC': 'ì‹œì•„ì½”ì¸',
                    'RVN': 'ë ˆì´ë¸ì½”ì¸',
                    'ZEN': 'í˜¸ë¼ì´ì¦Œ',
                    'IOST': 'ì•„ì´ì˜¤ìŠ¤íŠ¸',
                    'CVC': 'ì‹œë¹…',
                    'STORJ': 'ìŠ¤í† ë¦¬ì§€',
                    'DYDX': 'ë””ì™€ì´ë””ì—‘ìŠ¤',
                    'GMX': 'ì§€ì— ì—‘ìŠ¤',
                    'LDO': 'ë¦¬ë„',
                    'BLUR': 'ë¸”ëŸ¬',
                    'PEPE': 'í˜í˜',
                    'FLOKI': 'í”Œë¡œí‚¤',
                    'INJ': 'ì¸ì í‹°ë¸Œ',
                    'STX': 'ìŠ¤íƒìŠ¤',
                    'IMX': 'ì´ë®¤í„°ë¸”ì—‘ìŠ¤',
                    'TIA': 'ì…€ë ˆìŠ¤í‹°ì•„',
                    'SEI': 'ì„¸ì´',
                    'PYTH': 'í”¼ìŠ¤ë„¤íŠ¸ì›Œí¬',
                    'JUP': 'ì£¼í”¼í„°',
                    'WIF': 'ë„ê·¸ìœ„í”„í–‡',
                    'BONK': 'ë´‰í¬',
                    'STRK': 'ìŠ¤íƒ€í¬ë„·',
                    'WLD': 'ì›”ë“œì½”ì¸',
                    'FET': 'í˜ì¹˜AI',
                    'AGIX': 'ì‹±ê·¤ë˜ë¦¬í‹°ë„·',
                    'RNDR': 'ë Œë”í† í°',
                    'GRT': 'ë”ê·¸ë˜í”„',
                    'OCEAN': 'ì˜¤ì…˜í”„ë¡œí† ì½œ'
                }
                
                if base_asset in korean_names:
                    display_name = f"{korean_names[base_asset]} ({base_asset})"
                else:
                    display_name = base_asset
                
                usdt_pairs.append((display_name, symbol))
        
        # ì‹¬ë³¼ ì•ŒíŒŒë²³ ìˆœì„œë¡œ ì •ë ¬
        usdt_pairs.sort(key=lambda x: x[1])
        
        return usdt_pairs
    
    except Exception as e:
        st.warning(f"âš ï¸ ë°”ì´ë‚¸ìŠ¤ API ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ëª©ë¡ ë°˜í™˜
        return [
            ("ë¹„íŠ¸ì½”ì¸ (BTC)", "BTCUSDT"),
            ("ì´ë”ë¦¬ì›€ (ETH)", "ETHUSDT"),
            ("ë¦¬í”Œ (XRP)", "XRPUSDT"),
            ("ë„ì§€ì½”ì¸ (DOGE)", "DOGEUSDT"),
            ("ì¹´ë‹¤ë…¸ (ADA)", "ADAUSDT"),
            ("ì†”ë¼ë‚˜ (SOL)", "SOLUSDT")
        ]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.6.0: ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_data(ttl=3600)
def get_fear_greed_index(limit=30):
    """
    Fear & Greed Index ê°€ì ¸ì˜¤ê¸° (Alternative.me API)
    
    Returns:
    --------
    dict or None
        - 'current_value': í˜„ì¬ ê°’ (0-100)
        - 'current_classification': ë¶„ë¥˜
        - 'historical_data': DataFrame
    """
    try:
        url = f'https://api.alternative.me/fng/?limit={limit}'
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        if 'data' not in data:
            return None
        
        current = data['data'][0]
        current_value = int(current['value'])
        current_classification = current['value_classification']
        
        historical = []
        for item in data['data']:
            historical.append({
                'timestamp': datetime.datetime.fromtimestamp(int(item['timestamp'])),
                'value': int(item['value']),
                'classification': item['value_classification']
            })
        
        historical_df = pd.DataFrame(historical)
        
        return {
            'current_value': current_value,
            'current_classification': current_classification,
            'historical_data': historical_df
        }
    except Exception as e:
        return None


def calculate_sharpe_ratio(returns, risk_free_rate=0.02):
    """
    Sharpe Ratio ê³„ì‚°
    
    Parameters:
    -----------
    returns : pd.Series
        ìˆ˜ìµë¥  ë°ì´í„°
    risk_free_rate : float
        ì—°ê°„ ë¬´ìœ„í—˜ ì´ììœ¨ (ê¸°ë³¸ 2%)
    
    Returns:
    --------
    float : Sharpe Ratio (ì—°ìœ¨í™”)
    """
    if len(returns) < 2:
        return 0.0
    
    daily_rf = risk_free_rate / 252
    excess_returns = returns - daily_rf
    
    if excess_returns.std() == 0:
        return 0.0
    
    sharpe = np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)
    return sharpe





def backtest_portfolio_simple(price_data_df, symbol_name):
    """
    ë‹¨ì¼ ì½”ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©)
    
    Parameters:
    -----------
    price_data_df : pd.DataFrame
        ê°€ê²© ë°ì´í„° (Close ì»¬ëŸ¼ í¬í•¨)
    symbol_name : str
        ì½”ì¸ ì‹¬ë³¼ (ì˜ˆ: 'BTCUSDT')
    
    Returns:
    --------
    dict or None
        - 'total_return': ì´ ìˆ˜ìµë¥ 
        - 'sharpe_ratio': Sharpe Ratio
        - 'max_drawdown': ìµœëŒ€ ë‚™í­
        - 'win_rate': ìŠ¹ë¥ 
        - 'portfolio_value': í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì‹œê³„ì—´
        - 'individual_returns': ê° ì½”ì¸ë³„ ìˆ˜ìµë¥ 
    """
    try:
        # Close ê°€ê²© ì¶”ì¶œ
        if 'Close' not in price_data_df.columns:
            return None
        
        prices = price_data_df['Close'].dropna()
        
        if len(prices) < 5:
            return None
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        returns = prices.pct_change().dropna()
        
        if len(returns) < 2:
            return None
        
        # ëˆ„ì  ìˆ˜ìµë¥ 
        cumulative_returns = (1 + returns).cumprod()
        portfolio_value = cumulative_returns * 1000  # ì´ˆê¸° íˆ¬ì $1000
        
        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        total_return = (cumulative_returns.iloc[-1] - 1) * 100
        sharpe = calculate_sharpe_ratio(returns)
        
        # ìµœëŒ€ ë‚™í­ (Maximum Drawdown)
        running_max = cumulative_returns.cummax()
        drawdown = (cumulative_returns - running_max) / running_max
        max_drawdown = drawdown.min() * 100
        
        # ìŠ¹ë¥  (ì–‘ì˜ ìˆ˜ìµë¥  ë¹„ìœ¨)
        win_rate = (returns > 0).sum() / len(returns) * 100
        
        # ì½”ì¸ë³„ ìˆ˜ìµë¥  (ë‹¨ì¼ ì½”ì¸)
        coin_short_name = symbol_name[:-4] if symbol_name.endswith('USDT') else symbol_name
        individual_returns = {
            coin_short_name: total_return
        }
        
        return {
            'total_return': total_return,
            'sharpe_ratio': sharpe,
            'max_drawdown': max_drawdown,
            'win_rate': win_rate,
            'portfolio_value': portfolio_value,
            'individual_returns': individual_returns
        }
    
    except Exception as e:
        return None



# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 3: ì‹¤ê±°ë˜ ì‹œë®¬ë ˆì´ì…˜ - ê±°ë˜ì†Œ í”„ë¦¬ì…‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ê±°ë˜ì†Œë³„ ìˆ˜ìˆ˜ë£Œ í”„ë¦¬ì…‹
EXCHANGE_PRESETS = {
    'ë°”ì´ë‚¸ìŠ¤ ì„ ë¬¼': {
        'maker_fee': 0.0002,  # 0.02%
        'taker_fee': 0.0004,  # 0.04%
        'max_leverage': 125,
        'slippage_rate': 0.0005,  # 0.05% (ê¸°ë³¸ ìŠ¬ë¦¬í”¼ì§€)
        'funding_rate': 0.0001,  # 8ì‹œê°„ë‹¹ 0.01% (í‰ê· )
    },
    'ë°”ì´ë¹„íŠ¸ ì„ ë¬¼': {
        'maker_fee': 0.0002,  # 0.02%
        'taker_fee': 0.0006,  # 0.06%
        'max_leverage': 100,
        'slippage_rate': 0.0006,  # 0.06%
        'funding_rate': 0.0001,
    },
    'ì‚¬ìš©ì ì •ì˜': {
        'maker_fee': 0.0002,
        'taker_fee': 0.0004,
        'max_leverage': 50,
        'slippage_rate': 0.0005,
        'funding_rate': 0.0001,
    }
}


def calculate_effective_leverage(nominal_leverage, stop_loss_pct, volatility):
    """
    ìœ íš¨ ë ˆë²„ë¦¬ì§€ ê³„ì‚°
    
    Parameters:
    -----------
    nominal_leverage : float
        ëª…ëª© ë ˆë²„ë¦¬ì§€
    stop_loss_pct : float
        ì†ì ˆ ë¹„ìœ¨ (%)
    volatility : float
        ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
    
    Returns:
    --------
    dict : ìœ íš¨ ë ˆë²„ë¦¬ì§€ ì •ë³´
        - 'effective': ìœ íš¨ ë ˆë²„ë¦¬ì§€
        - 'risk_adjusted': ë¦¬ìŠ¤í¬ ì¡°ì • ë ˆë²„ë¦¬ì§€
        - 'liquidation_distance': ì²­ì‚° ê±°ë¦¬ (%)
    """
    # ì²­ì‚° ê±°ë¦¬ ê³„ì‚°
    liquidation_distance = 100 / nominal_leverage  # %
    
    # ìœ íš¨ ë ˆë²„ë¦¬ì§€ (ì†ì ˆ ê³ ë ¤)
    effective = min(nominal_leverage, 100 / stop_loss_pct)
    
    # ë¦¬ìŠ¤í¬ ì¡°ì • ë ˆë²„ë¦¬ì§€ (ë³€ë™ì„± ê³ ë ¤)
    risk_adjusted = effective * (1 - min(volatility / 10, 0.5))
    
    return {
        'effective': effective,
        'risk_adjusted': risk_adjusted,
        'liquidation_distance': liquidation_distance
    }


def calculate_expected_fill_price(entry_price, side, slippage_rate, market_impact=0.0):
    """
    ê¸°ëŒ€ ì²´ê²°ê°€ ê³„ì‚° (ìŠ¬ë¦¬í”¼ì§€ ë°˜ì˜)
    
    Parameters:
    -----------
    entry_price : float
        ì§„ì… ê°€ê²©
    side : str
        'long' or 'short'
    slippage_rate : float
        ìŠ¬ë¦¬í”¼ì§€ ë¹„ìœ¨ (0.0005 = 0.05%)
    market_impact : float
        ì‹œì¥ ì¶©ê²© ë¹„ìœ¨ (í° ì£¼ë¬¸ì¼ ê²½ìš° ì¶”ê°€)
    
    Returns:
    --------
    dict : ì²´ê²° ì •ë³´
        - 'expected_price': ê¸°ëŒ€ ì²´ê²°ê°€
        - 'slippage_amount': ìŠ¬ë¦¬í”¼ì§€ ê¸ˆì•¡
        - 'slippage_pct': ìŠ¬ë¦¬í”¼ì§€ í¼ì„¼íŠ¸
    """
    total_slippage = slippage_rate + market_impact
    
    if side == 'long':
        # ë§¤ìˆ˜: ê°€ê²©ì´ ì˜¬ë¼ê°€ë¯€ë¡œ ë¶ˆë¦¬
        expected_price = entry_price * (1 + total_slippage)
        slippage_amount = expected_price - entry_price
    else:  # short
        # ë§¤ë„: ê°€ê²©ì´ ë‚´ë ¤ê°€ë¯€ë¡œ ë¶ˆë¦¬
        expected_price = entry_price * (1 - total_slippage)
        slippage_amount = entry_price - expected_price
    
    slippage_pct = (slippage_amount / entry_price) * 100
    
    return {
        'expected_price': expected_price,
        'slippage_amount': slippage_amount,
        'slippage_pct': slippage_pct
    }


def calculate_trading_costs(position_size, entry_price, exit_price, 
                           leverage, exchange_preset, holding_hours=24):
    """
    ì´ ê±°ë˜ ë¹„ìš© ê³„ì‚° (ìˆ˜ìˆ˜ë£Œ + ìŠ¬ë¦¬í”¼ì§€ + í€ë”© ë¹„ìš©)
    
    Parameters:
    -----------
    position_size : float
        í¬ì§€ì…˜ í¬ê¸° (ì½”ì¸ ìˆ˜ëŸ‰)
    entry_price : float
        ì§„ì…ê°€
    exit_price : float
        ì²­ì‚°ê°€
    leverage : float
        ë ˆë²„ë¦¬ì§€
    exchange_preset : dict
        ê±°ë˜ì†Œ í”„ë¦¬ì…‹
    holding_hours : int
        ë³´ìœ  ì‹œê°„ (ì‹œê°„)
    
    Returns:
    --------
    dict : ë¹„ìš© ë‚´ì—­
    """
    position_value = position_size * entry_price
    
    # 1. ì§„ì… ìˆ˜ìˆ˜ë£Œ (Taker)
    entry_fee = position_value * exchange_preset['taker_fee']
    
    # 2. ì§„ì… ìŠ¬ë¦¬í”¼ì§€
    entry_slip = calculate_expected_fill_price(
        entry_price, 'long', exchange_preset['slippage_rate']
    )
    entry_slippage_cost = position_size * entry_slip['slippage_amount']
    
    # 3. ì²­ì‚° ìˆ˜ìˆ˜ë£Œ (Taker)
    exit_value = position_size * exit_price
    exit_fee = exit_value * exchange_preset['taker_fee']
    
    # 4. ì²­ì‚° ìŠ¬ë¦¬í”¼ì§€
    exit_slip = calculate_expected_fill_price(
        exit_price, 'short', exchange_preset['slippage_rate']
    )
    exit_slippage_cost = position_size * exit_slip['slippage_amount']
    
    # 5. í€ë”© ë¹„ìš© (8ì‹œê°„ë§ˆë‹¤)
    funding_periods = holding_hours / 8
    funding_cost = position_value * exchange_preset['funding_rate'] * funding_periods
    
    total_cost = entry_fee + exit_fee + entry_slippage_cost + exit_slippage_cost + funding_cost
    
    return {
        'entry_fee': entry_fee,
        'exit_fee': exit_fee,
        'entry_slippage': entry_slippage_cost,
        'exit_slippage': exit_slippage_cost,
        'funding_cost': funding_cost,
        'total_cost': total_cost,
        'cost_pct': (total_cost / position_value) * 100
    }


def calibrate_talib_pattern_confidence(pattern_value, candle_range, volatility):
    """
    TA-Lib íŒ¨í„´ ì‹ ë¢°ë„ êµì •
    
    Parameters:
    -----------
    pattern_value : int
        TA-Lib íŒ¨í„´ ê°’ (-100 ~ 100)
    candle_range : float
        ë´‰ ê¸¸ì´ (ê³ ê°€ - ì €ê°€)
    volatility : float
        ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
    
    Returns:
    --------
    float : êµì •ëœ ì‹ ë¢°ë„ (0 ~ 100)
    """
    # 1. ê¸°ë³¸ ì‹ ë¢°ë„ (ì ˆëŒ“ê°’ ë³€í™˜)
    base_confidence = abs(pattern_value)
    
    # 2. ë´‰ ê¸¸ì´ ì •ê·œí™” (ê¸´ ë´‰ì¼ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€)
    avg_candle_range = volatility * 2  # í‰ê·  ë´‰ ê¸¸ì´ ì¶”ì •
    if avg_candle_range > 0:
        range_factor = min(candle_range / avg_candle_range, 2.0)  # ìµœëŒ€ 2ë°°
    else:
        range_factor = 1.0
    
    # 3. ë³€ë™ì„± ëŒ€ë¹„ ìŠ¤ì¼€ì¼ë§
    # ê³ ë³€ë™ì„± ì‹œì¥: íŒ¨í„´ ì‹ ë¢°ë„ ê°ì†Œ
    volatility_factor = 1 / (1 + volatility / 10)
    
    # 4. ìµœì¢… ì‹ ë¢°ë„
    calibrated = base_confidence * range_factor * volatility_factor
    
    return min(calibrated, 100.0)



MAX_LEVERAGE_MAP = {
    "BTCUSDT": 125,
    "ETHUSDT": 100,
    "XRPUSDT": 75,
    "DOGEUSDT": 50,
    "ADAUSDT": 75,
    "SOLUSDT": 50
}

RESOLUTION_MAP = {
    "1ë¶„ë´‰ (1m)": "1m",
    "5ë¶„ë´‰ (5m)": "5m",
    "1ì‹œê°„ë´‰ (1h)": "1h",
    "1ì¼ë´‰ (1d)": "1d"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ë°ì´í„° ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=900, show_spinner=False)  # 15ë¶„ ìºì‹± (ì°¨íŠ¸ ë°ì´í„°)
def load_crypto_data(
    symbol: str,
    start: datetime.date,
    end: datetime.date,
    interval: str = '1d'
) -> pd.DataFrame:
    """ì•”í˜¸í™”í ë°ì´í„° ë¡œë“œ"""
    df = pd.DataFrame()
    yf_ticker = symbol[:-4] + "-USD"
    
    days_diff = (end - start).days
    
    interval_limits = {
        '1m': 7,
        '5m': 60,
        '1h': 730,
        '1d': 99999
    }
    
    max_days = interval_limits.get(interval, 99999)
    
    if days_diff > max_days:
        start = end - datetime.timedelta(days=max_days)
    
    try:
        ticker = yf.Ticker(yf_ticker)
        
        if days_diff <= 7:
            period = '7d'
        elif days_diff <= 30:
            period = '1mo'
        elif days_diff <= 90:
            period = '3mo'
        elif days_diff <= 180:
            period = '6mo'
        elif days_diff <= 365:
            period = '1y'
        elif days_diff <= 730:
            period = '2y'
        else:
            period = 'max'
        
        df_hist = ticker.history(period=period, interval=interval, auto_adjust=True, actions=False)
        
        if df_hist is not None and not df_hist.empty:
            df_hist = df_hist[(df_hist.index.date >= start) & (df_hist.index.date <= end)]
            
            if not df_hist.empty:
                df = df_hist.copy()
                if 'Volume' in df.columns:
                    df = df[df['Volume'] > 0].copy()
                if not df.empty:
                    return df
    except Exception as e:
        pass
    
    if df.empty:
        try:
            ticker = yf.Ticker(yf_ticker)
            df_hist = ticker.history(
                start=start,
                end=end + datetime.timedelta(days=1),
                interval=interval,
                auto_adjust=True,
                actions=False
            )
            if df_hist is not None and not df_hist.empty:
                df = df_hist.copy()
                if 'Volume' in df.columns:
                    df = df[df['Volume'] > 0].copy()
                if not df.empty:
                    return df
        except Exception as e:
            pass

    if df.empty:
        try:
            df_max = yf.download(
                yf_ticker,
                period=period if days_diff <= 730 else '2y',
                interval=interval,
                progress=False,
                threads=False,
                auto_adjust=True,
                actions=False
            )
            if df_max is not None and not df_max.empty:
                df = df_max.copy()
                if 'Volume' in df.columns:
                    df = df[df['Volume'] > 0].copy()
        except Exception as e:
            pass

    if df is not None and not df.empty:
        # MultiIndex ì»´ëŸ¼ ì²˜ë¦¬ (yf.downloadê°€ MultiIndex ë°˜í™˜í•˜ëŠ” ê²½ìš°)
        if isinstance(df.columns, pd.MultiIndex):
            # ì»´ëŸ¼ì´ ('Close', 'BTC-USD') í˜•íƒœì¸ ê²½ìš° í‰íƒ„í™”
            df.columns = df.columns.get_level_values(0)
        
        # í•„ìˆ˜ ì»´ëŸ¼ í™•ì¸
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        if all(col in df.columns for col in required_cols):
            return df
    
    return pd.DataFrame()


def add_candlestick_pattern_features(df: pd.DataFrame, window: int = 20) -> pd.DataFrame:
    """
    ìº ë“¤ìŠ¤í‹± íŒ¨í„´ íŠ¹ì§• ì¶”ê°€ (AI ëª¨ë¸ í•™ìŠµìš©)
    
    6ê°œ íŠ¹ì§• ì¶”ê°€:
    - pattern_bullish: ìƒìŠ¹ íŒ¨í„´ ê°œìˆ˜ (ìµœê·¼ 20 ìº ë“¤)
    - pattern_bearish: í•˜ë½ íŒ¨í„´ ê°œìˆ˜ (ìµœê·¼ 20 ìº ë“¤)
    - pattern_strength: í‰ê·  ì‹ ë¢°ë„ (0-100)
    - pattern_momentum: (-1 to +1, ìƒìŠ¹/í•˜ë½ ë°¸ëŸ°ìŠ¤)
    - pattern_recency: ìµœê·¼ì„± (0-1, ì§€ìˆ˜ ê°ì‡ )
    - pattern_diversity: ë‹¤ì–‘ì„± (0-1)
    """
    df = df.copy()
    
    # ì´ˆê¸°í™”
    df['pattern_bullish'] = 0.0
    df['pattern_bearish'] = 0.0
    df['pattern_strength'] = 0.0
    df['pattern_momentum'] = 0.0
    df['pattern_recency'] = 0.0
    df['pattern_diversity'] = 0.0
    
    if not TALIB_AVAILABLE or len(df) < 5:
        return df
    
    try:
        # íŒ¨í„´ ë°©í–¥ ë§¤í•‘ (ê°„ëµí™”ëœ ë²„ì „)
        bullish_patterns = [
            'CDLHAMMER', 'CDLINVERTEDHAMMER', 'CDLMORNINGSTAR', 'CDL3WHITESOLDIERS',
            'CDLPIERCING', 'CDLMATCHINGLOW', 'CDLHOMINGPIGEON', 'CDLTAKURI',
            'CDLMATHOLD', 'CDLCONCEALBABYSWALL', 'CDLLADDERBOTTOM', 'CDLUNIQUE3RIVER',
            'CDL3STARSINSOUTH'
        ]
        
        bearish_patterns = [
            'CDLSHOOTINGSTAR', 'CDLHANGINGMAN', 'CDLEVENINGSTAR', 'CDL3BLACKCROWS',
            'CDLDARKCLOUDCOVER', 'CDLONNECK', 'CDLINNECK', 'CDLTHRUSTING',
            'CDL2CROWS', 'CDLIDENTICAL3CROWS', 'CDLADVANCEBLOCK', 'CDLSTALLEDPATTERN',
            'CDLUPSIDEGAP2CROWS'
        ]
        
        # ëª¨ë“  íŒ¨í„´ ê°ì§€ ê²°ê³¼ ì €ì¥
        all_pattern_results = {}
        
        for pattern_list, pattern_type in [(bullish_patterns, 'bullish'), (bearish_patterns, 'bearish')]:
            for pattern_name in pattern_list:
                if hasattr(talib, pattern_name):
                    try:
                        pattern_func = getattr(talib, pattern_name)
                        result = pattern_func(df['Open'].values, df['High'].values, 
                                            df['Low'].values, df['Close'].values)
                        all_pattern_results[pattern_name] = (result, pattern_type)
                    except:
                        continue
        
        # ê° í–‰ì— ëŒ€í•´ ìœˆë„ìš° ê¸°ë°˜ íŠ¹ì§• ê³„ì‚°
        for i in range(window, len(df)):
            bullish_count = 0
            bearish_count = 0
            confidences = []
            unique_patterns = set()
            min_distance = window
            
            # ìœˆë„ìš° ë²”ìœ„
            start_idx = i - window
            end_idx = i + 1
            
            # ëª¨ë“  íŒ¨í„´ ê²°ê³¼ ê²€ì‚¬
            for pattern_name, (result, pattern_type) in all_pattern_results.items():
                for j in range(start_idx, end_idx):
                    if j < 0 or j >= len(result):
                        continue
                    
                    if result[j] != 0:
                        conf = abs(result[j])
                        confidences.append(conf)
                        unique_patterns.add(pattern_name)
                        
                        if pattern_type == 'bullish':
                            bullish_count += 1
                        else:
                            bearish_count += 1
                        
                        distance = i - j
                        if distance < min_distance:
                            min_distance = distance
            
            # íŠ¹ì§• ê°’ ì„¤ì •
            total_patterns = bullish_count + bearish_count
            
            df.iloc[i, df.columns.get_loc('pattern_bullish')] = bullish_count
            df.iloc[i, df.columns.get_loc('pattern_bearish')] = bearish_count
            
            if confidences:
                df.iloc[i, df.columns.get_loc('pattern_strength')] = np.mean(confidences)
            
            if total_patterns > 0:
                # ëª¨ë©˜í…€ (-1 to +1)
                momentum = (bullish_count - bearish_count) / (total_patterns + 1)
                df.iloc[i, df.columns.get_loc('pattern_momentum')] = momentum
                
                # ìµœê·¼ì„± (ì§€ìˆ˜ ê°ì‡ )
                recency = np.exp(-min_distance / 5)
                df.iloc[i, df.columns.get_loc('pattern_recency')] = recency
                
                # ë‹¤ì–‘ì„±
                diversity = len(unique_patterns) / total_patterns
                df.iloc[i, df.columns.get_loc('pattern_diversity')] = diversity
    
    except Exception as e:
        pass
    
    return df


def calculate_indicators_wilders(df: pd.DataFrame) -> pd.DataFrame:
    """ì ì‘í˜• ì§€í‘œ ê³„ì‚°"""
    df = df.copy()
    data_len = len(df)
    
    df['ì¼ì¼ìˆ˜ìµë¥ '] = df['Close'].pct_change()

    window_12 = min(12, max(3, data_len // 10))
    window_14 = min(14, max(3, data_len // 8))
    window_20 = min(20, max(5, data_len // 6))
    window_26 = min(26, max(5, data_len // 5))
    window_30 = min(30, max(5, data_len // 4))
    window_50 = min(50, max(10, data_len // 3))
    window_200 = min(200, max(20, data_len // 2))
    
    if data_len >= window_50:
        df['MA50'] = df['Close'].rolling(window=window_50).mean()
        df['EMA50'] = df['Close'].ewm(span=window_50, adjust=False).mean()
    else:
        df['MA50'] = df['Close'].rolling(window=max(3, data_len // 3)).mean()
        df['EMA50'] = df['Close'].ewm(span=max(3, data_len // 3), adjust=False).mean()
    
    if data_len >= window_200:
        df['EMA200'] = df['Close'].ewm(span=window_200, adjust=False).mean()
    else:
        df['EMA200'] = df['Close'].ewm(span=max(10, data_len // 2), adjust=False).mean()
    
    df['EMA12'] = df['Close'].ewm(span=window_12, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=window_26, adjust=False).mean()

    # RSI (Wilder's Smoothing)
    delta = df['Close'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    
    period = window_14
    alpha = 1.0 / period
    
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    
    if data_len > period:
        for i in range(period, len(df)):
            avg_gain.iloc[i] = alpha * gain.iloc[i] + (1 - alpha) * avg_gain.iloc[i - 1]
            avg_loss.iloc[i] = alpha * loss.iloc[i] + (1 - alpha) * avg_loss.iloc[i - 1]
    
    rs = avg_gain / (avg_loss + 1e-8)
    df['RSI14'] = 100 - (100 / (1 + rs))

    # ATR (Wilder's Smoothing)
    high = df['High']
    low = df['Low']
    close = df['Close']
    prev_close = close.shift(1)
    
    tr1 = high - low
    tr2 = (high - prev_close).abs()
    tr3 = (low - prev_close).abs()
    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    
    df['TR'] = true_range
    
    atr = true_range.rolling(window=period).mean()
    if data_len > period:
        for i in range(period, len(df)):
            atr.iloc[i] = alpha * true_range.iloc[i] + (1 - alpha) * atr.iloc[i - 1]
    
    df['ATR14'] = atr
    df['Volatility30d'] = df['ì¼ì¼ìˆ˜ìµë¥ '].rolling(window=window_30).std()

    # Stochastic
    df['StochK14'] = 0.0
    if data_len >= window_14:
        low14 = df['Low'].rolling(window=window_14).min()
        high14 = df['High'].rolling(window=window_14).max()
        df['StochK14'] = (df['Close'] - low14) / (high14 - low14 + 1e-8) * 100

    # MFI
    typical_price = (df['High'] + df['Low'] + df['Close']) / 3
    df['MF'] = typical_price * df['Volume']
    # ì¡°ê±´ë¶€ í• ë‹¹ (pandas í˜¸í™˜ì„± ê°œì„ )
    price_change = df['Close'].diff()
    df['PosMF'] = df['MF'].copy()
    df.loc[price_change <= 0, 'PosMF'] = 0
    df['NegMF'] = df['MF'].copy()
    df.loc[price_change >= 0, 'NegMF'] = 0
    roll_pos = df['PosMF'].rolling(window=window_14).sum()
    roll_neg = df['NegMF'].rolling(window=window_14).sum()
    df['MFI14'] = 100 - (100 / (1 + roll_pos / (roll_neg + 1e-8)))

    # VWAP
    df['PV'] = df['Close'] * df['Volume']
    df['Cum_PV'] = df['PV'].cumsum()
    df['Cum_Vol'] = df['Volume'].cumsum()
    df['VWAP'] = df['Cum_PV'] / (df['Cum_Vol'] + 1e-8)

    df['Vol_MA20'] = df['Volume'].rolling(window=window_20).mean()

    # MACD
    df['MACD'] = df['EMA12'] - df['EMA26']
    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']

    # Bollinger Bands (ì¶”ê°€)
    df['BB_middle'] = df['Close'].rolling(window=window_20).mean()
    df['BB_std'] = df['Close'].rolling(window=window_20).std()
    df['BB_upper'] = df['BB_middle'] + (df['BB_std'] * 2)
    df['BB_lower'] = df['BB_middle'] - (df['BB_std'] * 2)

    # EMA êµì°¨
    df['Cross_Signal'] = 0
    ema50 = df['EMA50']
    ema200 = df['EMA200']
    cond_up = (ema50 > ema200) & (ema50.shift(1) <= ema200.shift(1))
    cond_down = (ema50 < ema200) & (ema50.shift(1) >= ema200.shift(1))
    df.loc[cond_up, 'Cross_Signal'] = 1
    df.loc[cond_down, 'Cross_Signal'] = -1

    # [v2.7.1 ìƒˆë¡œ ì¶”ê°€] ìº ë“¤ìŠ¤í‹± íŒ¨í„´ íŠ¹ì§• ì¶”ê°€
    df = add_candlestick_pattern_features(df)
    
    essential_cols = ['Close', 'High', 'Low', 'Volume', 'ì¼ì¼ìˆ˜ìµë¥ ']
    df_clean = df.dropna(subset=essential_cols)
    
    optional_cols = ['RSI14', 'ATR14', 'StochK14', 'MFI14', 'MACD', 'MACD_Signal',
                     'pattern_bullish', 'pattern_bearish', 'pattern_strength',
                     'pattern_momentum', 'pattern_recency', 'pattern_diversity']
    for col in optional_cols:
        if col in df_clean.columns:
            df_clean[col].fillna(0, inplace=True)
    
    return df_clean


def detect_candlestick_patterns_talib(df: pd.DataFrame) -> list:
    """TA-Lib ê¸°ë°˜ 61ê°œ íŒ¨í„´ ê°ì§€"""
    patterns = []
    
    if len(df) < 5:  # ìµœì†Œ 5ê°œ í•„ìš” (ì¼ë¶€ íŒ¨í„´ì´ 5ë´‰ ìš”êµ¬)
        return []
    
    df_sorted = df.sort_index()
    open_prices = df_sorted['Open'].values
    high_prices = df_sorted['High'].values
    low_prices = df_sorted['Low'].values
    close_prices = df_sorted['Close'].values
    
    # TA-Lib íŒ¨í„´ ì •ì˜ (58ê°œ + ê¸°ì¡´ 3ê°œ = 61ê°œ)
    pattern_functions = {
        # ë‹¨ì¼(1-ìº”ë“¤) - 15ê°œ
        'CDLBELTHOLD': ('ğŸ”¨ Belt Hold', 'ë²¨íŠ¸ í™€ë“œ', 'ë‹¨ì¼'),
        'CDLCLOSINGMARUBOZU': ('ğŸ“Š Closing Marubozu', 'ì¢…ê°€ ë§ˆë£¨ë³´ì¦ˆ', 'ë‹¨ì¼'),
        'CDLMARUBOZU': ('ğŸ“ Marubozu', 'ë§ˆë£¨ë³´ì¦ˆ', 'ë‹¨ì¼'),
        'CDLLONGLINE': ('ğŸ“ Long Line', 'ì¥ëŒ€ë´‰', 'ë‹¨ì¼'),
        'CDLSHORTLINE': ('ğŸ“Œ Short Line', 'ë‹¨ë´‰', 'ë‹¨ì¼'),
        'CDLSPINNINGTOP': ('ğŸŒªï¸ Spinning Top', 'íŒ½ì´í˜•', 'ë‹¨ì¼'),
        'CDLHIGHWAVE': ('ğŸŒŠ High Wave', 'ë†’ì€ íŒŒë™í˜•', 'ë‹¨ì¼'),
        'CDLHAMMER': ('ğŸ”¨ Hammer', 'í•´ë¨¸', 'ë‹¨ì¼'),
        'CDLHANGINGMAN': ('ğŸ‘¤ Hanging Man', 'êµìˆ˜í˜•', 'ë‹¨ì¼'),
        'CDLINVERTEDHAMMER': ('ğŸ”§ Inverted Hammer', 'ì—­ë§ì¹˜', 'ë‹¨ì¼'),
        'CDLSHOOTINGSTAR': ('â­ Shooting Star', 'ìœ ì„±í˜•', 'ë‹¨ì¼'),
        'CDLRICKSHAWMAN': ('ğŸš¶ Rickshaw Man', 'ë¦­ìƒ¤ë§¨', 'ë‹¨ì¼'),
        'CDLTAKURI': ('ğŸ£ Takuri', 'íƒ€ì¿ ë¦¬', 'ë‹¨ì¼'),
        'CDLKICKING': ('ğŸ‘Ÿ Kicking', 'í‚¥í‚¹', 'ë‹¨ì¼'),
        'CDLKICKINGBYLENGTH': ('ğŸ‘¢ Kicking by Length', 'í‚¥í‚¹(ê¸¸ì´ ê¸°ì¤€)', 'ë‹¨ì¼'),
        
        # 2-ìº”ë“¤ - 12ê°œ
        'CDLENGULFING': ('ğŸ«‚ Engulfing', 'í¬ìš©í˜•', '2-ìº”ë“¤'),
        'CDLHARAMI': ('ğŸ¤° Harami', 'í•˜ë¼ë¯¸', '2-ìº”ë“¤'),
        'CDLHARAMICROSS': ('â• Harami Cross', 'í•˜ë¼ë¯¸ í¬ë¡œìŠ¤', '2-ìº”ë“¤'),
        'CDLPIERCING': ('ğŸ¯ Piercing', 'ê´€í†µí˜•', '2-ìº”ë“¤'),
        'CDLDARKCLOUDCOVER': ('â˜ï¸ Dark Cloud Cover', 'ì•”ìš´í˜•', '2-ìº”ë“¤'),
        'CDLCOUNTERATTACK': ('âš”ï¸ Counterattack', 'ë°˜ê²©ì„ ', '2-ìº”ë“¤'),
        'CDLONNECK': ('ğŸ¦¢ On Neck', 'ì˜¨ë„¥', '2-ìº”ë“¤'),
        'CDLINNECK': ('ğŸ¦† In Neck', 'ì¸ë„¥', '2-ìº”ë“¤'),
        'CDLTHRUSTING': ('ğŸ—¡ï¸ Thrusting', 'ìŠ¤ëŸ¬ìŠ¤íŒ…', '2-ìº”ë“¤'),
        'CDLSEPARATINGLINES': ('â†”ï¸ Separating Lines', 'ì„¸í¼ë ˆì´íŒ… ë¼ì¸', '2-ìº”ë“¤'),
        'CDLMATCHINGLOW': ('ğŸ¯ Matching Low', 'ë§¤ì¹­ ë¡œìš°', '2-ìº”ë“¤'),
        'CDLHOMINGPIGEON': ('ğŸ•Šï¸ Homing Pigeon', 'í˜¸ë° í”¼ì „', '2-ìº”ë“¤'),
        
        # 3-ìº”ë“¤ - 11ê°œ
        'CDL2CROWS': ('ğŸ¦ Two Crows', 'íˆ¬ í¬ë¡œìš°ì¦ˆ', '3-ìº”ë“¤'),
        'CDL3INSIDE': ('ğŸ“¦ Three Inside', 'ì‚¼ë‚´ë¶€', '3-ìº”ë“¤'),
        'CDL3OUTSIDE': ('ğŸ“¤ Three Outside', 'ì‚¼ì™¸ë¶€', '3-ìº”ë“¤'),
        'CDL3LINESTRIKE': ('âš¡ Three Line Strike', 'ì“°ë¦¬ ë¼ì¸ ìŠ¤íŠ¸ë¼ì´í¬', '3-ìº”ë“¤'),
        'CDL3BLACKCROWS': ('ğŸ¦â€â¬› Three Black Crows', 'ì„¸ ê²€ì€ ê¹Œë§ˆê·€', '3-ìº”ë“¤'),
        'CDLIDENTICAL3CROWS': ('ğŸ¦… Identical Three Crows', 'ë™ì¼ ì‚¼ê¹Œë§ˆê·€', '3-ìº”ë“¤'),
        'CDLUNIQUE3RIVER': ('ğŸï¸ Unique 3 River', 'ìœ ë‹ˆí¬ ì“°ë¦¬ ë¦¬ë²„', '3-ìº”ë“¤'),
        'CDL3STARSINSOUTH': ('â­ Three Stars in South', 'ë‚¨ìª½ì˜ ì„¸ ë³„', '3-ìº”ë“¤'),
        'CDLUPSIDEGAP2CROWS': ('ğŸ“ˆ Upside Gap Two Crows', 'ì—…ì‚¬ì´ë“œ ê°­ íˆ¬ í¬ë¡œìš°ì¦ˆ', '3-ìº”ë“¤'),
        'CDLEVENINGSTAR': ('ğŸŒ† Evening Star', 'ì„ë³„í˜•', '3-ìº”ë“¤'),
        'CDLTRISTAR': ('âœ¨ Tristar', 'íŠ¸ë¦¬ìŠ¤íƒ€', '3-ìº”ë“¤'),
        
        # ê°­/ì§€ì†/ë³µí•© - 9ê°œ
        'CDLBREAKAWAY': ('ğŸš€ Breakaway', 'ë¸Œë ˆì´í¬ì–´ì›¨ì´', 'ë³µí•©'),
        'CDLRISEFALL3METHODS': ('ğŸ“Š Rising/Falling 3 Methods', 'ìƒìŠ¹í•˜ë½ ì‚¼ë²•', 'ë³µí•©'),
        'CDLMATHOLD': ('ğŸ¤ Mat Hold', 'ë§¤íŠ¸ í™€ë“œ', 'ë³µí•©'),
        'CDLTASUKIGAP': ('ğŸ“ Tasuki Gap', 'íƒ€ìŠ¤í‚¤ ê°­', 'ë³µí•©'),
        'CDLGAPSIDESIDEWHITE': ('â¬œ Gap Side-by-Side White', 'ê°­ ì‚¬ì´ë“œë°”ì´ì‚¬ì´ë“œ', 'ë³µí•©'),
        'CDLXSIDEGAP3METHODS': ('ğŸ“ˆ Gap Three Methods', 'ê°­ ì“°ë¦¬ ë©”ì„œì¦ˆ', 'ë³µí•©'),
        'CDLABANDONEDBABY': ('ğŸ‘¶ Abandoned Baby', 'ì–´ë°´ë˜ë“œ ë² ì´ë¹„', 'ë³µí•©'),
        'CDLCONCEALBABYSWALL': ('ğŸ¦ Concealing Baby Swallow', 'ì»¨ì‹¤ë§ ë² ì´ë¹„', 'ë³µí•©'),
        'CDLLADDERBOTTOM': ('ğŸªœ Ladder Bottom', 'ë˜ë” ë°”í…€', 'ë³µí•©'),
        
        # íŠ¹ìˆ˜ - 5ê°œ
        'CDLADVANCEBLOCK': ('ğŸš§ Advance Block', 'ì „ì§„ ë´‰ì‡„', 'íŠ¹ìˆ˜'),
        'CDLSTALLEDPATTERN': ('â¸ï¸ Stalled Pattern', 'ì •ì²´ íŒ¨í„´', 'íŠ¹ìˆ˜'),
        'CDLSTICKSANDWICH': ('ğŸ¥ª Stick Sandwich', 'ìŠ¤í‹± ìƒŒë“œìœ„ì¹˜', 'íŠ¹ìˆ˜'),
        'CDLHIKKAKE': ('ğŸ£ Hikkake', 'í›ì¹´ì¼€', 'íŠ¹ìˆ˜'),
        'CDLHIKKAKEMOD': ('ğŸ¯ Modified Hikkake', 'ìˆ˜ì • í›ì¹´ì¼€', 'íŠ¹ìˆ˜'),
        
        # ê¸°ì¡´ 3ê°œ (TA-Libì—ë„ ìˆì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€)
        'CDL3WHITESOLDIERS': ('âšª Three White Soldiers', 'ì„¸ ê°œì˜ ì—°ì† ì–‘ë´‰', '3-ìº”ë“¤'),
        'CDLMORNINGSTAR': ('ğŸŒ… Morning Star', 'í•˜ë½ í›„ ë°˜ì „ ì‹ í˜¸', '3-ìº”ë“¤'),
        'CDLDOJI': ('âœ–ï¸ Doji', 'ë§¤ìˆ˜/ë§¤ë„ ê· í˜•', 'ë‹¨ì¼'),
    }
    
    # ê° íŒ¨í„´ ê°ì§€
    for func_name, (emoji_name, korean_name, category) in pattern_functions.items():
        try:
            if not hasattr(talib, func_name):
                continue
                
            pattern_func = getattr(talib, func_name)
            result = pattern_func(open_prices, high_prices, low_prices, close_prices)
            
            # íŒ¨í„´ ë°œìƒ ì§€ì  ì°¾ê¸°
            for i, value in enumerate(result):
                if value != 0:  # 0ì´ ì•„ë‹ˆë©´ íŒ¨í„´ ë°œìƒ
                    # ì‹ ë¢°ë„ ë³€í™˜: -100~100 â†’ 0~100%
                    confidence = abs(value)
                    
                    # ë°©í–¥ íŒë‹¨
                    if value > 0:
                        direction = 'ìƒìŠ¹'
                        impact = 'ìƒìŠ¹ ì‹ í˜¸'
                    elif value < 0:
                        direction = 'í•˜ë½'
                        impact = 'í•˜ë½ ì‹ í˜¸'
                    else:
                        direction = 'ì¤‘ë¦½'
                        impact = 'ì¶”ì„¸ ì „í™˜ ê°€ëŠ¥ì„±'
                    
                    patterns.append({
                        'name': emoji_name,
                        'category': category,
                        'date': df_sorted.index[i],
                        'conf': confidence,
                        'desc': korean_name,
                        'impact': impact,
                        'direction': direction
                    })
        except Exception as e:
            continue
    
    # ê°™ì€ íŒ¨í„´ëª…ì€ ìµœì‹  1ê°œë§Œ
    unique_patterns = {}
    for pattern in reversed(patterns):
        pattern_name = pattern['name']
        if pattern_name not in unique_patterns:
            unique_patterns[pattern_name] = pattern
    
    result = list(unique_patterns.values())
    result.sort(key=lambda x: x['date'], reverse=True)
    
    return result[:10]  # ìµœëŒ€ 10ê°œ


def detect_candlestick_patterns(df: pd.DataFrame) -> list:
    """ìº”ë“¤ìŠ¤í‹± íŒ¨í„´ ê°ì§€ (TA-Lib ìˆìœ¼ë©´ 61ê°œ, ì—†ìœ¼ë©´ 3ê°œ)"""
    if TALIB_AVAILABLE:
        return detect_candlestick_patterns_talib(df)
    else:
        return detect_candlestick_patterns_basic(df)


def calculate_exit_strategy(df: pd.DataFrame, entry_price: float, atr: float, 
                            investment_amount: float, leverage: float, interval: str = '1h') -> dict:
    """
    ë§¤ë„ ì‹œì  ì˜ˆì¸¡
    - ë³´ìˆ˜ì /ì¤‘ë¦½/ê³µê²©ì  ì‹œë‚˜ë¦¬ì˜¤ ì œê³µ
    - ATR ê¸°ë°˜ ë™ì  ì†ì ˆ/ìµì ˆ
    - ì¶”ì„¸ ì „í™˜ ì‹ í˜¸ ê°ì§€
    - ì‹œê°„ ê¸°ë°˜ ì˜ˆì¸¡ (ë¶„/ì‹œê°„/ì¼ ë‹¨ìœ„)
    """
    current_price = df['Close'].iloc[-1]
    rsi = df['RSI14'].iloc[-1]
    ema50 = df['EMA50'].iloc[-1]
    ema200 = df['EMA200'].iloc[-1]
    
    # ì¶”ì„¸ íŒë‹¨
    trend = 'bullish' if ema50 > ema200 else 'bearish'
    
    # ì‹œê°„ ê°„ê²©ë³„ ë¶„ ë‹¨ìœ„ ê³„ì‚°
    interval_minutes = {
        '1m': 1, '5m': 5, '15m': 15, '30m': 30,
        '1h': 60, '4h': 240, '1d': 1440
    }
    minutes_per_candle = interval_minutes.get(interval, 60)
    
    # 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤
    scenarios = {}
    
    # 1. ë³´ìˆ˜ì  (ë¹ ë¥¸ ìµì ˆ, ì†ì ˆ)
    scenarios['conservative'] = {
        'name': 'ğŸ›¡ï¸ ë³´ìˆ˜ì  ì „ëµ',
        'take_profit': entry_price + (atr * 1.5),
        'stop_loss': entry_price - (atr * 1.0),
        'holding_period': '1-3ì¼',
        'time_estimate_minutes': 24 * 60,  # 1ì¼ ê¸°ë³¸ê°’
        'description': 'ë¹ ë¥¸ ìˆ˜ìµ ì‹¤í˜„, ë¦¬ìŠ¤í¬ ìµœì†Œí™”',
        'rr_ratio': 1.5,
        'exit_signals': [
            'RSI > 70 (ê³¼ë§¤ìˆ˜)',
            'EMA50 í•˜í–¥ ëŒíŒŒ',
            'ëª©í‘œ ìˆ˜ìµë¥  5% ë„ë‹¬'
        ]
    }
    
    # 2. ì¤‘ë¦½ì  (ê· í˜•ì¡íŒ ì ‘ê·¼)
    scenarios['neutral'] = {
        'name': 'âš–ï¸ ì¤‘ë¦½ì  ì „ëµ',
        'take_profit': entry_price + (atr * 2.5),
        'stop_loss': entry_price - (atr * 1.5),
        'holding_period': '3-7ì¼',
        'time_estimate_minutes': 5 * 24 * 60,  # 5ì¼ ê¸°ë³¸ê°’
        'description': 'ë¦¬ìŠ¤í¬-ìˆ˜ìµ ê· í˜•',
        'rr_ratio': 1.67,
        'exit_signals': [
            'RSI > 75 (ê°•í•œ ê³¼ë§¤ìˆ˜)',
            'EMA50/200 ë°ë“œí¬ë¡œìŠ¤',
            'ëª©í‘œ ìˆ˜ìµë¥  10% ë„ë‹¬'
        ]
    }
    
    # 3. ê³µê²©ì  (í° ìˆ˜ìµ ì¶”êµ¬)
    scenarios['aggressive'] = {
        'name': 'ğŸš€ ê³µê²©ì  ì „ëµ',
        'take_profit': entry_price + (atr * 4.0),
        'stop_loss': entry_price - (atr * 2.0),
        'holding_period': '7-14ì¼',
        'time_estimate_minutes': 10 * 24 * 60,  # 10ì¼ ê¸°ë³¸ê°’
        'description': 'í° ìˆ˜ìµ ì¶”êµ¬, ë†’ì€ ë¦¬ìŠ¤í¬',
        'rr_ratio': 2.0,
        'exit_signals': [
            'RSI > 80 (ê·¹ì‹¬í•œ ê³¼ë§¤ìˆ˜)',
            'ì£¼ìš” ì €í•­ì„  ë„ë‹¬',
            'ëª©í‘œ ìˆ˜ìµë¥  20% ë„ë‹¬'
        ]
    }
    
    # ì¶”ì„¸ ê¸°ë°˜ ì¡°ì •
    if trend == 'bearish':
        # í•˜ë½ ì¶”ì„¸ì—ì„œëŠ” ë” ë³´ìˆ˜ì ìœ¼ë¡œ
        for scenario in scenarios.values():
            scenario['take_profit'] *= 0.8
            scenario['stop_loss'] *= 1.2
    
    # ì‹œê°„ ì˜ˆì¸¡ ê³„ì‚° (ê°€ê²© ë³€ë™ë¥  ê¸°ë°˜)
    try:
        # ìµœê·¼ 24ì‹œê°„ ê°€ê²© ë³€ë™ë¥  ê³„ì‚°
        recent_prices = df['Close'].tail(min(24, len(df)))
        price_changes = recent_prices.pct_change().dropna()
        avg_change_per_period = price_changes.mean() if len(price_changes) > 0 else 0.001
        
        # ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆì¸¡ ì‹œê°„ ê³„ì‚°
        for scenario in scenarios.values():
            target_price = scenario['take_profit']
            price_diff_pct = (target_price - current_price) / current_price
            
            if avg_change_per_period > 0.0001:  # ì˜ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                periods_needed = abs(price_diff_pct / avg_change_per_period)
                minutes_needed = int(periods_needed * minutes_per_candle)
                
                # ìµœì†Œ/ìµœëŒ€ ì œí•œ
                minutes_needed = max(60, min(minutes_needed, 30 * 24 * 60))  # 1ì‹œê°„ ~ 30ì¼
                scenario['time_estimate_minutes'] = minutes_needed
            
    except Exception as e:
        # ê³„ì‚° ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€
        pass
    
    # í˜„ì¬ ìƒíƒœ í‰ê°€
    current_status = {
        'current_price': current_price,
        'entry_price': entry_price,
        'unrealized_pnl': (current_price - entry_price) / entry_price * 100,
        'rsi_status': 'overbought' if rsi > 70 else 'oversold' if rsi < 30 else 'neutral',
        'trend': trend,
        'recommendation': None
    }
    
    # ì¦‰ì‹œ ë§¤ë„ ê¶Œì¥ ì¡°ê±´
    if rsi > 80 and current_status['unrealized_pnl'] > 10:
        current_status['recommendation'] = 'âš ï¸ ì¦‰ì‹œ ë§¤ë„ ê³ ë ¤ (ê·¹ì‹¬í•œ ê³¼ë§¤ìˆ˜ + ë†’ì€ ìˆ˜ìµ)'
    elif trend == 'bearish' and current_status['unrealized_pnl'] < -5:
        current_status['recommendation'] = 'âš ï¸ ì†ì ˆ ê³ ë ¤ (í•˜ë½ ì¶”ì„¸ + ì†ì‹¤ í™•ëŒ€)'
    elif current_status['unrealized_pnl'] > 20:
        current_status['recommendation'] = 'âœ… ë¶€ë¶„ ìµì ˆ ê³ ë ¤ (ë†’ì€ ìˆ˜ìµ ë‹¬ì„±)'
    else:
        current_status['recommendation'] = 'â³ í™€ë”© ìœ ì§€'
    
    return {
        'scenarios': scenarios,
        'current_status': current_status,
        'atr': atr,
        'trend': trend
    }


# ê¸°íƒ€ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [ì¶”ê°€ë¨] AI ì˜ˆì¸¡ ë° í¬ì§€ì…˜ ì¶”ì²œ í•¨ìˆ˜ (v2.2.0)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def predict_trend_with_ai(df: pd.DataFrame, current_price: float, 
                          ema_short: float, ema_long: float, 
                          rsi: float, macd: float, macd_signal: float) -> dict:
    """
    AI ê¸°ë°˜ ë‹¨ê¸° ì¶”ì„¸ ì˜ˆì¸¡
    
    Returns:
        dict: {
            'trend': 'bullish' | 'bearish' | 'neutral',
            'confidence': float (0-100),
            'reasoning': str,
            'signal_strength': float (0-100)
        }
    """
    signals = []
    weights = []
    reasons = []
    
    # 1. ì´ë™í‰ê·  ë¶„ì„ (ê°€ì¤‘ì¹˜: 30%)
    if ema_short > ema_long:
        ma_diff_pct = ((ema_short - ema_long) / ema_long) * 100
        if ma_diff_pct > 2:
            signals.append(1.0)
            reasons.append(f"ê³¨ë“ í¬ë¡œìŠ¤ ê°•ì„¸ (ì°¨ì´ {ma_diff_pct:.1f}%)")
        elif ma_diff_pct > 0.5:
            signals.append(0.7)
            reasons.append(f"ê³¨ë“ í¬ë¡œìŠ¤ ({ma_diff_pct:.1f}%)")
        else:
            signals.append(0.5)
            reasons.append("ë‹¨ê¸° ì´í‰ì„  ìš°ìœ„")
        weights.append(0.30)
    else:
        ma_diff_pct = ((ema_long - ema_short) / ema_long) * 100
        if ma_diff_pct > 2:
            signals.append(-1.0)
            reasons.append(f"ë°ë“œí¬ë¡œìŠ¤ ì•½ì„¸ (ì°¨ì´ {ma_diff_pct:.1f}%)")
        elif ma_diff_pct > 0.5:
            signals.append(-0.7)
            reasons.append(f"ë°ë“œí¬ë¡œìŠ¤ ({ma_diff_pct:.1f}%)")
        else:
            signals.append(-0.5)
            reasons.append("ì¥ê¸° ì´í‰ì„  ìš°ìœ„")
        weights.append(0.30)
    
    # 2. RSI ë¶„ì„ (ê°€ì¤‘ì¹˜: 25%)
    if rsi > 70:
        signals.append(-0.8)
        reasons.append(f"ê³¼ë§¤ìˆ˜ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    elif rsi > 60:
        signals.append(0.3)
        reasons.append(f"ê°•ì„¸ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    elif rsi < 30:
        signals.append(0.8)
        reasons.append(f"ê³¼ë§¤ë„ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    elif rsi < 40:
        signals.append(-0.3)
        reasons.append(f"ì•½ì„¸ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    else:
        signals.append(0.0)
        reasons.append(f"ì¤‘ë¦½ ì˜ì—­ (RSI {rsi:.1f})")
        weights.append(0.25)
    
    # 3. MACD ë¶„ì„ (ê°€ì¤‘ì¹˜: 25%)
    macd_diff = macd - macd_signal
    if macd_diff > 0:
        if macd > 0:
            signals.append(0.9)
            reasons.append("MACD ìƒìŠ¹ ëª¨ë©˜í…€")
        else:
            signals.append(0.5)
            reasons.append("MACD ë°˜ì „ ì‹ í˜¸")
        weights.append(0.25)
    else:
        if macd < 0:
            signals.append(-0.9)
            reasons.append("MACD í•˜ë½ ëª¨ë©˜í…€")
        else:
            signals.append(-0.5)
            reasons.append("MACD ì•½í™” ì‹ í˜¸")
        weights.append(0.25)
    
    # 4. ê±°ë˜ëŸ‰ ë¶„ì„ (ê°€ì¤‘ì¹˜: 20%)
    if 'Volume' in df.columns and len(df) > 20:
        recent_volume = df['Volume'].iloc[-5:].mean()
        avg_volume = df['Volume'].iloc[-20:].mean()
        volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1.0
        
        if volume_ratio > 1.5:
            current_trend = 1 if ema_short > ema_long else -1
            signals.append(current_trend * 0.7)
            reasons.append(f"ê±°ë˜ëŸ‰ ê¸‰ì¦ ({volume_ratio:.1f}ë°°)")
            weights.append(0.20)
        elif volume_ratio > 1.2:
            current_trend = 1 if ema_short > ema_long else -1
            signals.append(current_trend * 0.4)
            reasons.append(f"ê±°ë˜ëŸ‰ ì¦ê°€ ({volume_ratio:.1f}ë°°)")
            weights.append(0.20)
        elif volume_ratio < 0.7:
            signals.append(0.0)
            reasons.append(f"ê±°ë˜ëŸ‰ ê°ì†Œ ({volume_ratio:.1f}ë°°)")
            weights.append(0.20)
        else:
            signals.append(0.0)
            reasons.append("ê±°ë˜ëŸ‰ í‰ê·  ìˆ˜ì¤€")
            weights.append(0.20)
    
    # ê°€ì¤‘ í‰ê·  ê³„ì‚°
    weighted_signal = sum(s * w for s, w in zip(signals, weights)) / sum(weights)
    
    # ì¶”ì„¸ íŒë‹¨
    if weighted_signal > 0.3:
        trend = 'bullish'
        trend_kr = 'ìƒìŠ¹'
    elif weighted_signal < -0.3:
        trend = 'bearish'
        trend_kr = 'í•˜ë½'
    else:
        trend = 'neutral'
        trend_kr = 'ë³´í•©'
    
    # ì‹ ë¢°ë„ ê³„ì‚°
    confidence = min(abs(weighted_signal) * 100, 100)
    signal_strength = (weighted_signal + 1) * 50
    
    top_reasons = reasons[:2] if len(reasons) >= 2 else reasons
    reasoning = " + ".join(top_reasons)
    
    return {
        'trend': trend,
        'trend_kr': trend_kr,
        'confidence': round(confidence, 1),
        'reasoning': reasoning,
        'signal_strength': round(signal_strength, 1),
        'weighted_signal': weighted_signal
    }


def recommend_position(ai_prediction: dict, current_price: float, 
                      stop_loss: float, take_profit: float,
                      volatility: float) -> dict:
    """
    AI ì˜ˆì¸¡ì„ ê¸°ë°˜ìœ¼ë¡œ í¬ì§€ì…˜ ì¶”ì²œ
    """
    trend = ai_prediction['trend']
    confidence = ai_prediction['confidence']
    
    # í¬ì§€ì…˜ ê²°ì •
    if trend == 'bullish' and confidence > 50:
        position = 'LONG'
        position_kr = 'ë¡± í¬ì§€ì…˜'
        probability = 50 + (confidence * 0.5)
        base_reason = ai_prediction['reasoning']
    elif trend == 'bearish' and confidence > 50:
        position = 'SHORT'
        position_kr = 'ìˆ í¬ì§€ì…˜'
        probability = 50 + (confidence * 0.5)
        base_reason = ai_prediction['reasoning']
    else:
        position = 'NEUTRAL'
        position_kr = 'ê´€ë§'
        probability = 50
        base_reason = "ëª…í™•í•œ ì¶”ì„¸ ì—†ìŒ"
    
    # ë¦¬ìŠ¤í¬ ë ˆë²¨
    if volatility > 0.05:
        risk_level = 'HIGH'
        risk_kr = 'ë†’ìŒ'
        risk_adjustment = -5
    elif volatility > 0.03:
        risk_level = 'MEDIUM'
        risk_kr = 'ì¤‘ê°„'
        risk_adjustment = 0
    else:
        risk_level = 'LOW'
        risk_kr = 'ë‚®ìŒ'
        risk_adjustment = +5
    
    final_probability = min(max(probability + risk_adjustment, 45), 85)
    
    if position == 'NEUTRAL':
        reasoning = f"{base_reason}, ì‹œì¥ ë³€ë™ì„± {risk_kr}"
        recommendation_text = "í˜„ì¬ ë°ì´í„° ê¸°ì¤€, **ê´€ë§(ë³´ë¥˜)** ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
    else:
        reasoning = f"{base_reason}, ì‹œì¥ ë³€ë™ì„± {risk_kr}"
        recommendation_text = f"í˜„ì¬ ë°ì´í„° ê¸°ì¤€, **{position_kr}** ì´ ìš°ì„¸(ì•½ **{final_probability:.0f}%**) ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
    
    # ì†ìµë¹„
    if position == 'LONG':
        potential_profit = ((take_profit - current_price) / current_price) * 100
        potential_loss = ((current_price - stop_loss) / current_price) * 100
    elif position == 'SHORT':
        potential_profit = ((current_price - stop_loss) / current_price) * 100
        potential_loss = ((take_profit - current_price) / current_price) * 100
    else:
        potential_profit = 0
        potential_loss = 0
    
    rr_ratio = potential_profit / potential_loss if potential_loss > 0 else 0
    
    return {
        'position': position,
        'position_kr': position_kr,
        'probability': round(final_probability, 1),
        'reasoning': reasoning,
        'risk_level': risk_level,
        'risk_kr': risk_kr,
        'recommendation_text': recommendation_text,
        'potential_profit_pct': round(potential_profit, 2),
        'potential_loss_pct': round(potential_loss, 2),
        'risk_reward_ratio': round(rr_ratio, 2)
    }


def render_ai_prediction(ai_prediction: dict, current_price: float):
    """[ì¶”ê°€ë¨] ğŸ¤– AI ì˜ˆì¸¡ ê²°ê³¼ ì„¹ì…˜"""
    st.markdown("<div class='section-title'>ğŸ¤– AI ì˜ˆì¸¡ ê²°ê³¼</div>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ“Š ë‹¨ê¸° ì¶”ì„¸ ì˜ˆì¸¡")
        trend_emoji = {'bullish': 'ğŸ“ˆ', 'bearish': 'ğŸ“‰', 'neutral': 'â¡ï¸'}
        trend_color = {'bullish': 'green', 'bearish': 'red', 'neutral': 'gray'}
        trend = ai_prediction['trend']
        st.markdown(f"<h2 style='color:{trend_color[trend]};'>{trend_emoji[trend]} {ai_prediction['trend_kr']}</h2>", 
                   unsafe_allow_html=True)
    
    with col2:
        st.markdown("### ğŸ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„")
        confidence = ai_prediction['confidence']
        if confidence >= 70:
            bar_color = 'green'
            conf_text = 'ë†’ìŒ'
        elif confidence >= 50:
            bar_color = 'orange'
            conf_text = 'ì¤‘ê°„'
        else:
            bar_color = 'red'
            conf_text = 'ë‚®ìŒ'
        st.markdown(f"""
        <div style='background-color: #f0f0f0; border-radius: 10px; padding: 10px;'>
            <div style='background-color: {bar_color}; width: {confidence}%; height: 30px; 
                        border-radius: 5px; text-align: center; line-height: 30px; color: white; font-weight: bold;'>
                {confidence:.1f}%
            </div>
            <p style='text-align: center; margin-top: 5px; color: #666;'>{conf_text}</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### ğŸ’¡ ì˜ˆì¸¡ ê·¼ê±°")
        st.info(ai_prediction['reasoning'])
    
    signal_strength = ai_prediction['signal_strength']
    if signal_strength > 60:
        gauge_color = 'linear-gradient(90deg, #28a745 0%, #218838 100%)'
        gauge_text = 'ê°•í•œ ë§¤ìˆ˜ ì‹ í˜¸'
    elif signal_strength > 55:
        gauge_color = 'linear-gradient(90deg, #90EE90 0%, #28a745 100%)'
        gauge_text = 'ë§¤ìˆ˜ ì‹ í˜¸'
    elif signal_strength >= 45:
        gauge_color = 'linear-gradient(90deg, #FFA500 0%, #FF8C00 100%)'
        gauge_text = 'ì¤‘ë¦½'
    elif signal_strength >= 40:
        gauge_color = 'linear-gradient(90deg, #FF6347 0%, #FFA500 100%)'
        gauge_text = 'ë§¤ë„ ì‹ í˜¸'
    else:
        gauge_color = 'linear-gradient(90deg, #dc3545 0%, #c82333 100%)'
        gauge_text = 'ê°•í•œ ë§¤ë„ ì‹ í˜¸'
    
    st.markdown(f"""
    <div style='background-color: #e0e0e0; border-radius: 20px; height: 40px; position: relative; overflow: hidden; margin-top: 20px;'>
        <div style='background: {gauge_color}; width: {signal_strength}%; height: 100%; border-radius: 20px;'></div>
        <div style='position: absolute; top: 0; left: 0; right: 0; text-align: center; 
                    line-height: 40px; color: white; font-weight: bold; text-shadow: 1px 1px 2px rgba(0,0,0,0.5);'>
            {gauge_text} ({signal_strength:.0f}/100)
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("---")


def render_position_recommendation(position_rec: dict):
    """[ì¶”ê°€ë¨] í¬ì§€ì…˜ ì¶”ì²œ (ë§¤ë§¤ ì „ëµ ë‚´ë¶€)"""
    st.markdown("#### ğŸ¯ í¬ì§€ì…˜ ì¶”ì²œ")
    position = position_rec['position']
    if position == 'LONG':
        bg_color = '#d4edda'
        border_color = '#28a745'
        icon = 'ğŸ“ˆ'
    elif position == 'SHORT':
        bg_color = '#f8d7da'
        border_color = '#dc3545'
        icon = 'ğŸ“‰'
    else:
        bg_color = '#fff3cd'
        border_color = '#ffc107'
        icon = 'â¸ï¸'
    
    st.markdown(f"""
    <div style='background-color: {bg_color}; border-left: 5px solid {border_color}; 
                padding: 20px; border-radius: 10px; margin: 10px 0;'>
        <h3 style='margin: 0; color: {border_color};'>{icon} {position_rec['recommendation_text']}</h3>
        <p style='margin: 10px 0 0 0; color: #666;'>
            <strong>ì¶”ì²œ ì´ìœ :</strong> {position_rec['reasoning']}
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric(label="í¬ì§€ì…˜", value=position_rec['position_kr'])
    with col2:
        st.metric(label="í™•ë¥ ", value=f"{position_rec['probability']:.0f}%")
    with col3:
        st.metric(label="ë¦¬ìŠ¤í¬", value=position_rec['risk_kr'])
    with col4:
        if position != 'NEUTRAL':
            st.metric(label="ì†ìµë¹„", value=f"{position_rec['risk_reward_ratio']:.2f}")
    
    if position != 'NEUTRAL':
        st.markdown("##### ğŸ’° ì˜ˆìƒ ì†ìµ")
        col_profit, col_loss = st.columns(2)
        with col_profit:
            st.success(f"**ëª©í‘œ ìˆ˜ìµ:** +{position_rec['potential_profit_pct']:.2f}%")
        with col_loss:
            st.error(f"**ìµœëŒ€ ì†ì‹¤:** -{position_rec['potential_loss_pct']:.2f}%")
    
    # ì£¼ì˜ì‚¬í•­ ì‚­ì œë¨



# ==============================================================================
# RISK MANAGEMENT FUNCTIONS (Reordered for logical flow)
# ==============================================================================

def calculate_kelly_criterion(ai_confidence: float, rr_ratio: float, win_rate: float = None,
                              kelly_fraction: float = 0.5, max_position: float = 0.25) -> dict:
    """
    Kelly Criterionì„ ì‚¬ìš©í•œ ìµœì  Position Size ê³„ì‚°
    
    ê³µì‹: Kelly = (b*p - q) / b
    - b = RR Ratio (ìŠ¹ë¥ )
    - p = ìŠ¹ë¦¬ í™•ë¥  (AI ì‹ ë¢°ë„ ë˜ëŠ” ë°±í…ŒìŠ¤íŒ… ê²°ê³¼)
    - q = íŒ¨ë°° í™•ë¥  (1-p)
    """
    p = (ai_confidence / 100.0) if win_rate is None else win_rate
    p = max(0.01, min(0.99, p))
    q = 1.0 - p
    
    if rr_ratio <= 0:
        return {'kelly_full': 0.0, 'kelly_adjusted': 0.0, 'kelly_capped': 0.0,
                'position_pct': 0.0, 'recommendation': 'NO TRADE',
                'risk_category': 'ë¹„ì •ìƒ', 'reason': 'RR Ratioê°€ 0 ì´í•˜ì…ë‹ˆë‹¤.',
                'win_rate_used': p, 'rr_ratio_used': rr_ratio, 'kelly_fraction_used': kelly_fraction}
    
    b = rr_ratio
    kelly_full = (b * p - q) / b
    
    if kelly_full <= 0:
        return {'kelly_full': kelly_full, 'kelly_adjusted': 0.0, 'kelly_capped': 0.0,
                'position_pct': 0.0, 'recommendation': 'NO TRADE',
                'risk_category': 'ê¸°ëŒ€ê°’ ìŒìˆ˜',
                'reason': f'ê¸°ëŒ€ê°’ì´ ìŒìˆ˜ì…ë‹ˆë‹¤ (p={p:.1%}, b={b:.2f})',
                'win_rate_used': p, 'rr_ratio_used': b, 'kelly_fraction_used': kelly_fraction}
    
    kelly_adjusted = kelly_full * kelly_fraction
    kelly_capped = min(kelly_adjusted, max_position)
    
    if kelly_capped < 0.02:
        risk_category, recommendation = 'ê±°ë˜ ì œì™¸', 'SKIP'
        reason = 'í¬ì§€ì…˜ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ (2% ë¯¸ë§Œ)'
    elif kelly_capped < 0.05:
        risk_category, recommendation = 'ë§¤ìš° ë³´ìˆ˜ì ', 'TRADE'
        reason = 'ë³´ìˆ˜ì  í¬ì§€ì…˜ (2-5%)'
    elif kelly_capped < 0.10:
        risk_category, recommendation = 'ì¤‘ë¦½ì ', 'TRADE'
        reason = 'ì¤‘ë¦½ì  í¬ì§€ì…˜ (5-10%)'
    elif kelly_capped < 0.15:
        risk_category, recommendation = 'ê³µê²©ì ', 'TRADE'
        reason = 'ê³µê²©ì  í¬ì§€ì…˜ (10-15%)'
    else:
        risk_category, recommendation = 'ë§¤ìš° ê³µê²©ì ', 'TRADE'
        reason = 'ë§¤ìš° ê³µê²©ì  í¬ì§€ì…˜ (15%+)'
    
    return {
        'kelly_full': round(kelly_full, 4),
        'kelly_adjusted': round(kelly_adjusted, 4),
        'kelly_capped': round(kelly_capped, 4),
        'position_pct': round(kelly_capped * 100, 2),
        'recommendation': recommendation,
        'risk_category': risk_category,
        'reason': reason,
        'win_rate_used': p,
        'rr_ratio_used': b,
        'kelly_fraction_used': kelly_fraction
    }



def calculate_optimized_leverage(investment_amount: float, volatility: float, 
                                 atr_ratio: float, confidence: float, max_leverage: int, 
                                 crypto_name: str = "BTC") -> dict:
    """
    ë ˆë²„ë¦¬ì§€ ìµœì í™” (v2.3.0)
    
    Returns:
        dict: {
            'recommended': ê¶Œì¥ ë ˆë²„ë¦¬ì§€,
            'maximum': ìµœëŒ€ ë ˆë²„ë¦¬ì§€,
            'risk_level': ë¦¬ìŠ¤í¬ ë ˆë²¨
        }
    """
    base_leverage = 10
    
    # [ì¶”ê°€ë¨] v2.3.0: ì½”ì¸ë³„ ë¦¬ìŠ¤í¬ íŒ©í„° (ë³€ë™ì„± ê¸°ë°˜)
    crypto_risk_factors = {
        'BTC': 1.0,   # ë¹„íŠ¸ì½”ì¸: ê¸°ì¤€ (ê°€ì¥ ì•ˆì •ì )
        'ETH': 1.1,   # ì´ë”ë¦¬ì›€: ì•½ê°„ ë†’ì€ ë³€ë™ì„±
        'BNB': 1.2,   # ë°”ì´ë‚¸ìŠ¤: ì¤‘ê°„ ë³€ë™ì„±
        'XRP': 1.3,   # ë¦¬í”Œ: ë†’ì€ ë³€ë™ì„±
        'ADA': 1.3,   # ì¹´ë¥´ë‹¤ë…¸: ë†’ì€ ë³€ë™ì„±
        'SOL': 1.4,   # ì†”ë¼ë‚˜: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
        'DOGE': 1.5,  # ë„ì§€ì½”ì¸: ê·¹ì‹¬í•œ ë³€ë™ì„±
        'MATIC': 1.4, # í´ë¦¬ê³¤: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
        'DOT': 1.3,   # í´ì¹´ë‹·: ë†’ì€ ë³€ë™ì„±
        'AVAX': 1.4,  # ì•„ë°œë€ì²´: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
    }
    
    # ì½”ì¸ ì´ë¦„ì—ì„œ ê¸°í˜¸ ì¶”ì¶œ (ì˜ˆ: "Bitcoin (BTC)" -> "BTC")
    crypto_symbol = crypto_name
    for symbol in crypto_risk_factors.keys():
        if symbol in crypto_name.upper():
            crypto_symbol = symbol
            break
    
    crypto_factor = crypto_risk_factors.get(crypto_symbol, 1.2)  # ê¸°ë³¸ê°’: ì¤‘ê°„ ë¦¬ìŠ¤í¬
    
    # [ì¶”ê°€ë¨] v2.3.0: íˆ¬ì ê¸ˆì•¡ì— ë”°ë¥¸ ì„¸ë¶„í™”ëœ íŒ©í„°
    # ëŒ€ëŸ‰ íˆ¬ìì â†’ ë¦¬ìŠ¤í¬ ê°ìˆ˜ ëŠ¥ë ¥ ë†’ìŒ â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    # ì†Œì•¡ íˆ¬ìì â†’ ì†ì‹¤ íšŒë³µ ì–´ë ¤ì›€ â†’ ë³´ìˆ˜ì  ë ˆë²„ë¦¬ì§€
    if investment_amount >= 50000:
        investment_factor = 1.3  # ì´ˆëŒ€ëŸ‰ íˆ¬ì â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    elif investment_amount >= 20000:
        investment_factor = 1.2  # ëŒ€ëŸ‰ íˆ¬ì â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    elif investment_amount >= 10000:
        investment_factor = 1.1  # ìƒë‹¹ íˆ¬ì â†’ ì•½ê°„ ì—¬ìœ 
    elif investment_amount >= 5000:
        investment_factor = 1.0  # ê¸°ì¤€
    elif investment_amount >= 2000:
        investment_factor = 0.9  # ì¤‘ê°„ â†’ ì•½ê°„ ì‹ ì¤‘
    elif investment_amount >= 1000:
        investment_factor = 0.8  # ì†Œì•¡ â†’ ì‹ ì¤‘
    else:
        investment_factor = 0.6  # ê·¹ì†Œì•¡ â†’ ë§¤ìš° ë³´ìˆ˜ì 
    
    # ë³€ë™ì„± íŒ©í„°
    if volatility < 0.02:
        volatility_factor = 1.5  # ë‚®ì€ ë³€ë™ì„± â†’ ë ˆë²„ë¦¬ì§€ ì—¬ìœ 
    elif volatility < 0.05:
        volatility_factor = 1.2  # ì¤‘ê°„ ë³€ë™ì„±
    elif volatility < 0.10:
        volatility_factor = 0.9  # ë†’ì€ ë³€ë™ì„±
    else:
        volatility_factor = 0.7  # ê·¹ì‹¬í•œ ë³€ë™ì„± â†’ ë³´ìˆ˜ì 
    
    confidence_factor = confidence / 100.0
    atr_factor = 1.0 / (atr_ratio + 0.5)
    
    # [ì¶”ê°€ë¨] v2.3.0: ê¶Œì¥ ë ˆë²„ë¦¬ì§€ ê³„ì‚° (ë³´ìˆ˜ì )
    recommended_leverage = base_leverage * investment_factor * volatility_factor * confidence_factor * atr_factor / crypto_factor
    recommended_leverage = max(1.0, min(recommended_leverage, float(max_leverage) * 0.7))  # ìµœëŒ€ ë ˆë²„ë¦¬ì§€ì˜ 70%ê¹Œì§€
    recommended_leverage = round(recommended_leverage, 1)
    
    # [ì¶”ê°€ë¨] v2.3.0: ìµœëŒ€ ë ˆë²„ë¦¬ì§€ ê³„ì‚° (ê³µê²©ì )
    maximum_leverage = recommended_leverage * 1.5  # ê¶Œì¥ì˜ 1.5ë°°
    maximum_leverage = max(recommended_leverage + 1, min(maximum_leverage, float(max_leverage)))
    maximum_leverage = round(maximum_leverage, 1)
    
    # [ìˆ˜ì •ë¨] v2.9.0.2: ë¦¬ìŠ¤í¬ ë ˆë²¨ íŒë‹¨ ë¡œì§ ìˆ˜ì •
    # ë¦¬ìŠ¤í¬ ì ìˆ˜ = ì½”ì¸ ë¦¬ìŠ¤í¬ * ë³€ë™ì„± * 100
    risk_score = crypto_factor * volatility * 100
    
    # ë¦¬ìŠ¤í¬ ë ˆë²¨ ë¶„ë¥˜ (ì„¸ë¶„í™”)
    if risk_score < 2:
        risk_level = "ë§¤ìš° ë‚®ìŒ"  # ì•ˆì •ì  (BTC + ë‚®ì€ ë³€ë™ì„±)
    elif risk_score < 4:
        risk_level = "ë‚®ìŒ"  # ë³´ìˆ˜ì 
    elif risk_score < 6:
        risk_level = "ì¤‘ê°„"  # ì¤‘ë¦½ì 
    elif risk_score < 8:
        risk_level = "ë†’ìŒ"  # ê³µê²©ì 
    else:
        risk_level = "ë§¤ìš° ë†’ìŒ"  # ë§¤ìš° ìœ„í—˜ (ì•ŒíŠ¸ì½”ì¸ + ë†’ì€ ë³€ë™ì„±)
    
    return {
        'recommended': recommended_leverage,
        'maximum': maximum_leverage,
        'risk_level': risk_level
    }




# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.9.0: ì‹¤ì‹œê°„ ê¸€ë¡œë²Œ ë°ì´í„° ë¶„ì„ í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# - CryptoPanic ë‰´ìŠ¤ ë¶„ì„
# - FRED ê²½ì œ ì§€í‘œ
# - ì˜¨ì²´ì¸ ë©”íŠ¸ë¦­ (ë„ë¯¸ë„ŒìŠ¤, ê¹€í”„, í€ë”©ë¹„, ì²­ì‚°)
# - ì¢…í•© ì‹œì¥ ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.9.0.4: typing import ëª…ì‹œì  ì¬ì„ ì–¸ (Streamlit Cloud í˜¸í™˜ì„±)
from typing import Dict, List, Optional, Tuple


def fetch_cryptopanic_news(
    currency: str = 'BTC',
    api_key: Optional[str] = None,
    limit: int = 20
) -> Dict:
    """
    CryptoPanic APIë¥¼ í†µí•´ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘
    
    Parameters:
    -----------
    currency : str
        ì•”í˜¸í™”í ì‹¬ë³¼ (BTC, ETH ë“±)
    api_key : str, optional
        CryptoPanic API í‚¤ (ì—†ìœ¼ë©´ ê³µê°œ ë°ì´í„°ë§Œ)
    limit : int
        ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜
    
    Returns:
    --------
    dict : {
        'news': list of dict,
        'sentiment_score': float,
        'total_count': int,
        'bullish_count': int,
        'bearish_count': int,
        'neutral_count': int
    }
    """
    try:
        # API ì—”ë“œí¬ì¸íŠ¸
        base_url = "https://cryptopanic.com/api/v1/posts/"
        
        params = {
            'auth_token': api_key if api_key else 'free',
            'currencies': currency,
            'kind': 'news',  # news, media, blog
            'filter': 'rising',  # hot, rising, bullish, bearish
            'public': 'true'
        }
        
        response = requests.get(base_url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            results = data.get('results', [])[:limit]
            
            # ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
            sentiment_counts = {
                'positive': 0,
                'negative': 0,
                'neutral': 0
            }
            
            news_list = []
            for item in results:
                votes = item.get('votes', {})
                
                # ì„¼í‹°ë¨¼íŠ¸ ê²°ì •
                positive = votes.get('positive', 0)
                negative = votes.get('negative', 0)
                important = votes.get('important', 0)
                
                if positive > negative:
                    sentiment = 'positive'
                    sentiment_counts['positive'] += 1
                elif negative > positive:
                    sentiment = 'negative'
                    sentiment_counts['negative'] += 1
                else:
                    sentiment = 'neutral'
                    sentiment_counts['neutral'] += 1
                
                news_list.append({
                    'title': item.get('title', ''),
                    'published_at': item.get('published_at', ''),
                    'url': item.get('url', ''),
                    'source': item.get('source', {}).get('title', 'Unknown'),
                    'sentiment': sentiment,
                    'votes_positive': positive,
                    'votes_negative': negative,
                    'votes_important': important,
                    'currencies': item.get('currencies', [])
                })
            
            # ì„¼í‹°ë¨¼íŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚° (-1 ~ +1)
            total = sum(sentiment_counts.values())
            if total > 0:
                sentiment_score = (
                    (sentiment_counts['positive'] - sentiment_counts['negative']) / total
                )
            else:
                sentiment_score = 0.0
            
            return {
                'news': news_list,
                'sentiment_score': sentiment_score,
                'total_count': len(news_list),
                'bullish_count': sentiment_counts['positive'],
                'bearish_count': sentiment_counts['negative'],
                'neutral_count': sentiment_counts['neutral'],
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
        else:
            return {
                'news': [],
                'sentiment_score': 0.0,
                'total_count': 0,
                'bullish_count': 0,
                'bearish_count': 0,
                'neutral_count': 0,
                'error': f'API Error: {response.status_code}',
                'status': 'error'
            }
    
    except Exception as e:
        return {
            'news': [],
            'sentiment_score': 0.0,
            'total_count': 0,
            'bullish_count': 0,
            'bearish_count': 0,
            'neutral_count': 0,
            'error': str(e),
            'status': 'error'
        }


def analyze_news_sentiment_advanced(news_data: Dict) -> Dict:
    """
    ë‰´ìŠ¤ ì„¼í‹°ë¨¼íŠ¸ ê³ ê¸‰ ë¶„ì„
    
    Returns:
    --------
    dict : {
        'overall_sentiment': str (Bullish/Bearish/Neutral),
        'confidence': float (0-1),
        'market_impact': str (High/Medium/Low),
        'key_topics': list,
        'recommendation': str
    }
    """
    if not news_data.get('news'):
        return {
            'overall_sentiment': 'Neutral',
            'confidence': 0.0,
            'market_impact': 'Low',
            'key_topics': [],
            'recommendation': 'No recent news data available'
        }
    
    sentiment_score = news_data['sentiment_score']
    total_votes = sum([
        n['votes_positive'] + n['votes_negative'] + n['votes_important']
        for n in news_data['news']
    ])
    
    # ì „ì²´ ì„¼í‹°ë¨¼íŠ¸ ê²°ì •
    if sentiment_score > 0.3:
        overall = 'Bullish'
    elif sentiment_score < -0.3:
        overall = 'Bearish'
    else:
        overall = 'Neutral'
    
    # ì‹ ë¢°ë„ ê³„ì‚°
    confidence = min(abs(sentiment_score) + (total_votes / 1000), 1.0)
    
    # ì‹œì¥ ì˜í–¥ë„
    if total_votes > 500 and abs(sentiment_score) > 0.5:
        impact = 'High'
    elif total_votes > 200 or abs(sentiment_score) > 0.3:
        impact = 'Medium'
    else:
        impact = 'Low'
    
    # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë¹ˆë„ ë¶„ì„)
    all_titles = ' '.join([n['title'].lower() for n in news_data['news']])
    keywords = ['bitcoin', 'eth', 'regulation', 'sec', 'etf', 'trading', 
                'price', 'market', 'crypto', 'bullish', 'bearish']
    key_topics = [kw for kw in keywords if kw in all_titles][:5]
    
    # ì¶”ì²œ ë©”ì‹œì§€
    if overall == 'Bullish' and confidence > 0.6:
        recommendation = "Strong positive market sentiment. Consider long positions."
    elif overall == 'Bearish' and confidence > 0.6:
        recommendation = "Negative market sentiment detected. Exercise caution."
    else:
        recommendation = "Mixed signals. Wait for clearer market direction."
    
    return {
        'overall_sentiment': overall,
        'confidence': confidence,
        'market_impact': impact,
        'key_topics': key_topics,
        'recommendation': recommendation
    }


# ==============================================================================
# 2. FRED ECONOMIC DATA
# ==============================================================================

def fetch_fred_economic_data(
    series_id: str = 'CPIAUCSL',  # CPI for All Urban Consumers
    api_key: Optional[str] = None,
    limit: int = 12
) -> Dict:
    """
    FRED (Federal Reserve Economic Data) APIì—ì„œ ê²½ì œ ì§€í‘œ ìˆ˜ì§‘
    
    Parameters:
    -----------
    series_id : str
        FRED ì‹œë¦¬ì¦ˆ ID
        - CPIAUCSL: Consumer Price Index
        - UNRATE: Unemployment Rate
        - DFF: Federal Funds Rate
    api_key : str
        FRED API í‚¤
    limit : int
        ë°ì´í„° í¬ì¸íŠ¸ ê°œìˆ˜
    
    Returns:
    --------
    dict : {
        'data': pandas.DataFrame,
        'latest_value': float,
        'change_mom': float (month-over-month),
        'change_yoy': float (year-over-year),
        'trend': str
    }
    """
    try:
        if not api_key:
            # API í‚¤ ì—†ì„ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
            return _get_fred_dummy_data(series_id)
        
        base_url = "https://api.stlouisfed.org/fred/series/observations"
        
        params = {
            'series_id': series_id,
            'api_key': api_key,
            'file_type': 'json',
            'sort_order': 'desc',
            'limit': limit
        }
        
        response = requests.get(base_url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            observations = data.get('observations', [])
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(observations)
            df['date'] = pd.to_datetime(df['date'])
            df['value'] = pd.to_numeric(df['value'], errors='coerce')
            df = df.dropna(subset=['value'])
            df = df.sort_values('date')
            
            if len(df) == 0:
                return _get_fred_dummy_data(series_id)
            
            latest_value = df['value'].iloc[-1]
            
            # Month-over-Month ë³€í™”
            if len(df) >= 2:
                change_mom = ((latest_value / df['value'].iloc[-2]) - 1) * 100
            else:
                change_mom = 0.0
            
            # Year-over-Year ë³€í™”
            if len(df) >= 12:
                change_yoy = ((latest_value / df['value'].iloc[-12]) - 1) * 100
            else:
                change_yoy = 0.0
            
            # íŠ¸ë Œë“œ ë¶„ì„
            if change_mom > 0.2:
                trend = 'Rising'
            elif change_mom < -0.2:
                trend = 'Falling'
            else:
                trend = 'Stable'
            
            return {
                'data': df,
                'latest_value': latest_value,
                'change_mom': change_mom,
                'change_yoy': change_yoy,
                'trend': trend,
                'series_id': series_id,
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
        else:
            return _get_fred_dummy_data(series_id)
    
    except Exception as e:
        return _get_fred_dummy_data(series_id)


def _get_fred_dummy_data(series_id: str) -> Dict:
    """FRED API ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜"""
    # ìµœê·¼ 12ê°œì›” ë”ë¯¸ ë°ì´í„°
    dates = pd.date_range(end=datetime.now(), periods=12, freq='MS')
    
    if 'CPI' in series_id:
        # CPI ë”ë¯¸ (ì•½ 3% ì¸í”Œë ˆì´ì…˜)
        base = 300.0
        values = [base * (1.03 ** (i/12)) for i in range(12)]
    else:
        values = [100 + i * 0.5 for i in range(12)]
    
    df = pd.DataFrame({
        'date': dates,
        'value': values
    })
    
    return {
        'data': df,
        'latest_value': values[-1],
        'change_mom': 0.3,
        'change_yoy': 3.2,
        'trend': 'Rising',
        'series_id': series_id,
        'timestamp': datetime.now().isoformat(),
        'status': 'dummy'
    }


# ==============================================================================
# 3. ONCHAIN METRICS
# ==============================================================================

def fetch_btc_dominance() -> Dict:
    """
    ë¹„íŠ¸ì½”ì¸ ë„ë¯¸ë„ŒìŠ¤ (ì‹œê°€ì´ì•¡ ì ìœ ìœ¨) ìˆ˜ì§‘
    
    Returns:
    --------
    dict : {
        'dominance': float (percentage),
        'trend': str,
        'change_24h': float
    }
    """
    try:
        # CoinGecko API
        url = "https://api.coingecko.com/api/v3/global"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            market_data = data.get('data', {})
            
            dominance = market_data.get('market_cap_percentage', {}).get('btc', 0)
            
            # ê°„ë‹¨í•œ íŠ¸ë Œë“œ (ì‹¤ì œë¡œëŠ” historical ë°ì´í„° í•„ìš”)
            if dominance > 45:
                trend = 'Strong'
            elif dominance > 40:
                trend = 'Moderate'
            else:
                trend = 'Weak'
            
            return {
                'dominance': dominance,
                'trend': trend,
                'change_24h': 0.0,  # Historical data needed
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
        else:
            return {'dominance': 0, 'trend': 'Unknown', 'change_24h': 0, 'status': 'error'}
    
    except Exception as e:
        return {'dominance': 0, 'trend': 'Unknown', 'change_24h': 0, 'error': str(e), 'status': 'error'}


def fetch_kimchi_premium(symbol: str = 'BTC') -> Dict:
    """
    ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„ ê³„ì‚° (í•œêµ­ ê±°ë˜ì†Œ vs ê¸€ë¡œë²Œ ê±°ë˜ì†Œ)
    
    Returns:
    --------
    dict : {
        'premium': float (percentage),
        'korea_price': float,
        'global_price': float,
        'signal': str
    }
    """
    try:
        # Upbit (í•œêµ­) ê°€ê²©
        upbit_url = f"https://api.upbit.com/v1/ticker?markets=KRW-{symbol}"
        upbit_response = requests.get(upbit_url, timeout=10)
        
        # Binance (ê¸€ë¡œë²Œ) ê°€ê²©
        binance_url = f"https://api.binance.com/api/v3/ticker/price?symbol={symbol}USDT"
        binance_response = requests.get(binance_url, timeout=10)
        
        # USD/KRW í™˜ìœ¨ (ê³ ì •ê°’ ë˜ëŠ” APIì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        usd_krw = 1320  # ëŒ€ëµì ì¸ í™˜ìœ¨
        
        if upbit_response.status_code == 200 and binance_response.status_code == 200:
            upbit_data = upbit_response.json()[0]
            binance_data = binance_response.json()
            
            korea_price = upbit_data['trade_price']  # KRW
            global_price_usd = float(binance_data['price'])  # USD
            global_price_krw = global_price_usd * usd_krw
            
            # í”„ë¦¬ë¯¸ì—„ ê³„ì‚°
            premium = ((korea_price / global_price_krw) - 1) * 100
            
            # ì‹œê·¸ë„
            if premium > 5:
                signal = 'High Premium (Bullish KR Market)'
            elif premium < -5:
                signal = 'Negative Premium (Bearish KR Market)'
            else:
                signal = 'Normal Range'
            
            return {
                'premium': premium,
                'korea_price': korea_price,
                'global_price': global_price_krw,
                'usd_krw_rate': usd_krw,
                'signal': signal,
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
        else:
            return {'premium': 0, 'korea_price': 0, 'global_price': 0, 'signal': 'Unknown', 'status': 'error'}
    
    except Exception as e:
        return {'premium': 0, 'korea_price': 0, 'global_price': 0, 'signal': 'Unknown', 'error': str(e), 'status': 'error'}


def fetch_funding_rate(symbol: str = 'BTCUSDT') -> Dict:
    """
    Binance ì„ ë¬¼ í€ë”©ë¹„ ìˆ˜ì§‘
    
    Returns:
    --------
    dict : {
        'funding_rate': float,
        'next_funding_time': str,
        'signal': str
    }
    """
    try:
        url = f"https://fapi.binance.com/fapi/v1/fundingRate?symbol={symbol}&limit=1"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if len(data) > 0:
                latest = data[0]
                funding_rate = float(latest['fundingRate']) * 100  # Percentage
                
                # ì‹œê·¸ë„
                if funding_rate > 0.05:
                    signal = 'High Positive (Overleveraged Long)'
                elif funding_rate < -0.05:
                    signal = 'Negative (Short Dominance)'
                else:
                    signal = 'Neutral'
                
                return {
                    'funding_rate': funding_rate,
                    'funding_time': latest['fundingTime'],
                    'signal': signal,
                    'timestamp': datetime.now().isoformat(),
                    'status': 'success'
                }
        
        return {'funding_rate': 0, 'funding_time': '', 'signal': 'Unknown', 'status': 'error'}
    
    except Exception as e:
        return {'funding_rate': 0, 'funding_time': '', 'signal': 'Unknown', 'error': str(e), 'status': 'error'}


def fetch_liquidation_data(symbol: str = 'BTCUSDT', period: str = '24h') -> Dict:
    """
    ì²­ì‚° ë°ì´í„° ìˆ˜ì§‘ (Coinglass API ë˜ëŠ” ì¶”ì •)
    
    Returns:
    --------
    dict : {
        'total_liquidation': float,
        'long_liquidation': float,
        'short_liquidation': float,
        'signal': str
    }
    """
    try:
        # Coinglass APIëŠ” ìœ ë£Œì´ë¯€ë¡œ Binance ê³µê°œ ë°ì´í„° í™œìš©
        # ì‹¤ì œë¡œëŠ” historical liquidation dataê°€ í•„ìš”
        
        # ë”ë¯¸ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ API ì—°ë™ í•„ìš”)
        return {
            'total_liquidation': 0,
            'long_liquidation': 0,
            'short_liquidation': 0,
            'signal': 'Data Unavailable (Premium API Required)',
            'timestamp': datetime.now().isoformat(),
            'status': 'dummy'
        }
    
    except Exception as e:
        return {
            'total_liquidation': 0,
            'long_liquidation': 0,
            'short_liquidation': 0,
            'signal': 'Error',
            'error': str(e),
            'status': 'error'
        }


# ==============================================================================
# 4. COMPREHENSIVE MARKET ANALYSIS
# ==============================================================================

def analyze_comprehensive_market(
    symbol: str,
    news_data: Dict,
    fred_data: Dict,
    dominance_data: Dict,
    kimchi_data: Dict,
    funding_data: Dict,
    current_price: float,
    ai_confidence: float
) -> Dict:
    """
    ì¢…í•© ì‹œì¥ ë¶„ì„ - ëª¨ë“  ë°ì´í„° í†µí•©
    
    Returns:
    --------
    dict : {
        'overall_score': float (0-100),
        'recommendation': str (Strong Buy/Buy/Hold/Sell/Strong Sell),
        'confidence': float (0-1),
        'key_factors': list,
        'risk_level': str,
        'summary': str
    }
    """
    scores = []
    factors = []
    
    # 1. ë‰´ìŠ¤ ì„¼í‹°ë¨¼íŠ¸ (30% ê°€ì¤‘ì¹˜)
    news_score = (news_data.get('sentiment_score', 0) + 1) * 50  # 0-100 scale
    scores.append(news_score * 0.3)
    if news_data.get('sentiment_score', 0) > 0.3:
        factors.append("âœ… Positive News Sentiment")
    elif news_data.get('sentiment_score', 0) < -0.3:
        factors.append("âš ï¸ Negative News Sentiment")
    
    # 2. ê²½ì œ ì§€í‘œ (20% ê°€ì¤‘ì¹˜)
    if fred_data.get('trend') == 'Rising':
        macro_score = 30  # ì¸í”Œë ˆì´ì…˜ ìƒìŠ¹ì€ cryptoì— ë¶€ì •ì ì¼ ìˆ˜ ìˆìŒ
        factors.append("âš ï¸ Rising Inflation (Macro Risk)")
    else:
        macro_score = 70
        factors.append("âœ… Stable Macro Environment")
    scores.append(macro_score * 0.2)
    
    # 3. ë¹„íŠ¸ì½”ì¸ ë„ë¯¸ë„ŒìŠ¤ (15% ê°€ì¤‘ì¹˜)
    dominance = dominance_data.get('dominance', 0)
    if dominance > 45:
        dom_score = 80 if 'BTC' in symbol else 40
        factors.append(f"{'âœ…' if 'BTC' in symbol else 'âš ï¸'} BTC Dominance High ({dominance:.1f}%)")
    else:
        dom_score = 40 if 'BTC' in symbol else 80
        factors.append(f"{'âš ï¸' if 'BTC' in symbol else 'âœ…'} BTC Dominance Low ({dominance:.1f}%)")
    scores.append(dom_score * 0.15)
    
    # 4. ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„ (10% ê°€ì¤‘ì¹˜)
    premium = kimchi_data.get('premium', 0)
    if premium > 3:
        kimchi_score = 75
        factors.append(f"âœ… Kimchi Premium Positive (+{premium:.2f}%)")
    elif premium < -3:
        kimchi_score = 25
        factors.append(f"âš ï¸ Kimchi Premium Negative ({premium:.2f}%)")
    else:
        kimchi_score = 50
    scores.append(kimchi_score * 0.1)
    
    # 5. í€ë”©ë¹„ (15% ê°€ì¤‘ì¹˜)
    funding = funding_data.get('funding_rate', 0)
    if funding > 0.1:
        funding_score = 30  # Over-leveraged long
        factors.append(f"âš ï¸ High Funding Rate (+{funding:.3f}%) - Overleveraged")
    elif funding < -0.05:
        funding_score = 70  # Short squeeze potential
        factors.append(f"âœ… Negative Funding ({funding:.3f}%) - Short Squeeze Risk")
    else:
        funding_score = 60
        factors.append("âœ… Balanced Funding Rate")
    scores.append(funding_score * 0.15)
    
    # 6. AI ì‹ ë¢°ë„ (10% ê°€ì¤‘ì¹˜)
    ai_score = ai_confidence * 100
    scores.append(ai_score * 0.1)
    if ai_confidence > 0.7:
        factors.append(f"âœ… High AI Confidence ({ai_confidence:.1%})")
    
    # ì¢…í•© ì ìˆ˜
    overall_score = sum(scores)
    
    # ì¶”ì²œ ê²°ì •
    if overall_score >= 75:
        recommendation = "Strong Buy"
        risk_level = "Low"
    elif overall_score >= 60:
        recommendation = "Buy"
        risk_level = "Medium"
    elif overall_score >= 40:
        recommendation = "Hold"
        risk_level = "Medium"
    elif overall_score >= 25:
        recommendation = "Sell"
        risk_level = "High"
    else:
        recommendation = "Strong Sell"
        risk_level = "Very High"
    
    # ì‹ ë¢°ë„ ê³„ì‚°
    confidence = (
        0.3 * (1 if news_data.get('status') == 'success' else 0) +
        0.2 * (1 if fred_data.get('status') in ['success', 'dummy'] else 0) +
        0.2 * (1 if dominance_data.get('status') == 'success' else 0) +
        0.15 * (1 if kimchi_data.get('status') == 'success' else 0) +
        0.15 * (1 if funding_data.get('status') == 'success' else 0)
    )
    
    summary = f"Comprehensive market analysis shows {recommendation} signal with {overall_score:.0f}/100 score."
    
    return {
        'overall_score': overall_score,
        'recommendation': recommendation,
        'confidence': confidence,
        'key_factors': factors,
        'risk_level': risk_level,
        'summary': summary,
        'timestamp': datetime.now().isoformat()
    }




# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.8.0: ê³ ê¸‰ ë¦¬ìŠ¤í¬ ê´€ë¦¬ í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•



# [v2.9.0] Monte Carlo simulation removed

def compare_position_sizing_strategies(investment_amount: float, entry_price: float,
                                      stop_loss: float, take_profit: float,
                                      ai_confidence: float, volatility: float,
                                      leverage: float = 1.0, rr_ratio: float = 2.0) -> dict:
    """
    ì—¬ëŸ¬ Position Sizing ì „ëµ ë¹„êµ
    1. Fixed Fractional (2%)
    2. Kelly Criterion (Half Kelly)
    3. Volatility Adjusted
    4. AI Confidence Based
    """
    stop_loss_distance = abs(entry_price - stop_loss)
    
    # 1. Fixed Fractional
    fixed_risk_pct = 0.02
    fixed_position_size = (investment_amount * fixed_risk_pct) / stop_loss_distance
    
    # 2. Kelly Criterion
    kelly_result = calculate_kelly_criterion(ai_confidence, rr_ratio, kelly_fraction=0.5)
    kelly_risk_pct = kelly_result['kelly_capped']
    kelly_position_size = (investment_amount * kelly_risk_pct) / stop_loss_distance
    
    # 3. Volatility Adjusted
    vol_adjusted_risk_pct = max(0.005, min(0.05, 0.02 / (volatility * 50 + 1)))
    vol_adjusted_position_size = (investment_amount * vol_adjusted_risk_pct) / stop_loss_distance
    
    # 4. AI Confidence Based
    ai_risk_pct = max(0.01, min(0.05, (ai_confidence / 100) * 0.05))
    ai_position_size = (investment_amount * ai_risk_pct) / stop_loss_distance
    
    strategies = {
        'fixed_fractional': {
            'name': 'ê³ ì • ë¹„ìœ¨ (2%)',
            'risk_pct': fixed_risk_pct * 100,
            'position_size': fixed_position_size,
            'position_value': fixed_position_size * entry_price,
            'max_loss': fixed_position_size * stop_loss_distance,
            'max_profit': fixed_position_size * (take_profit - entry_price),
            'required_margin': (fixed_position_size * entry_price) / leverage
        },
        'kelly_criterion': {
            'name': 'Kelly Criterion (Half)',
            'risk_pct': kelly_risk_pct * 100,
            'position_size': kelly_position_size,
            'position_value': kelly_position_size * entry_price,
            'max_loss': kelly_position_size * stop_loss_distance,
            'max_profit': kelly_position_size * (take_profit - entry_price),
            'required_margin': (kelly_position_size * entry_price) / leverage
        },
        'volatility_adjusted': {
            'name': 'ë³€ë™ì„± ì¡°ì •',
            'risk_pct': vol_adjusted_risk_pct * 100,
            'position_size': vol_adjusted_position_size,
            'position_value': vol_adjusted_position_size * entry_price,
            'max_loss': vol_adjusted_position_size * stop_loss_distance,
            'max_profit': vol_adjusted_position_size * (take_profit - entry_price),
            'required_margin': (vol_adjusted_position_size * entry_price) / leverage
        },
        'ai_confidence_based': {
            'name': 'AI ì‹ ë¢°ë„ ê¸°ë°˜',
            'risk_pct': ai_risk_pct * 100,
            'position_size': ai_position_size,
            'position_value': ai_position_size * entry_price,
            'max_loss': ai_position_size * stop_loss_distance,
            'max_profit': ai_position_size * (take_profit - entry_price),
            'required_margin': (ai_position_size * entry_price) / leverage
        }
    }
    
    recommended_strategy = 'kelly_criterion' if (kelly_result['recommendation'] == 'TRADE' and kelly_risk_pct >= 0.01) else 'fixed_fractional'
    
    return {
        'strategies': strategies,
        'recommended_strategy': recommended_strategy,
        'kelly_details': kelly_result
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Phase 2: ì›Œí¬-í¬ì›Œë“œ ê²€ì¦ (Walk-Forward Validation)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class NBeatsBlock(nn.Module):
    """N-BEATSì˜ ê¸°ë³¸ ë¸”ë¡"""
    def __init__(self, input_size, theta_size, hidden_size=256):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, hidden_size)
        self.fc4 = nn.Linear(hidden_size, hidden_size)
        
        # Backcast and Forecast heads
        self.backcast_fc = nn.Linear(hidden_size, input_size)
        self.forecast_fc = nn.Linear(hidden_size, theta_size)
        
    def forward(self, x):
        h = torch.relu(self.fc1(x))
        h = torch.relu(self.fc2(h))
        h = torch.relu(self.fc3(h))
        h = torch.relu(self.fc4(h))
        
        backcast = self.backcast_fc(h)
        forecast = self.forecast_fc(h)
        
        return backcast, forecast


class NBeatsModel(nn.Module):
    """N-BEATS ì „ì²´ ëª¨ë¸"""
    def __init__(self, input_size, forecast_size, num_blocks=3, hidden_size=256):
        super().__init__()
        self.blocks = nn.ModuleList([
            NBeatsBlock(input_size, forecast_size, hidden_size)
            for _ in range(num_blocks)
        ])
        
    def forward(self, x):
        residuals = x
        # [ì•ˆì „ì„±] ë””ë°”ì´ìŠ¤ ë¬¸ì œ í•´ê²° - xì™€ ê°™ì€ ë””ë°”ì´ìŠ¤ ì‚¬ìš©
        forecast = torch.zeros(x.size(0), self.blocks[0].forecast_fc.out_features, dtype=x.dtype, device=x.device)
        
        for block in self.blocks:
            backcast, block_forecast = block(residuals)
            residuals = residuals - backcast
            forecast = forecast + block_forecast
        
        return forecast


def train_nbeats(data, forecast_days=3, lookback=180, epochs=50):
    """N-BEATS ëª¨ë¸ í•™ìŠµ (ê²½ëŸ‰í™” ë²„ì „)"""
    if not TORCH_AVAILABLE:
        return None, None
    
    try:
        # [ì•ˆì „ì„±] ë°ì´í„° ê¸¸ì´ ì²´í¬
        if len(data) < lookback + forecast_days + 20:
            return None, None
        
        # [ìµœì í™”] lookback ì¶•ì†Œ (ë©”ëª¨ë¦¬ ì ˆì•½)
        effective_lookback = min(lookback, 60)  # ìµœëŒ€ 60ì¼ë¡œ ì œí•œ
        
        # ë°ì´í„° ì •ê·œí™”
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(data.values.reshape(-1, 1)).flatten()
        
        # í•™ìŠµ ë°ì´í„° ìƒì„±
        X, y = [], []
        for i in range(effective_lookback, len(scaled_data) - forecast_days):
            X.append(scaled_data[i-effective_lookback:i])
            y.append(scaled_data[i:i+forecast_days])
        
        if len(X) < 20:  # ìµœì†Œ 20ê°œ ìƒ˜í”Œ í•„ìš”
            return None, None
        
        # [ì•ˆì „ì„±] í…ì„œ ë³€í™˜ ì „ í¬ê¸° ì²´í¬
        if len(X) * effective_lookback > 100000:  # ë©”ëª¨ë¦¬ ì œí•œ
            # ìµœê·¼ 500ê°œë§Œ ì‚¬ìš©
            X = X[-500:]
            y = y[-500:]
        
        X = torch.FloatTensor(X)
        y = torch.FloatTensor(y)
        
    except Exception as e:
        # N-BEATS ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨
        return None, None
    
    try:
        # [ê²½ëŸ‰í™”] ì‘ì€ ëª¨ë¸ ì‚¬ìš©
        model = NBeatsModel(
            input_size=effective_lookback, 
            forecast_size=forecast_days, 
            num_blocks=2,  # 3â†’2 ë¸”ë¡
            hidden_size=64  # 128â†’64 ì°¨ì›
        )
        
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        # [ìµœì í™”] ë°°ì¹˜ í•™ìŠµ
        batch_size = min(32, len(X))
        num_batches = len(X) // batch_size
        
        # [ì•ˆì „ì„±] epochs ì œí•œ
        safe_epochs = min(epochs, 20)  # ìµœëŒ€ 20 epoch
        
        model.train()
        for epoch in range(safe_epochs):
            for i in range(num_batches):
                start_idx = i * batch_size
                end_idx = start_idx + batch_size
                
                X_batch = X[start_idx:end_idx]
                y_batch = y[start_idx:end_idx]
                
                optimizer.zero_grad()
                output = model(X_batch)
                loss = criterion(output, y_batch)
                loss.backward()
                optimizer.step()
        
        model.eval()
        return model, scaler
        
    except Exception as e:
        # N-BEATS í•™ìŠµ ì‹¤íŒ¨
        return None, None


def predict_nbeats(model, scaler, last_sequence, forecast_days=3):
    """N-BEATS ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence.reshape(-1, 1)).flatten()
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        forecast_original = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. TFT (Temporal Fusion Transformer) - ê°„ì†Œí™” ë²„ì „
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SimpleTFT(nn.Module):
    """ê°„ì†Œí™”ëœ TFT ëª¨ë¸ (í•µì‹¬ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜)"""
    def __init__(self, input_size, hidden_size=128, num_heads=4, forecast_size=3):
        super().__init__()
        self.embedding = nn.Linear(input_size, hidden_size)
        self.attention = nn.MultiheadAttention(hidden_size, num_heads, batch_first=True)
        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, forecast_size)
        
    def forward(self, x):
        # x shape: (batch, seq_len, features)
        embedded = self.embedding(x)
        
        # Self-attention
        attn_out, _ = self.attention(embedded, embedded, embedded)
        
        # LSTM
        lstm_out, _ = self.lstm(attn_out)
        
        # Take last timestep
        last_output = lstm_out[:, -1, :]
        
        # Forecast
        forecast = self.fc(last_output)
        
        return forecast


def train_tft(data, features_df, forecast_days=3, lookback=90, epochs=50):
    """TFT ëª¨ë¸ í•™ìŠµ (ê²½ëŸ‰í™” ë²„ì „)"""
    if not TORCH_AVAILABLE:
        return None, None
    
    try:
        # [ì•ˆì „ì„±] ë°ì´í„° ê¸¸ì´ ì²´í¬
        if len(data) < lookback + forecast_days + 20:
            return None, None
        
        # [ìµœì í™”] lookback ì¶•ì†Œ
        effective_lookback = min(lookback, 60)
        
        # ê°€ê²© + ì§€í‘œ ê²°í•©
        combined_data = features_df[['Close', 'RSI14', 'MACD', 'Volume']].iloc[-len(data):].values
        
        # ì •ê·œí™”
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(combined_data)
        
        # í•™ìŠµ ë°ì´í„° ìƒì„±
        X, y = [], []
        for i in range(effective_lookback, len(scaled_data) - forecast_days):
            X.append(scaled_data[i-effective_lookback:i])
            y.append(scaled_data[i:i+forecast_days, 0])  # Closeë§Œ ì˜ˆì¸¡
        
        if len(X) < 20:
            return None, None
        
        # [ì•ˆì „ì„±] ë©”ëª¨ë¦¬ ì œí•œ
        if len(X) > 500:
            X = X[-500:]
            y = y[-500:]
        
        X = torch.FloatTensor(X)
        y = torch.FloatTensor(y)
        
        # [ê²½ëŸ‰í™”] ì‘ì€ ëª¨ë¸
        model = SimpleTFT(
            input_size=combined_data.shape[1], 
            hidden_size=32,  # 64â†’32
            num_heads=2,      # 4â†’2
            forecast_size=forecast_days
        )
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        # [ìµœì í™”] ë°°ì¹˜ í•™ìŠµ
        batch_size = min(32, len(X))
        safe_epochs = min(epochs, 15)
        
        model.train()
        for epoch in range(safe_epochs):
            for i in range(0, len(X), batch_size):
                X_batch = X[i:i+batch_size]
                y_batch = y[i:i+batch_size]
                
                if len(X_batch) == 0:
                    continue
                
                optimizer.zero_grad()
                output = model(X_batch)
                loss = criterion(output, y_batch)
                loss.backward()
                optimizer.step()
        
        model.eval()
        return model, scaler
        
    except Exception as e:
        # TFT í•™ìŠµ ì‹¤íŒ¨
        return None, None


def predict_tft(model, scaler, last_sequence, forecast_days=3):
    """TFT ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence)
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        
        # ì—­ë³€í™˜ (Closeë§Œ)
        dummy = np.zeros((forecast.shape[0], scaler.n_features_in_))
        dummy[:, 0] = forecast
        forecast_original = scaler.inverse_transform(dummy)[:, 0]
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. XGBoost
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_xgboost(data, features_df, forecast_days=3, lookback=60):
    """XGBoost ëª¨ë¸ í•™ìŠµ"""
    if not XGBOOST_AVAILABLE:
        return None, None
    
    # íŠ¹ì§• ì„ íƒ (ê¸°ìˆ ì  ì§€í‘œ + íŒ¨í„´ íŠ¹ì§•)
    feature_cols = ['RSI14', 'MACD', 'StochK14', 'MFI14', 'ATR14',
                    'pattern_bullish', 'pattern_bearish', 'pattern_strength',
                    'pattern_momentum', 'pattern_recency', 'pattern_diversity']
    X_features = features_df[feature_cols].iloc[-len(data):].values
    
    # ì‹œê³„ì—´ íŠ¹ì§• ì¶”ê°€ (ê³¼ê±° ê°€ê²©)
    X, y = [], []
    for i in range(lookback, len(data) - forecast_days):
        past_prices = data.iloc[i-lookback:i].values
        past_features = X_features[i-lookback:i].mean(axis=0)  # í‰ê·  ì§€í‘œ
        X.append(np.concatenate([past_prices[-10:], past_features]))  # ìµœê·¼ 10ê°œ ê°€ê²© + ì§€í‘œ
        y.append(data.iloc[i+forecast_days-1])  # forecast_days í›„ ê°€ê²©
    
    if len(X) < 10:
        return None, None
    
    X = np.array(X)
    y = np.array(y)
    
    # XGBoost í•™ìŠµ
    model = xgb.XGBRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
    model.fit(X, y)
    
    return model, (lookback, feature_cols)


def predict_xgboost(model, metadata, data, features_df, forecast_days=3):
    """XGBoost ì˜ˆì¸¡"""
    if model is None or not XGBOOST_AVAILABLE:
        return None
    
    lookback, feature_cols = metadata
    X_features = features_df[feature_cols].values
    
    # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤
    past_prices = data.iloc[-lookback:].values
    past_features = X_features[-lookback:].mean(axis=0)
    X_pred = np.concatenate([past_prices[-10:], past_features]).reshape(1, -1)
    
    forecast = model.predict(X_pred)
    
    # ë°˜ë³µ ì˜ˆì¸¡ (ë‹¨ì¼ ìŠ¤í…ì”©)
    forecasts = [forecast[0]]
    for _ in range(1, forecast_days):
        # ì´ì „ ì˜ˆì¸¡ì„ í¬í•¨í•˜ì—¬ ë‹¤ìŒ ì˜ˆì¸¡
        new_prices = np.append(past_prices[1-10:], forecasts[-1])
        X_pred = np.concatenate([new_prices, past_features]).reshape(1, -1)
        forecasts.append(model.predict(X_pred)[0])
    
    return np.array(forecasts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. GRU (Gated Recurrent Unit)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class GRUModel(nn.Module):
    """GRU ëª¨ë¸ (ê²½ëŸ‰í™”)"""
    def __init__(self, input_size=1, hidden_size=64, num_layers=2, forecast_size=3):
        super().__init__()
        # [ì•ˆì „ì„±] dropoutì€ num_layers>1ì¼ ë•Œë§Œ ì‚¬ìš©
        if num_layers > 1:
            self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        else:
            self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, forecast_size)
        
    def forward(self, x):
        out, _ = self.gru(x)
        out = self.fc(out[:, -1, :])
        return out


def train_gru(data, forecast_days=3, lookback=120, epochs=50):
    """GRU ëª¨ë¸ í•™ìŠµ (ê²½ëŸ‰í™”)"""
    if not TORCH_AVAILABLE:
        return None, None
    
    try:
        # [ì•ˆì „ì„±] ë°ì´í„° ì²´í¬
        if len(data) < lookback + forecast_days + 20:
            return None, None
        
        # [ìµœì í™”] lookback ì¶•ì†Œ
        effective_lookback = min(lookback, 60)
        
        # ë°ì´í„° ì •ê·œí™”
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(data.values.reshape(-1, 1))
        
        # í•™ìŠµ ë°ì´í„° ìƒì„±
        X, y = [], []
        for i in range(effective_lookback, len(scaled_data) - forecast_days):
            X.append(scaled_data[i-effective_lookback:i])
            y.append(scaled_data[i:i+forecast_days].flatten())
        
        if len(X) < 20:
            return None, None
        
        # [ì•ˆì „ì„±] ë©”ëª¨ë¦¬ ì œí•œ
        if len(X) > 500:
            X = X[-500:]
            y = y[-500:]
        
        X = torch.FloatTensor(X)
        y = torch.FloatTensor(y)
        
        # [ê²½ëŸ‰í™”] ì‘ì€ ëª¨ë¸
        model = GRUModel(
            input_size=1, 
            hidden_size=32,  # 64â†’32
            num_layers=1,    # 2â†’1
            forecast_size=forecast_days
        )
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        # [ìµœì í™”] ë°°ì¹˜ í•™ìŠµ
        batch_size = min(32, len(X))
        safe_epochs = min(epochs, 15)
        
        model.train()
        for epoch in range(safe_epochs):
            for i in range(0, len(X), batch_size):
                X_batch = X[i:i+batch_size]
                y_batch = y[i:i+batch_size]
                
                if len(X_batch) == 0:
                    continue
                
                optimizer.zero_grad()
                output = model(X_batch)
                loss = criterion(output, y_batch)
                loss.backward()
                optimizer.step()
        
        model.eval()
        return model, scaler
        
    except Exception as e:
        # GRU í•™ìŠµ ì‹¤íŒ¨
        return None, None


def predict_gru(model, scaler, last_sequence, forecast_days=3):
    """GRU ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence.reshape(-1, 1))
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        forecast_original = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. LightGBM
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_lightgbm(data, features_df, forecast_days=3, lookback=60):
    """LightGBM ëª¨ë¸ í•™ìŠµ"""
    if not LIGHTGBM_AVAILABLE:
        return None, None
    
    # íŠ¹ì§• ì„ íƒ (ê¸°ìˆ  ì§€í‘œ + íŒ¨í„´ íŠ¹ì§•)
    feature_cols = ['RSI14', 'MACD', 'StochK14', 'MFI14', 'ATR14', 'BB_upper', 'BB_lower',
                    'pattern_bullish', 'pattern_bearish', 'pattern_strength',
                    'pattern_momentum', 'pattern_recency', 'pattern_diversity']
    X_features = features_df[feature_cols].iloc[-len(data):].values
    
    # í•™ìŠµ ë°ì´í„° ìƒì„±
    X, y = [], []
    for i in range(lookback, len(data) - forecast_days):
        past_prices = data.iloc[i-lookback:i].values
        past_features = X_features[i-lookback:i].mean(axis=0)
        X.append(np.concatenate([past_prices[-10:], past_features]))
        y.append(data.iloc[i+forecast_days-1])
    
    if len(X) < 10:
        return None, None
    
    X = np.array(X)
    y = np.array(y)
    
    # LightGBM í•™ìŠµ
    model = lgb.LGBMRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42,
        verbose=-1
    )
    model.fit(X, y)
    
    return model, (lookback, feature_cols)


def predict_lightgbm(model, metadata, data, features_df, forecast_days=3):
    """LightGBM ì˜ˆì¸¡"""
    if model is None or not LIGHTGBM_AVAILABLE:
        return None
    
    lookback, feature_cols = metadata
    X_features = features_df[feature_cols].values
    
    # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤
    past_prices = data.iloc[-lookback:].values
    past_features = X_features[-lookback:].mean(axis=0)
    X_pred = np.concatenate([past_prices[-10:], past_features]).reshape(1, -1)
    
    forecasts = [model.predict(X_pred)[0]]
    for _ in range(1, forecast_days):
        new_prices = np.append(past_prices[1-10:], forecasts[-1])
        X_pred = np.concatenate([new_prices, past_features]).reshape(1, -1)
        forecasts.append(model.predict(X_pred)[0])
    
    return np.array(forecasts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. Prophet (ê°„ë‹¨í•œ ë˜í¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_prophet(data, forecast_days=3):
    """Prophet ëª¨ë¸ í•™ìŠµ"""
    if not PROPHET_AVAILABLE:
        return None
    
    # Prophet í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (timezone ì œê±°)
    df_prophet = pd.DataFrame({
        'ds': pd.to_datetime(data.index).tz_localize(None),
        'y': data.values
    })
    
    model = Prophet(
        daily_seasonality=True,
        weekly_seasonality=True,
        yearly_seasonality=False,
        changepoint_prior_scale=0.05
    )
    
    model.fit(df_prophet)
    
    return model


def predict_prophet(model, forecast_days=3):
    """Prophet ì˜ˆì¸¡"""
    if model is None or not PROPHET_AVAILABLE:
        return None
    
    future = model.make_future_dataframe(periods=forecast_days)
    forecast = model.predict(future)
    
    return forecast['yhat'].iloc[-forecast_days:].values


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. LSTM (ê¸°ì¡´ë³´ë‹¤ ê°•í™”ëœ ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LSTMModel(nn.Module):
    """LSTM ëª¨ë¸ (ê²½ëŸ‰í™”)"""
    def __init__(self, input_size=1, hidden_size=128, num_layers=3, forecast_size=3):
        super().__init__()
        # [ì•ˆì „ì„±] dropoutì€ num_layers>1ì¼ ë•Œë§Œ ì‚¬ìš©
        if num_layers > 1:
            self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        else:
            self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, forecast_size)
        
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out


def train_lstm(data, forecast_days=3, lookback=120, epochs=50):
    """LSTM ëª¨ë¸ í•™ìŠµ (ê²½ëŸ‰í™”)"""
    if not TORCH_AVAILABLE:
        return None, None
    
    try:
        # [ì•ˆì „ì„±] ë°ì´í„° ì²´í¬
        if len(data) < lookback + forecast_days + 20:
            return None, None
        
        # [ìµœì í™”] lookback ì¶•ì†Œ
        effective_lookback = min(lookback, 60)
        
        # ë°ì´í„° ì •ê·œí™”
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(data.values.reshape(-1, 1))
        
        # í•™ìŠµ ë°ì´í„° ìƒì„±
        X, y = [], []
        for i in range(effective_lookback, len(scaled_data) - forecast_days):
            X.append(scaled_data[i-effective_lookback:i])
            y.append(scaled_data[i:i+forecast_days].flatten())
        
        if len(X) < 20:
            return None, None
        
        # [ì•ˆì „ì„±] ë©”ëª¨ë¦¬ ì œí•œ
        if len(X) > 500:
            X = X[-500:]
            y = y[-500:]
        
        X = torch.FloatTensor(X)
        y = torch.FloatTensor(y)
        
        # [ê²½ëŸ‰í™”] ì‘ì€ ëª¨ë¸
        model = LSTMModel(
            input_size=1, 
            hidden_size=32,  # 128â†’32
            num_layers=1,    # 3â†’1
            forecast_size=forecast_days
        )
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        # [ìµœì í™”] ë°°ì¹˜ í•™ìŠµ
        batch_size = min(32, len(X))
        safe_epochs = min(epochs, 15)
        
        model.train()
        for epoch in range(safe_epochs):
            for i in range(0, len(X), batch_size):
                X_batch = X[i:i+batch_size]
                y_batch = y[i:i+batch_size]
                
                if len(X_batch) == 0:
                    continue
                
                optimizer.zero_grad()
                output = model(X_batch)
                loss = criterion(output, y_batch)
                loss.backward()
                optimizer.step()
        
        model.eval()
        return model, scaler
        
    except Exception as e:
        # LSTM í•™ìŠµ ì‹¤íŒ¨
        return None, None


def predict_lstm(model, scaler, last_sequence, forecast_days=3):
    """LSTM ì˜ˆì¸¡"""
    if model is None or not TORCH_AVAILABLE:
        return None
    
    with torch.no_grad():
        last_scaled = scaler.transform(last_sequence.reshape(-1, 1))
        X = torch.FloatTensor(last_scaled).unsqueeze(0)
        forecast = model(X).numpy().flatten()
        forecast_original = scaler.inverse_transform(forecast.reshape(-1, 1)).flatten()
    
    return forecast_original


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. ì•™ìƒë¸” ì¡°í•© ë° ìë™ ì„ íƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_ensemble_config(interval):
    """
    ì‹œê°„ í”„ë ˆì„ì— ë”°ë¥¸ ì•™ìƒë¸” ëª¨ë¸ ìë™ ì„ íƒ
    
    Parameters:
    -----------
    interval : str
        ì‹œê°„ í”„ë ˆì„ ('1m', '5m', '1h', '1d')
    
    Returns:
    --------
    dict : ì•™ìƒë¸” ì„¤ì •
        - 'models': ì‚¬ìš©í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
        - 'weights': ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜
        - 'lookback': í•™ìŠµ ìœˆë„ìš° í¬ê¸°
        - 'epochs': í•™ìŠµ ì—í­ ìˆ˜
    """
    if interval in ['1m', '5m']:
        # ì´ˆë‹¨íƒ€ íŠ¸ë ˆì´ë”©: N-BEATS + TFT + XGBoost
        return {
            'models': ['nbeats', 'tft', 'xgboost'],
            'weights': [0.40, 0.35, 0.25],
            'lookback': {'nbeats': 60, 'tft': 60, 'xgboost': 60},  # [ìµœì í™”] ì¶•ì†Œ
            'epochs': 20,  # [ìµœì í™”] 30â†’20
            'description': 'ì´ˆë‹¨íƒ€ íŠ¸ë ˆì´ë”© (N-BEATS 40% + TFT 35% + XGBoost 25%)'
        }
    elif interval == '1h':
        # ë‹¨ê¸° íŠ¸ë ˆì´ë”© ìƒë‹¨: N-BEATS + TFT + XGBoost (ì‹œê°„ë´‰ë„ ë¹ ë¥¸ í¸)
        return {
            'models': ['nbeats', 'tft', 'xgboost'],
            'weights': [0.40, 0.35, 0.25],
            'lookback': {'nbeats': 60, 'tft': 60, 'xgboost': 60},  # [ìµœì í™”] ì¶•ì†Œ
            'epochs': 20,  # [ìµœì í™”] 40â†’20
            'description': 'ì‹œê°„ë´‰ íŠ¸ë ˆì´ë”© (N-BEATS 40% + TFT 35% + XGBoost 25%)'
        }
    elif interval == '1d':
        # ë‹¨ê¸° íŠ¸ë ˆì´ë”©: LightGBM + GRU + Prophet
        return {
            'models': ['gru', 'lightgbm', 'prophet'],
            'weights': [0.40, 0.35, 0.25],
            'lookback': {'gru': 60, 'lightgbm': 60, 'prophet': None},  # [ìµœì í™”] ì¶•ì†Œ
            'epochs': 20,  # [ìµœì í™”] 50â†’20
            'description': 'ì¼ë´‰ íŠ¸ë ˆì´ë”© (GRU 40% + LightGBM 35% + Prophet 25%)'
        }
    else:
        # ì¤‘ê¸° íŠ¸ë ˆì´ë”© (ì£¼ë´‰ ì´ìƒ): XGBoost + LSTM + Holt-Winters
        return {
            'models': ['lstm', 'xgboost', 'holtwinters'],
            'weights': [0.45, 0.30, 0.25],
            'lookback': {'lstm': 60, 'xgboost': 60, 'holtwinters': None},  # [ìµœì í™”] ì¶•ì†Œ
            'epochs': 20,  # [ìµœì í™”] 50â†’20
            'description': 'ì¤‘ê¸° íŠ¸ë ˆì´ë”© (LSTM 45% + XGBoost 30% + Holt-Winters 25%)'
        }


def train_ensemble_models(data, features_df, interval, forecast_days=3):
    """
    ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
    
    Parameters:
    -----------
    data : pd.Series
        ê°€ê²© ë°ì´í„°
    features_df : pd.DataFrame
        ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„°
    interval : str
        ì‹œê°„ í”„ë ˆì„
    forecast_days : int
        ì˜ˆì¸¡ ì¼ìˆ˜
    
    Returns:
    --------
    dict : í•™ìŠµëœ ëª¨ë¸ë“¤ê³¼ ë©”íƒ€ë°ì´í„°
    """
    config = get_ensemble_config(interval)
    models = {}
    
    st.info(f"ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ ì„ íƒ: {config['description']}")
    
    progress_bar = st.progress(0)
    status_text = st.empty()  # ë™ì  ìƒíƒœ í…ìŠ¤íŠ¸ìš©
    total_models = len(config['models'])
    
    for idx, model_name in enumerate(config['models']):
        try:
            lookback = config['lookback'].get(model_name, 90)
            epochs = config['epochs']
            
            status_text.text(f"ğŸ”„ í•™ìŠµ ì¤‘: {model_name.upper()} ({idx+1}/{total_models}) - lookback={lookback}, epochs={epochs}")
            
            if model_name == 'nbeats':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_nbeats(data, forecast_days, lookback, epochs)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨ (ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ì˜¤ë¥˜)")
                        models[model_name] = None
                    else:
                        models['nbeats'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'tft':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_tft(data, features_df, forecast_days, lookback, epochs)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨")
                        models[model_name] = None
                    else:
                        models['tft'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'xgboost':
                if not XGBOOST_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: XGBoost ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, metadata = train_xgboost(data, features_df, forecast_days, lookback)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨")
                        models[model_name] = None
                    else:
                        models['xgboost'] = {'model': model, 'metadata': metadata}
            
            elif model_name == 'gru':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_gru(data, forecast_days, lookback, epochs)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨")
                        models[model_name] = None
                    else:
                        models['gru'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'lightgbm':
                if not LIGHTGBM_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: LightGBM ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, metadata = train_lightgbm(data, features_df, forecast_days, lookback)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨")
                        models[model_name] = None
                    else:
                        models['lightgbm'] = {'model': model, 'metadata': metadata}
            
            elif model_name == 'prophet':
                if not PROPHET_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: Prophet ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model = train_prophet(data, forecast_days)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨")
                        models[model_name] = None
                    else:
                        models['prophet'] = {'model': model}
            
            elif model_name == 'lstm':
                if not TORCH_AVAILABLE:
                    st.warning(f"âš ï¸ {model_name} ì‚¬ìš© ë¶ˆê°€: PyTorch ë¯¸ì„¤ì¹˜")
                    models[model_name] = None
                else:
                    model, scaler = train_lstm(data, forecast_days, lookback, epochs)
                    if model is None:
                        st.warning(f"âš ï¸ {model_name} í•™ìŠµ ì‹¤íŒ¨")
                        models[model_name] = None
                    else:
                        models['lstm'] = {'model': model, 'scaler': scaler}
            
            elif model_name == 'holtwinters':
                # Holt-WintersëŠ” ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©
                hw_model, seasonality_info, window_size = fit_hw_model_robust(data, max_window=500)
                models['holtwinters'] = {'model': hw_model, 'seasonality': seasonality_info}
            
            progress_bar.progress((idx + 1) / total_models)
        
        except Exception as e:
            st.error(f"âŒ {model_name.upper()} í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {type(e).__name__}")
            st.exception(e)  # ì „ì²´ traceback í‘œì‹œ
            models[model_name] = None
    
    progress_bar.empty()
    status_text.empty()
    
    # í•™ìŠµ ê²°ê³¼ ìš”ì•½
    successful_models = [k for k, v in models.items() if v is not None]
    st.success(f"âœ… í•™ìŠµ ì™„ë£Œ: {len(successful_models)}/{total_models} ëª¨ë¸ ì„±ê³µ")
    if successful_models:
        st.info(f"ğŸ¯ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸: {', '.join([m.upper() for m in successful_models])}")
    
    return models, config


def predict_ensemble(models, config, data, features_df, forecast_days=3):
    """
    ì•™ìƒë¸” ì˜ˆì¸¡
    
    Parameters:
    -----------
    models : dict
        í•™ìŠµëœ ëª¨ë¸ë“¤
    config : dict
        ì•™ìƒë¸” ì„¤ì •
    data : pd.Series
        ê°€ê²© ë°ì´í„°
    features_df : pd.DataFrame
        ê¸°ìˆ ì  ì§€í‘œ
    forecast_days : int
        ì˜ˆì¸¡ ì¼ìˆ˜
    
    Returns:
    --------
    np.array : ì•™ìƒë¸” ì˜ˆì¸¡ê°’
    dict : ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ê°’
    """
    predictions = {}
    weights = {}
    
    for model_name, weight in zip(config['models'], config['weights']):
        if models.get(model_name) is None:
            continue
        
        try:
            model_data = models[model_name]
            lookback = config['lookback'].get(model_name, 90)
            
            if model_name == 'nbeats':
                pred = predict_nbeats(
                    model_data['model'], 
                    model_data['scaler'], 
                    data.iloc[-lookback:].values, 
                    forecast_days
                )
            
            elif model_name == 'tft':
                last_features = features_df[['Close', 'RSI14', 'MACD', 'Volume']].iloc[-lookback:].values
                pred = predict_tft(
                    model_data['model'], 
                    model_data['scaler'], 
                    last_features, 
                    forecast_days
                )
            
            elif model_name == 'xgboost':
                pred = predict_xgboost(
                    model_data['model'], 
                    model_data['metadata'], 
                    data, 
                    features_df, 
                    forecast_days
                )
            
            elif model_name == 'gru':
                pred = predict_gru(
                    model_data['model'], 
                    model_data['scaler'], 
                    data.iloc[-lookback:].values, 
                    forecast_days
                )
            
            elif model_name == 'lightgbm':
                pred = predict_lightgbm(
                    model_data['model'], 
                    model_data['metadata'], 
                    data, 
                    features_df, 
                    forecast_days
                )
            
            elif model_name == 'prophet':
                pred = predict_prophet(model_data['model'], forecast_days)
            
            elif model_name == 'lstm':
                pred = predict_lstm(
                    model_data['model'], 
                    model_data['scaler'], 
                    data.iloc[-lookback:].values, 
                    forecast_days
                )
            
            elif model_name == 'holtwinters':
                hw_forecast = model_data['model'].forecast(steps=forecast_days)
                pred = hw_forecast.values
            
            if pred is not None and len(pred) == forecast_days:
                predictions[model_name] = pred
                weights[model_name] = weight
        
        except Exception as e:
            st.warning(f"âš ï¸ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    
    # ê°€ì¤‘ í‰ê· 
    if not predictions:
        return None, {}
    
    # ê°€ì¤‘ì¹˜ ì •ê·œí™”
    total_weight = sum(weights.values())
    normalized_weights = {k: v/total_weight for k, v in weights.items()}
    
    # ì•™ìƒë¸” ì˜ˆì¸¡
    ensemble_forecast = np.zeros(forecast_days)
    for model_name, pred in predictions.items():
        ensemble_forecast += pred * normalized_weights[model_name]
    
    return ensemble_forecast, predictions


def detect_seasonality_auto(series: pd.Series, max_period: int = 30) -> tuple:
    """
    ìë™ ê³„ì ˆì„± ê°ì§€ (v2.4.0)
    
    Returns:
        tuple: (has_seasonality: bool, optimal_period: int, seasonality_type: str)
    """
    from scipy import stats
    
    if len(series) < 20:
        return False, None, None
    
    # 1. ACF ê¸°ë°˜ ê³„ì ˆì„± ê°ì§€
    try:
        from statsmodels.tsa.stattools import acf
        acf_values = acf(series, nlags=min(max_period, len(series) // 2), fft=True)
        
        # ACF í”¼í¬ ì°¾ê¸° (ì²« ë²ˆì§¸ ì§€ì—° ì œì™¸)
        peaks = []
        for i in range(2, len(acf_values)):
            if acf_values[i] > 0.3:  # ì„ê³„ê°’
                peaks.append((i, acf_values[i]))
        
        if peaks:
            # ê°€ì¥ ê°•í•œ í”¼í¬ ì„ íƒ
            optimal_period = max(peaks, key=lambda x: x[1])[0]
            has_seasonality = True
        else:
            has_seasonality = False
            optimal_period = None
    except:
        has_seasonality = False
        optimal_period = None
    
    # 2. ë³€ë™ì„± ê¸°ë°˜ ê³„ì ˆì„± íƒ€ì… ê²°ì •
    if has_seasonality:
        volatility = series.pct_change().std()
        if volatility > 0.05:
            seasonality_type = 'mul'  # ë³€ë™ì„± ë†’ìœ¼ë©´ multiplicative
        else:
            seasonality_type = 'add'  # ë³€ë™ì„± ë‚®ìœ¼ë©´ additive
    else:
        seasonality_type = None
    
    return has_seasonality, optimal_period, seasonality_type


def fit_hw_model_robust(series: pd.Series, max_window: int = 500) -> tuple:
    """
    ê°•ê±´í•œ Holt-Winters ëª¨ë¸ í•™ìŠµ (v2.4.0)
    
    Features:
    - ìë™ ê³„ì ˆì„± ê°ì§€
    - ìµœì‹  ìœˆë„ìš° ì œí•œ (ì„±ëŠ¥ ê°œì„ )
    - í´ë°± ì „ëµ
    
    Returns:
        tuple: (model, seasonality_info: dict, training_window_size: int)
    """
    import statsmodels.api as sm
    
    # ìµœì‹  ë°ì´í„°ë§Œ ì‚¬ìš© (ì„±ëŠ¥ ê°œì„ )
    if len(series) > max_window:
        series_windowed = series.iloc[-max_window:]
        original_index = series.index
        window_used = max_window
    else:
        series_windowed = series
        original_index = series.index
        window_used = len(series)
    
    # ê³„ì ˆì„± ìë™ ê°ì§€
    has_seasonality, optimal_period, seasonality_type = detect_seasonality_auto(
        series_windowed, 
        max_period=min(30, len(series_windowed) // 3)
    )
    
    seasonality_info = {
        'detected': has_seasonality,
        'period': optimal_period,
        'type': seasonality_type,
        'window_size': window_used
    }
    
    # ëª¨ë¸ í•™ìŠµ (ê³„ì¸µì  í´ë°±)
    model = None
    error_log = []
    
    # Try 1: ê°ì§€ëœ ê³„ì ˆì„± ì‚¬ìš©
    if has_seasonality and optimal_period and optimal_period >= 2:
        try:
            model = sm.tsa.ExponentialSmoothing(
                series_windowed,
                trend='add',
                seasonal=seasonality_type,
                seasonal_periods=optimal_period,
                initialization_method="estimated"
            ).fit(optimized=True)
            seasonality_info['model_type'] = f'{seasonality_type}_seasonal'
            return model, seasonality_info, window_used
        except Exception as e:
            error_log.append(f"Seasonal model failed: {str(e)[:50]}")
    
    # Try 2: ë‹¨ìˆœ ê³„ì ˆì„± (period=7)
    if len(series_windowed) >= 14:
        try:
            model = sm.tsa.ExponentialSmoothing(
                series_windowed,
                trend='add',
                seasonal='add',
                seasonal_periods=7,
                initialization_method="estimated"
            ).fit(optimized=True)
            seasonality_info['model_type'] = 'default_seasonal'
            seasonality_info['period'] = 7
            return model, seasonality_info, window_used
        except Exception as e:
            error_log.append(f"Default seasonal failed: {str(e)[:50]}")
    
    # Try 3: ë¹„ê³„ì ˆ ëª¨ë¸ (í´ë°±)
    try:
        model = sm.tsa.ExponentialSmoothing(
            series_windowed,
            trend='add',
            seasonal=None,
            initialization_method="estimated"
        ).fit(optimized=True)
        seasonality_info['model_type'] = 'non_seasonal'
        seasonality_info['detected'] = False
        return model, seasonality_info, window_used
    except Exception as e:
        error_log.append(f"Non-seasonal failed: {str(e)[:50]}")
    
    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
    raise ValueError(f"All model fitting attempts failed: {'; '.join(error_log)}")


def forecast_with_offset_scaling(model, steps: int, last_actual_value: float, 
                                  recent_trend: float) -> np.ndarray:
    """
    ì˜¤í”„ì…‹ ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡ (v2.4.0)
    
    ì ˆëŒ€ê°€ê²© ëŒ€ì‹  ì°¨ë¶„(difference) ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í•˜ì—¬ í•˜ë½ ì¶”ì„¸ ë³´ì •
    
    Args:
        model: í•™ìŠµëœ HW ëª¨ë¸
        steps: ì˜ˆì¸¡ ìŠ¤í… ìˆ˜
        last_actual_value: ë§ˆì§€ë§‰ ì‹¤ì œ ê°€ê²©
        recent_trend: ìµœê·¼ ì¶”ì„¸ (ì´ë™í‰ê·  ê¸°ìš¸ê¸°)
    
    Returns:
        np.ndarray: ë³´ì •ëœ ì˜ˆì¸¡ê°’
    """
    # ëª¨ë¸ ì˜ˆì¸¡ (ì°¨ë¶„ ê³µê°„)
    raw_forecast = model.forecast(steps=steps)
    
    # ì˜¤í”„ì…‹ ë³´ì •
    # 1. ì²« ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ ê³„ì‚°
    offset = last_actual_value - raw_forecast.iloc[0]
    
    # 2. ì¶”ì„¸ ë³´ì • (ìµœê·¼ ì¶”ì„¸ ë°˜ì˜)
    trend_correction = np.linspace(0, recent_trend * steps, steps)
    
    # 3. ìµœì¢… ì˜ˆì¸¡ê°’ = ì›ë³¸ ì˜ˆì¸¡ + ì˜¤í”„ì…‹ + ì¶”ì„¸ ë³´ì •
    corrected_forecast = raw_forecast + offset + trend_correction
    
    return corrected_forecast




def perform_timeseries_cv(df: pd.DataFrame, n_splits: int = 5) -> pd.DataFrame:
    """TimeSeriesSplit ê²€ì¦"""
    if len(df) < n_splits * 10:
        return pd.DataFrame({
            'Fold': [1],
            'Accuracy': ['N/A (ë°ì´í„° ë¶€ì¡±)'],
            'MASE': ['N/A'],
            'Mean_Error': ['N/A'],
            'Train_Size': [len(df)],
            'Test_Size': [0]
        })
    
    tscv = TimeSeriesSplit(n_splits=n_splits)
    results = []
    
    close_values = df['Close'].values
    
    for fold, (train_idx, test_idx) in enumerate(tscv.split(close_values), 1):
        train_data = close_values[train_idx]
        test_data = close_values[test_idx]
        
        if len(train_data) < 20:
            results.append({
                'Fold': fold,
                'Accuracy': 'N/A',
                'MASE': 'N/A',
                'Mean_Error': 'N/A',
                'Train_Size': len(train_data),
                'Test_Size': len(test_data)
            })
            continue
        
        try:
            seasonal_periods = min(7, len(train_data) // 3)
            
            if seasonal_periods >= 2:
                hw_model = sm.tsa.ExponentialSmoothing(
                    train_data,
                    trend='add',
                    seasonal='add',
                    seasonal_periods=seasonal_periods,
                    initialization_method="estimated"
                ).fit(optimized=True)
            else:
                hw_model = sm.tsa.ExponentialSmoothing(
                    train_data,
                    trend='add',
                    seasonal=None,
                    initialization_method="estimated"
                ).fit(optimized=True)
            
            forecast = hw_model.forecast(steps=len(test_data))
            
            if len(test_data) > 1:
                actual_direction = np.sign(np.diff(test_data))
                pred_direction = np.sign(np.diff(forecast))
                accuracy = (actual_direction == pred_direction).mean() * 100
            else:
                accuracy = 0.0
            
            mase = calculate_mase(test_data[1:], forecast[1:], train_data)
            mean_error = np.abs(test_data - forecast).mean()
            
            results.append({
                'Fold': fold,
                'Accuracy': f"{accuracy:.2f}%",
                'MASE': f"{mase:.4f}",
                'Mean_Error': f"${mean_error:.2f}",
                'Train_Size': len(train_data),
                'Test_Size': len(test_data)
            })
        except Exception as e:
            results.append({
                'Fold': fold,
                'Accuracy': 'N/A',
                'MASE': 'N/A',
                'Mean_Error': 'N/A',
                'Train_Size': len(train_data),
                'Test_Size': len(test_data)
            })
    
    return pd.DataFrame(results)


def calculate_mase(actual, forecast, train_data):
    """MASE ê³„ì‚°"""
    try:
        mae = np.mean(np.abs(actual - forecast))
        naive_mae = np.mean(np.abs(np.diff(train_data)))
        if naive_mae == 0:
            return 999.0
        mase = mae / naive_mae
        return mase
    except:
        return 999.0


def calculate_rr_ratio(entry_price: float, take_profit: float, stop_loss: float) -> float:
    """Risk-Reward Ratio ê³„ì‚°"""
    reward = abs(take_profit - entry_price)
    risk = abs(entry_price - stop_loss)
    
    if risk == 0:
        return 999.0
    
    return reward / risk


def render_progress_bar(step: int, total: int = 6):
    """ì§„í–‰ ìƒíƒœ"""
    steps = ['ë°ì´í„° ë¡œë“œ', 'ì§€í‘œ ê³„ì‚°', 'AI í•™ìŠµ', 'íŒ¨í„´ ë¶„ì„', 'ê²€ì¦', 'ê²°ê³¼ ìƒì„±']
    progress_html = '<div style="margin: 20px 0;">'
    for i, step_name in enumerate(steps[:total], 1):
        if i <= step:
            progress_html += f'<span class="progress-step active">{i}. {step_name}</span>'
        else:
            progress_html += f'<span class="progress-step">{i}. {step_name}</span>'
    progress_html += '</div>'
    return progress_html


def render_data_summary(df: pd.DataFrame, selected_crypto: str, interval_name: str):
    """ë°ì´í„° ìš”ì•½"""
    st.markdown("<div class='section-title'>ğŸ“Š ë°ì´í„° ê°œìš”</div>", unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    current_price = df['Close'].iloc[-1]
    daily_change = df['ì¼ì¼ìˆ˜ìµë¥ '].iloc[-1] * 100
    avg_volume = df['Volume'].mean()
    total_periods = len(df)
    
    with col1:
        st.metric(
            label=f"í˜„ì¬ê°€ (USD)",
            value=f"${current_price:,.2f}",
            delta=f"{daily_change:+.2f}%"
        )
    
    with col2:
        period_text = f"{total_periods} ê¸°ê°„"
        st.metric(
            label=f"ë¶„ì„ ê¸°ê°„ ({interval_name})",
            value=period_text
        )
    
    with col3:
        st.metric(
            label="í‰ê·  ê±°ë˜ëŸ‰",
            value=f"{avg_volume:,.0f}"
        )
    
    with col4:
        volatility = df['Volatility30d'].iloc[-1] * 100
        st.metric(
            label="ë³€ë™ì„± (30ê¸°ê°„)",
            value=f"{volatility:.2f}%"
        )


def render_ai_forecast(future_df: pd.DataFrame, hw_confidence: float):
    """AI ì˜ˆì¸¡"""
    st.markdown("<div class='section-title'>ğŸ¤– AI ì˜ˆì¸¡ (Holt-Winters Seasonal)</div>", unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=future_df.index,
            y=future_df['ì˜ˆì¸¡ ì¢…ê°€'],
            mode='lines+markers',
            name='ì˜ˆì¸¡ ì¢…ê°€',
            line=dict(color='#667EEA', width=3),
            marker=dict(size=8)
        ))
        
        fig.update_layout(
            title="í–¥í›„ 30ì¼ ì˜ˆì¸¡",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ì˜ˆì¸¡ ê°€ê²© (USD)",
            template="plotly_white",
            height=400,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### ğŸ“ˆ ì˜ˆì¸¡ ìš”ì•½")
        st.metric(
            label="30ì¼ í›„ ì˜ˆìƒê°€",
            value=f"${future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[-1]:,.2f}",
            delta=f"{((future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[-1] / future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[0]) - 1) * 100:+.2f}%"
        )
        
        st.metric(
            label="ëª¨ë¸ ì‹ ë¢°ë„",
            value=f"{hw_confidence:.1f}%"
        )
        
        predicted_change = ((future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[-1] / future_df['ì˜ˆì¸¡ ì¢…ê°€'].iloc[0]) - 1) * 100
        
        if predicted_change > 5:
            st.success("ğŸš€ ê°•í•œ ìƒìŠ¹ ì˜ˆìƒ")
        elif predicted_change > 0:
            st.info("ğŸ“ˆ ì†Œí­ ìƒìŠ¹ ì˜ˆìƒ")
        elif predicted_change > -5:
            st.warning("ğŸ“‰ ì†Œí­ í•˜ë½ ì˜ˆìƒ")
        else:
            st.error("âš ï¸ ê°•í•œ í•˜ë½ ì˜ˆìƒ")


def render_patterns(patterns: list):
    """íŒ¨í„´ ë¶„ì„ (ê°œì„ ëœ ë ˆì´ì•„ì›ƒ)"""
    st.markdown("<div class='section-title'>ğŸ•¯ï¸ ìº”ë“¤ìŠ¤í‹± íŒ¨í„´</div>", unsafe_allow_html=True)
    
    if not patterns:
        st.info("ìµœê·¼ ì£¼ìš” íŒ¨í„´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # íŒ¨í„´ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
    categories = {}
    for pattern in patterns:
        cat = pattern.get('category', 'ê¸°íƒ€')
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(pattern)
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    st.markdown(f"**ì´ {len(patterns)}ê°œ íŒ¨í„´ ê°ì§€** | ì¹´í…Œê³ ë¦¬: {', '.join([f'{k}({len(v)})' for k, v in categories.items()])}")
    
    for pattern in patterns:
        with st.container():
            date_str = pattern['date'].strftime('%Y-%m-%d %H:%M') if hasattr(pattern['date'], 'strftime') else str(pattern['date'])
            
            st.markdown(f"""
                <div class='pattern-card'>
                    <div class='pattern-title'>{pattern['name']} [{pattern.get('category', 'ê¸°íƒ€')}]</div>
                    <table style='width: 100%; color: white; border-collapse: collapse;'>
                        <tr>
                            <td style='width: 50%; padding: 8px 0;'>ğŸ“… ë°œìƒì¼: {date_str}</td>
                            <td style='width: 50%; padding: 8px 0;'>ğŸ“ ì„¤ëª…: {pattern['desc']}</td>
                        </tr>
                        <tr>
                            <td style='padding: 8px 0;'>ğŸ¯ ì‹ ë¢°ë„: {pattern['conf']}%</td>
                            <td style='padding: 8px 0;'>ğŸ’¡ ì˜í–¥: {pattern['impact']}</td>
                        </tr>
                    </table>
                </div>
            """, unsafe_allow_html=True)


def render_exit_strategy(exit_strategy: dict, entry_price: float, investment_amount: float, leverage: float):
    """ë§¤ë„ ì „ëµ (ì‹ ê·œ)"""
    st.markdown("<div class='section-title'>ğŸ’° ë§¤ë„ ì‹œì  ì˜ˆì¸¡</div>", unsafe_allow_html=True)
    
    current_status = exit_strategy['current_status']
    scenarios = exit_strategy['scenarios']
    
    # í˜„ì¬ ìƒíƒœ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ì§„ì…ê°€",
            value=f"${entry_price:,.2f}"
        )
    
    with col2:
        st.metric(
            label="í˜„ì¬ê°€",
            value=f"${current_status['current_price']:,.2f}",
            delta=f"{current_status['unrealized_pnl']:+.2f}%"
        )
    
    with col3:
        # RSI ìƒíƒœ í•œê¸€ ë²ˆì—­
        rsi_korean = {
            'overbought': 'ê³¼ë§¤ìˆ˜',
            'oversold': 'ê³¼ë§¤ë„',
            'neutral': 'ì¤‘ë¦½'
        }
        rsi_status_kr = rsi_korean.get(current_status['rsi_status'], current_status['rsi_status'])
        rsi_color = "ğŸ”´" if current_status['rsi_status'] == 'overbought' else "ğŸŸ¢" if current_status['rsi_status'] == 'oversold' else "âšª"
        st.metric(
            label="RSI ìƒíƒœ",
            value=f"{rsi_color} {rsi_status_kr}"
        )
    
    with col4:
        # ì¶”ì„¸ í•œê¸€ ë²ˆì—­
        trend_korean = {
            'bullish': 'ìƒìŠ¹',
            'bearish': 'í•˜ë½',
            'neutral': 'ì¤‘ë¦½'
        }
        trend_kr = trend_korean.get(current_status['trend'], current_status['trend'])
        trend_color = "ğŸ“ˆ" if current_status['trend'] == 'bullish' else "ğŸ“‰"
        st.metric(
            label="ì¶”ì„¸",
            value=f"{trend_color} {trend_kr}"
        )
    
    # ê¶Œì¥ì‚¬í•­
    if current_status['recommendation']:
        if 'ì¦‰ì‹œ' in current_status['recommendation']:
            st.error(current_status['recommendation'])
        elif 'ê³ ë ¤' in current_status['recommendation']:
            st.warning(current_status['recommendation'])
        else:
            st.info(current_status['recommendation'])
    
    st.markdown("---")
    
    # 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤
    st.markdown("### ğŸ¯ ë§¤ë„ ì‹œë‚˜ë¦¬ì˜¤")
    
    for scenario_key, scenario in scenarios.items():
        with st.container():
            profit_pct = ((scenario['take_profit'] - entry_price) / entry_price) * 100
            loss_pct = ((entry_price - scenario['stop_loss']) / entry_price) * 100
            
            profit_amount = investment_amount * leverage * (profit_pct / 100)
            loss_amount = investment_amount * leverage * (loss_pct / 100)
            
            # ì‹œê°„ ì˜ˆì¸¡ í¬ë§·íŒ…
            time_minutes = scenario.get('time_estimate_minutes', 0)
            if time_minutes >= 1440:  # 1ì¼ ì´ìƒ
                days = time_minutes // 1440
                hours = (time_minutes % 1440) // 60
                time_str = f"{days}ì¼" if hours == 0 else f"{days}ì¼ {hours}ì‹œê°„"
            elif time_minutes >= 60:  # 1ì‹œê°„ ì´ìƒ
                hours = time_minutes // 60
                minutes = time_minutes % 60
                time_str = f"{hours}ì‹œê°„" if minutes == 0 else f"{hours}ì‹œê°„ {minutes}ë¶„"
            else:  # 1ì‹œê°„ ë¯¸ë§Œ
                time_str = f"{time_minutes}ë¶„"
            
            st.markdown(f"""
                <div class='exit-card'>
                    <div class='exit-title'>{scenario['name']}</div>
                    <table style='width: 100%; color: white; border-collapse: collapse;'>
                        <tr>
                            <td style='width: 33%; padding: 8px 0;'>ğŸ¯ ìµì ˆê°€: ${scenario['take_profit']:,.2f} (+{profit_pct:.2f}%)</td>
                            <td style='width: 33%; padding: 8px 0;'>ğŸ›‘ ì†ì ˆê°€: ${scenario['stop_loss']:,.2f} (-{loss_pct:.2f}%)</td>
                            <td style='width: 34%; padding: 8px 0;'>â° ì˜ˆì¸¡ ì‹œê°„: <strong style='color: #ffd700;'>{time_str} í›„</strong></td>
                        </tr>
                        <tr>
                            <td style='padding: 8px 0;'>ğŸ’µ ëª©í‘œ ìˆ˜ìµ: ${profit_amount:,.2f}</td>
                            <td style='padding: 8px 0;'>ğŸ’¸ ìµœëŒ€ ì†ì‹¤: ${loss_amount:,.2f}</td>
                            <td style='padding: 8px 0;'>ğŸ“Š RR Ratio: {scenario['rr_ratio']:.2f}</td>
                        </tr>
                        <tr>
                            <td colspan='3' style='padding: 8px 0;'>ğŸ“ {scenario['description']}</td>
                        </tr>
                    </table>
                    <div style='margin-top: 12px; padding-top: 12px; border-top: 1px solid rgba(255,255,255,0.3);'>
                        <strong>ë§¤ë„ ì‹ í˜¸:</strong><br/>
                        {'<br/>'.join(['â€¢ ' + signal for signal in scenario['exit_signals']])}
                    </div>
                </div>
            """, unsafe_allow_html=True)


def render_validation_results(cv_results: pd.DataFrame):
    """ëª¨ë¸ ê²€ì¦"""
    st.markdown("<div class='section-title'>âœ… ëª¨ë¸ ê²€ì¦ (TimeSeriesSplit)</div>", unsafe_allow_html=True)
    
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.dataframe(
            cv_results,
            use_container_width=True,
            hide_index=True
        )
    
    with col2:
        st.markdown("### ğŸ“Š ê²€ì¦ ì§€í‘œ ì„¤ëª…")
        st.markdown("""
        - **Accuracy**: ë°©í–¥ì„± ì˜ˆì¸¡ ì •í™•ë„
        - **MASE**: ì˜ˆì¸¡ ì˜¤ì°¨ (1.0 ë¯¸ë§Œì´ ìš°ìˆ˜)
        - **Mean_Error**: í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
        - **Train/Test Size**: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°
        """)
        
        try:
            accuracies = []
            for acc in cv_results['Accuracy']:
                if isinstance(acc, str) and '%' in acc:
                    accuracies.append(float(acc.replace('%', '')))
            
            if accuracies:
                avg_accuracy = np.mean(accuracies)
                st.metric(
                    label="í‰ê·  ë°©í–¥ì„± ì •í™•ë„",
                    value=f"{avg_accuracy:.2f}%"
                )
        except:
            pass



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# [ì¶”ê°€ë¨] v2.3.1: ê°œë³„ ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def create_candlestick_chart(df: pd.DataFrame, symbol: str):
    """ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # ìº”ë“¤ìŠ¤í‹±
    fig.add_trace(
        go.Candlestick(
            x=df.index,
            open=df['Open'],
            high=df['High'],
            low=df['Low'],
            close=df['Close'],
            name='ê°€ê²©',
            increasing_line_color='#26a69a',
            decreasing_line_color='#ef5350'
        )
    )
    
    # EMA50
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['EMA50'],
            name='EMA50',
            line=dict(color='orange', width=2)
        )
    )
    
    # EMA200
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['EMA200'],
            name='EMA200',
            line=dict(color='purple', width=2)
        )
    )
    
    fig.update_layout(
        title=f'{symbol} ê°€ê²© ì°¨íŠ¸',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ê°€ê²© (USD)',
        template='plotly_white',
        height=600,
        hovermode='x unified',
        xaxis_rangeslider_visible=False
    )
    
    return fig


def create_volume_chart(df: pd.DataFrame):
    """ê±°ë˜ëŸ‰ ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # ê±°ë˜ëŸ‰ ë§‰ëŒ€ (ìƒìŠ¹/í•˜ë½ì— ë”°ë¼ ìƒ‰ìƒ êµ¬ë¶„)
    colors = ['#26a69a' if close >= open_ else '#ef5350' 
              for close, open_ in zip(df['Close'], df['Open'])]
    
    fig.add_trace(
        go.Bar(
            x=df.index,
            y=df['Volume'],
            name='ê±°ë˜ëŸ‰',
            marker_color=colors
        )
    )
    
    # ê±°ë˜ëŸ‰ ì´ë™í‰ê·  (20ì¼)
    volume_ma20 = df['Volume'].rolling(window=20).mean()
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=volume_ma20,
            name='ê±°ë˜ëŸ‰ MA20',
            line=dict(color='blue', width=2)
        )
    )
    
    fig.update_layout(
        title='ê±°ë˜ëŸ‰ ì°¨íŠ¸',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ê±°ë˜ëŸ‰',
        template='plotly_white',
        height=600,
        hovermode='x unified'
    )
    
    return fig


def create_rsi_chart(df: pd.DataFrame):
    """RSI ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # RSI ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['RSI14'],
            name='RSI (14)',
            line=dict(color='blue', width=2)
        )
    )
    
    # ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ë¼ì¸
    fig.add_hline(y=70, line_dash="dash", line_color="red", 
                  annotation_text="ê³¼ë§¤ìˆ˜ (70)")
    fig.add_hline(y=50, line_dash="dot", line_color="gray")
    fig.add_hline(y=30, line_dash="dash", line_color="green", 
                  annotation_text="ê³¼ë§¤ë„ (30)")
    
    # ë°°ê²½ ìƒ‰ìƒ ì˜ì—­
    fig.add_hrect(y0=70, y1=100, fillcolor="red", opacity=0.1, line_width=0)
    fig.add_hrect(y0=0, y1=30, fillcolor="green", opacity=0.1, line_width=0)
    
    fig.update_layout(
        title='RSI (Relative Strength Index)',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='RSI',
        template='plotly_white',
        height=600,
        hovermode='x unified',
        yaxis=dict(range=[0, 100])
    )
    
    return fig


def create_macd_chart(df: pd.DataFrame):
    """MACD ì°¨íŠ¸ ìƒì„±"""
    fig = go.Figure()
    
    # MACD ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['MACD'],
            name='MACD',
            line=dict(color='blue', width=2)
        )
    )
    
    # Signal ë¼ì¸
    fig.add_trace(
        go.Scatter(
            x=df.index,
            y=df['MACD_Signal'],
            name='Signal',
            line=dict(color='red', width=2)
        )
    )
    
    # Histogram
    colors = ['#26a69a' if val >= 0 else '#ef5350' for val in df['MACD_Hist']]
    fig.add_trace(
        go.Bar(
            x=df.index,
            y=df['MACD_Hist'],
            name='Histogram',
            marker_color=colors
        )
    )
    
    # 0ì„ 
    fig.add_hline(y=0, line_dash="dash", line_color="gray")
    
    fig.update_layout(
        title='MACD (Moving Average Convergence Divergence)',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='MACD',
        template='plotly_white',
        height=600,
        hovermode='x unified'
    )
    
    return fig


def render_trading_strategy(current_price: float, leverage_info: dict, entry_price: float,
                           stop_loss: float, take_profit: float, position_size: float,
                           rr_ratio: float, investment_amount: float):
    """ë§¤ë§¤ ì „ëµ (v2.3.0: ë ˆë²„ë¦¬ì§€ í‘œì‹œ ê°œì„ )"""
    st.markdown("<div class='section-title'>ğŸ¯ ë§¤ë§¤ ì „ëµ</div>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ“ ì§„ì… ì„¤ì •")
        # [ìˆ˜ì •ë¨] v2.3.0: ê¶Œì¥/ìµœëŒ€ ë ˆë²„ë¦¬ì§€ ë¶„ë¦¬ í‘œì‹œ
        st.markdown(f"""
        <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
            <p style='margin: 0; font-size: 14px; color: #666;'>âš™ï¸ ë ˆë²„ë¦¬ì§€ ìµœì í™”</p>
            <div style='display: flex; justify-content: space-between; margin-top: 5px;'>
                <div>
                    <p style='margin: 0; font-size: 12px; color: #888;'>ê¶Œì¥ ë ˆë²„ë¦¬ì§€</p>
                    <p style='margin: 0; font-size: 24px; font-weight: bold; color: #1f77b4;'>{leverage_info['recommended']}ë°°</p>
                </div>
                <div>
                    <p style='margin: 0; font-size: 12px; color: #888;'>ìµœëŒ€ ë ˆë²„ë¦¬ì§€</p>
                    <p style='margin: 0; font-size: 24px; font-weight: bold; color: #ff7f0e;'>{leverage_info['maximum']}ë°°</p>
                </div>
            </div>
            <p style='margin: 5px 0 0 0; font-size: 11px; color: #888; text-align: center;'>
                ë¦¬ìŠ¤í¬ ë ˆë²¨: <strong>{leverage_info['risk_level']}</strong>
            </p>
        </div>
        """, unsafe_allow_html=True)
        st.metric(label="ì§„ì…ê°€", value=f"${entry_price:,.2f}")
        st.metric(label="í¬ì§€ì…˜ í¬ê¸°", value=f"{position_size:.4f} ì½”ì¸")
    
    with col2:
        st.markdown("### ğŸ›‘ ë¦¬ìŠ¤í¬ ê´€ë¦¬")
        st.metric(label="ì†ì ˆê°€", value=f"${stop_loss:,.2f}")
        st.metric(label="ëª©í‘œê°€", value=f"${take_profit:,.2f}")
        st.metric(label="RR Ratio", value=f"{rr_ratio:.2f}")
    
    with col3:
        st.markdown("### ğŸ’° ì˜ˆìƒ ì†ìµ")
        expected_profit = position_size * (take_profit - entry_price)
        expected_loss = position_size * (entry_price - stop_loss)
        
        st.metric(
            label="ëª©í‘œ ìˆ˜ìµ",
            value=f"${expected_profit:,.2f}",
            delta=f"{(expected_profit / investment_amount) * 100:.2f}%"
        )
        st.metric(
            label="ìµœëŒ€ ì†ì‹¤",
            value=f"-${expected_loss:,.2f}",
            delta=f"-{(expected_loss / investment_amount) * 100:.2f}%"
        )
    
    # [ê°œì„ ë¨] v2.9.0.1: ì´ˆë³´ì ì¹œí™”ì  ì¦ê±°ê¸ˆ ì •ë³´ í‘œì‹œ
    st.markdown("---")
    st.markdown("### ğŸ’³ ê±°ë˜ ìê¸ˆ ì •ë³´")
    st.caption("ğŸ“Œ ë ˆë²„ë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ ì ì€ ìê¸ˆìœ¼ë¡œ í° ê±°ë˜ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    position_value = position_size * entry_price
    required_margin = position_value / leverage_info['recommended']
    margin_usage = (required_margin / investment_amount) * 100
    margin_saved = investment_amount - required_margin
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ“Š ì‹¤ì œ ê±°ë˜ ê¸ˆì•¡",
            value=f"${position_value:,.2f}",
            help="ë ˆë²„ë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ê±°ë˜í•˜ëŠ” ì´ ê¸ˆì•¡ì…ë‹ˆë‹¤"
        )
    
    with col2:
        st.metric(
            label="ğŸ’µ í•„ìš”í•œ ë‚´ ëˆ",
            value=f"${required_margin:,.2f}",
            delta=f"-{((margin_saved) / investment_amount * 100):.1f}% ì ˆì•½",
            help=f"ì‹¤ì œë¡œ ë‚´ê°€ ë‚´ì•¼ í•˜ëŠ” ëˆì…ë‹ˆë‹¤ ({leverage_info['recommended']}ë°° ë ˆë²„ë¦¬ì§€ ì‚¬ìš©)"
        )
    
    with col3:
        st.metric(
            label="ğŸ“ˆ ìê¸ˆ ì‚¬ìš©ë¥ ",
            value=f"{margin_usage:.1f}%",
            help="ë‚´ íˆ¬ìê¸ˆ ì¤‘ì—ì„œ ì´ë²ˆ ê±°ë˜ì— ì“°ëŠ” ë¹„ìœ¨ì…ë‹ˆë‹¤"
        )
    
    with col4:
        st.metric(
            label="ğŸ’° ë‚¨ì€ ìê¸ˆ",
            value=f"${margin_saved:,.2f}",
            delta=f"+{(margin_saved / investment_amount * 100):.1f}%",
            help="ë‹¤ë¥¸ ê±°ë˜ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‚¨ì€ ëˆì…ë‹ˆë‹¤"
        )
    
    # ì´ˆë³´ìë¥¼ ìœ„í•œ ì‰¬ìš´ ì„¤ëª… ì¶”ê°€
    with st.expander("ğŸ’¡ ë ˆë²„ë¦¬ì§€ë€? (ì´ˆë³´ì ê°€ì´ë“œ)"):
        st.markdown(f"""
        **ë ˆë²„ë¦¬ì§€ëŠ” 'ì§€ë ›ëŒ€'ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤. ì ì€ ëˆìœ¼ë¡œ í° ê±°ë˜ë¥¼ í•˜ëŠ” ë°©ë²•ì´ì—ìš”!**
        
        ğŸ¯ **í˜„ì¬ ì˜ˆì‹œ:**
        - ì‹¤ì œ ê±°ë˜ ê¸ˆì•¡: **${position_value:,.2f}**
        - ë‚´ê°€ ë‚´ì•¼ í•  ëˆ: **${required_margin:,.2f}**
        - ë ˆë²„ë¦¬ì§€: **{leverage_info['recommended']}ë°°**
        
        ğŸ’¡ **ì‰½ê²Œ ë§í•˜ë©´:**
        - ${required_margin:,.2f}ë§Œ ìˆìœ¼ë©´ ${position_value:,.2f}ì–´ì¹˜ ê±°ë˜ë¥¼ í•  ìˆ˜ ìˆì–´ìš”
        - ë‚˜ë¨¸ì§€ ${margin_saved:,.2f}ëŠ” ë‹¤ë¥¸ ì½”ì¸ì— íˆ¬ìí•  ìˆ˜ ìˆì–´ìš”
        
        âš ï¸ **ì£¼ì˜ì‚¬í•­:**
        - ìˆ˜ìµë„ {leverage_info['recommended']}ë°°ê°€ ë˜ì§€ë§Œ, **ì†ì‹¤ë„ {leverage_info['recommended']}ë°°**ê°€ ë©ë‹ˆë‹¤
        - ì†ì‹¤ì´ ì¦ê±°ê¸ˆì„ ë„˜ìœ¼ë©´ ìë™ìœ¼ë¡œ ì²­ì‚°(ê°•ì œ ì¢…ë£Œ)ë©ë‹ˆë‹¤
        - ì²˜ìŒì—ëŠ” ë‚®ì€ ë ˆë²„ë¦¬ì§€(1-3ë°°)ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤
        """)
    
    # [ì¶”ê°€ë¨] v2.7.2: ë¦¬ìŠ¤í¬ ê²€ì¦ ë©”ì‹œì§€
    st.markdown("---")
    actual_risk_pct = (expected_loss / investment_amount) * 100
    
    if actual_risk_pct > 5.0:
        st.error(f"ğŸš¨ ê²½ê³ : ì‹¤ì œ ë¦¬ìŠ¤í¬ê°€ {actual_risk_pct:.2f}%ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. í¬ì§€ì…˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    elif actual_risk_pct > 3.0:
        st.warning(f"âš ï¸ ì£¼ì˜: ì‹¤ì œ ë¦¬ìŠ¤í¬ê°€ {actual_risk_pct:.2f}%ë¡œ ë†’ìŠµë‹ˆë‹¤.")
    else:
        st.success(f"âœ… ë¦¬ìŠ¤í¬ ê´€ë¦¬: ì‹¤ì œ ë¦¬ìŠ¤í¬ê°€ {actual_risk_pct:.2f}%ë¡œ ì ì • ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
    
    if rr_ratio >= 3:
        st.success(f"âœ… ìš°ìˆ˜í•œ RR Ratio ({rr_ratio:.2f}) - ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ë†’ì€ ìˆ˜ìµ ê°€ëŠ¥")
    elif rr_ratio >= 2:
        st.info(f"ğŸ“Š ì ì •í•œ RR Ratio ({rr_ratio:.2f}) - ê· í˜•ì¡íŒ ì „ëµ")
    else:
        st.warning(f"âš ï¸ ë‚®ì€ RR Ratio ({rr_ratio:.2f}) - ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµì´ ì‘ìŒ")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.8.0: ê³ ê¸‰ ë¦¬ìŠ¤í¬ ê´€ë¦¬ UI í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def render_kelly_analysis(kelly_result: dict, current_position_size: float, 
                         entry_price: float, investment_amount: float):
    """ğŸ² Kelly Criterion ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("<div class='section-title'>ğŸ² Kelly Criterion ë¶„ì„</div>", unsafe_allow_html=True)
    
    # ê¸°ë³¸ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="Full Kelly",
            value=f"{kelly_result['kelly_full']:.2%}",
            help="ì´ë¡ ì  ìµœì  í¬ì§€ì…˜ í¬ê¸° (ë§¤ìš° ê³µê²©ì )"
        )
    
    with col2:
        st.metric(
            label="Half Kelly (ê¶Œì¥)",
            value=f"{kelly_result['kelly_adjusted']:.2%}",
            help="ì•ˆì •ì ì¸ ê¶Œì¥ í¬ê¸° (Full Kellyì˜ 50%)"
        )
    
    with col3:
        st.metric(
            label="ìµœì¢… ê¶Œì¥",
            value=f"{kelly_result['kelly_capped']:.2%}",
            help="ìµœëŒ€ì¹˜ ì œí•œ ì ìš© í›„"
        )
    
    with col4:
        category_emoji = {
            'ë§¤ìš° ë³´ìˆ˜ì ': 'ğŸ›¡ï¸',
            'ì¤‘ë¦½ì ': 'âš–ï¸',
            'ê³µê²©ì ': 'ğŸš€',
            'ë§¤ìš° ê³µê²©ì ': 'ğŸ”¥',
            'ê±°ë˜ ì œì™¸': 'â›”',
            'ê¸°ëŒ€ê°’ ìŒìˆ˜': 'âŒ',
            'ë¹„ì •ìƒ': 'âš ï¸'
        }
        emoji = category_emoji.get(kelly_result['risk_category'], 'ğŸ“Š')
        st.metric(
            label="ë¦¬ìŠ¤í¬ ì¹´í…Œê³ ë¦¬",
            value=f"{emoji} {kelly_result['risk_category']}"
        )
    
    # Kelly ê²°ê³¼ í•´ì„
    if kelly_result['recommendation'] == 'TRADE':
        kelly_position_value = investment_amount * kelly_result['kelly_capped']
        kelly_position_size = kelly_position_value / entry_price
        current_position_value = current_position_size * entry_price
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ Kelly vs í˜„ì¬ ì „ëµ ë¹„êµ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            <div style='background-color: #e8f5e9; padding: 15px; border-radius: 10px;'>
                <h4 style='color: #2e7d32; margin: 0 0 10px 0;'>ğŸ¯ Kelly Criterion ê¶Œì¥</h4>
                <p style='margin: 5px 0;'><strong>í¬ì§€ì…˜ í¬ê¸°:</strong> {kelly_position_size:.6f} ì½”ì¸</p>
                <p style='margin: 5px 0;'><strong>í¬ì§€ì…˜ ê°€ì¹˜:</strong> ${kelly_position_value:,.2f}</p>
                <p style='margin: 5px 0;'><strong>ë¦¬ìŠ¤í¬ ë¹„ìœ¨:</strong> {kelly_result['position_pct']:.2f}%</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div style='background-color: #e3f2fd; padding: 15px; border-radius: 10px;'>
                <h4 style='color: #1565c0; margin: 0 0 10px 0;'>ğŸ“Š í˜„ì¬ ì „ëµ (Fixed 2%)</h4>
                <p style='margin: 5px 0;'><strong>í¬ì§€ì…˜ í¬ê¸°:</strong> {current_position_size:.6f} ì½”ì¸</p>
                <p style='margin: 5px 0;'><strong>í¬ì§€ì…˜ ê°€ì¹˜:</strong> ${current_position_value:,.2f}</p>
                <p style='margin: 5px 0;'><strong>ë¦¬ìŠ¤í¬ ë¹„ìœ¨:</strong> 2.00%</p>
            </div>
            """, unsafe_allow_html=True)
        
        # ì°¨ì´ ë¶„ì„ (0 ë‚˜ëˆ„ê¸° ë³´í˜¸)
        if current_position_size > 0:
            diff_pct = ((kelly_position_size - current_position_size) / current_position_size) * 100
            if abs(diff_pct) > 10:
                if diff_pct > 0:
                    st.info(f"ğŸ“ˆ Kelly Criterionì€ í˜„ì¬ë³´ë‹¤ **{diff_pct:.1f}% ë” í°** í¬ì§€ì…˜ì„ ê¶Œì¥í•©ë‹ˆë‹¤. (AI ì‹ ë¢°ë„ê°€ ë†’ê³  RR Ratioê°€ ì¢‹ìŒ)")
                else:
                    st.warning(f"ğŸ“‰ Kelly Criterionì€ í˜„ì¬ë³´ë‹¤ **{abs(diff_pct):.1f}% ë” ì‘ì€** í¬ì§€ì…˜ì„ ê¶Œì¥í•©ë‹ˆë‹¤. (AI ì‹ ë¢°ë„ê°€ ë‚®ê±°ë‚˜ RR Ratioê°€ ë‚œì¡°í•¨)")
            else:
                st.success("âœ… Kelly Criterionê³¼ í˜„ì¬ ì „ëµì´ ìœ ì‚¬í•©ë‹ˆë‹¤. (Â±10% ì´ë‚´)")
        else:
            st.warning("âš ï¸ í˜„ì¬ í¬ì§€ì…˜ í¬ê¸°ê°€ 0ì´ì–´ì„œ ë¹„êµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    else:
        st.error(f"âŒ {kelly_result['reason']}")
        st.warning("âš ï¸ Kelly Criterionì— ë”°ë¥´ë©´ ì´ ê±°ë˜ë¥¼ ê±´ë„ˆë›„ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.")
    
    # ìƒì„¸ ì •ë³´
    with st.expander("ğŸ“– Kelly Criterion ìƒì„¸ ì •ë³´"):
        # ì•ˆì „í•˜ê²Œ í‚¤ ì ‘ê·¼
        win_rate_used = kelly_result.get('win_rate_used', 0.5)
        rr_ratio_used = kelly_result.get('rr_ratio_used', 1.0)
        kelly_fraction_used = kelly_result.get('kelly_fraction_used', 0.5)
        
        st.markdown(f"""
        **ì…ë ¥ íŒŒë¼ë¯¸í„°:**
        - ìŠ¹ë¥  (Win Rate): {win_rate_used:.1%}
        - RR Ratio: {rr_ratio_used:.2f}
        - Kelly Fraction: {kelly_fraction_used:.0%} (Half Kelly)
        
        **ê³µì‹:**
        ```
        Kelly = (b*p - q) / b
        
        ì—¬ê¸°ì„œ:
        - b = RR Ratio (ìŠ¹ë¥ )
        - p = ìŠ¹ë¦¬ í™•ë¥  (AI ì‹ ë¢°ë„)
        - q = íŒ¨ë°° í™•ë¥  (1 - p)
        ```
        
        **í•´ì„:**
        - Full KellyëŠ” ì´ë¡ ì  ìµœì ê°’ì´ì§€ë§Œ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤.
        - Half Kelly (50%)ëŠ” ì•ˆì •ì ì´ë©´ì„œë„ ì¢‹ì€ ì„±ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤. (ê¶Œì¥)
        - Quarter Kelly (25%)ëŠ” ë³´ìˆ˜ì  ì ‘ê·¼ì…ë‹ˆë‹¤.
        """)


# [v2.9.0] Monte Carlo UI rendering removed

def render_strategy_comparison(comparison: dict, investment_amount: float):
    """ğŸ† Position Sizing ì „ëµ ë¹„êµ"""
    st.markdown("<div class='section-title'>ğŸ† Position Sizing ì „ëµ ë¹„êµ</div>", unsafe_allow_html=True)
    
    strategies = comparison['strategies']
    recommended = comparison['recommended_strategy']
    
    # ë¹„êµ í‘œ
    st.markdown("### ğŸ“Š 4ê°€ì§€ ì „ëµ ë¹„êµ")
    
    data = []
    for key, strategy in strategies.items():
        is_recommended = (key == recommended)
        emoji = "â­" if is_recommended else ""
        
        data.append({
            'ì „ëµ': f"{emoji} {strategy['name']}",
            'ë¦¬ìŠ¤í¬ ë¹„ìœ¨': f"{strategy['risk_pct']:.2f}%",
            'í¬ì§€ì…˜ í¬ê¸°': f"{strategy['position_size']:.6f}",
            'í¬ì§€ì…˜ ê°€ì¹˜': f"${strategy['position_value']:,.0f}",
            'ìµœëŒ€ ì†ì‹¤': f"${strategy['max_loss']:,.0f}",
            'ìµœëŒ€ ìˆ˜ìµ': f"${strategy['max_profit']:,.0f}",
            'í•„ìš” ì¦ê±°ê¸ˆ': f"${strategy['required_margin']:,.0f}"
        })
    
    import pandas as pd
    df_comparison = pd.DataFrame(data)
    st.dataframe(df_comparison, use_container_width=True, hide_index=True)
    
    # ê¶Œì¥ ì „ëµ
    st.markdown("---")
    recommended_strategy = strategies[recommended]
    
    st.success(f"""
    â­ **ê¶Œì¥ ì „ëµ: {recommended_strategy['name']}**
    
    - í¬ì§€ì…˜ í¬ê¸°: **{recommended_strategy['position_size']:.6f} ì½”ì¸**
    - ë¦¬ìŠ¤í¬ ë¹„ìœ¨: **{recommended_strategy['risk_pct']:.2f}%**
    - ì˜ˆìƒ ì†ì‹¤: **${recommended_strategy['max_loss']:,.2f}**
    - ì˜ˆìƒ ìˆ˜ìµ: **${recommended_strategy['max_profit']:,.2f}**
    """)
    
    # ì „ëµë³„ íŠ¹ì§•
    with st.expander("ğŸ“š ì „ëµë³„ íŠ¹ì§•"):
        st.markdown("""
        **1ï¸âƒ£ ê³ ì • ë¹„ìœ¨ (Fixed Fractional 2%)**
        - ê°€ì¥ ë‹¨ìˆœí•˜ê³  ì•ˆì •ì 
        - ëª¨ë“  ê±°ë˜ì— ë™ì¼í•œ ë¦¬ìŠ¤í¬ ì ìš©
        - ì´ˆë³´ìì—ê²Œ ì¶”ì²œ
        
        **2ï¸âƒ£ Kelly Criterion (Half Kelly)**
        - ìˆ˜í•™ì  ìµœì í™” ê¸°ë°˜
        - AI ì‹ ë¢°ë„ì™€ RR Ratioë¥¼ ê³ ë ¤
        - ìŠ¹ë¥ ì´ ë†’ì„ ë•Œ í¬ì§€ì…˜ í™•ëŒ€
        - ì¤‘ê¸‰ì ì´ìƒ ì¶”ì²œ
        
        **3ï¸âƒ£ ë³€ë™ì„± ì¡°ì • (Volatility Adjusted)**
        - ì‹œì¥ ë³€ë™ì„±ì— ë”°ë¼ ìë™ ì¡°ì •
        - ë³€ë™ì„± ë†’ì„ ë•Œ í¬ì§€ì…˜ ì¶•ì†Œ
        - ë¦¬ìŠ¤í¬ íšŒí”¼í˜• íŠ¸ë ˆì´ë”ì—ê²Œ ì í•©
        
        **4ï¸âƒ£ AI ì‹ ë¢°ë„ ê¸°ë°˜**
        - AI ì˜ˆì¸¡ ì‹ ë¢°ë„ë¥¼ ì§ì ‘ ë°˜ì˜
        - ì‹ ë¢°ë„ ë†’ì„ ë•Œ ê³µê²©ì 
        - AI ëª¨ë¸ ì„±ëŠ¥ì„ ì‹ ë¢°í•˜ëŠ” ê²½ìš°
        """)


def render_portfolio_backtest(price_data_df, symbol_name):
    """
    í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ ë Œë”ë§ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©)
    """
    result = backtest_portfolio_simple(price_data_df, symbol_name)
    
    if result is None:
        st.warning("âš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return
    
    # ì„±ê³¼ ì§€í‘œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        return_color = "normal" if result['total_return'] >= 0 else "inverse"
        st.metric(
            label="ğŸ“ˆ ì´ ìˆ˜ìµë¥ ",
            value=f"{result['total_return']:.2f}%",
            delta=f"{result['total_return']:.2f}%",
            delta_color=return_color
        )
    
    with col2:
        st.metric(
            label="ğŸ“Š Sharpe Ratio",
            value=f"{result['sharpe_ratio']:.3f}",
            help="ë¦¬ìŠ¤í¬ ì¡°ì • ìˆ˜ìµë¥  (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)"
        )
    
    with col3:
        st.metric(
            label="ğŸ“‰ ìµœëŒ€ ë‚™í­",
            value=f"{result['max_drawdown']:.2f}%",
            delta=f"{result['max_drawdown']:.2f}%",
            delta_color="inverse"
        )
    
    with col4:
        st.metric(
            label="ğŸ¯ ìŠ¹ë¥ ",
            value=f"{result['win_rate']:.1f}%",
            help="ì–‘ì˜ ìˆ˜ìµë¥ ì„ ê¸°ë¡í•œ ë‚ ì˜ ë¹„ìœ¨"
        )
    
    # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì¶”ì´ ë° ì½”ì¸ë³„ ì„±ê³¼ ì„¹ì…˜ ì‚­ì œë¨


def render_technical_indicators(df: pd.DataFrame):
    """ê¸°ìˆ ì  ì§€í‘œ"""
    st.markdown("<div class='section-title'>ğŸ“Š ê¸°ìˆ ì  ì§€í‘œ</div>", unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        rsi = df['RSI14'].iloc[-1]
        rsi_signal = "ê³¼ë§¤ìˆ˜" if rsi > 70 else "ê³¼ë§¤ë„" if rsi < 30 else "ì¤‘ë¦½"
        st.metric(label="RSI (14)", value=f"{rsi:.2f}", delta=rsi_signal)
    
    with col2:
        stoch = df['StochK14'].iloc[-1]
        stoch_signal = "ê³¼ë§¤ìˆ˜" if stoch > 80 else "ê³¼ë§¤ë„" if stoch < 20 else "ì¤‘ë¦½"
        st.metric(label="Stochastic (14)", value=f"{stoch:.2f}", delta=stoch_signal)
    
    with col3:
        mfi = df['MFI14'].iloc[-1]
        mfi_signal = "ê³¼ë§¤ìˆ˜" if mfi > 80 else "ê³¼ë§¤ë„" if mfi < 20 else "ì¤‘ë¦½"
        st.metric(label="MFI (14)", value=f"{mfi:.2f}", delta=mfi_signal)
    
    with col4:
        macd_hist = df['MACD_Hist'].iloc[-1]
        macd_signal = "ìƒìŠ¹" if macd_hist > 0 else "í•˜ë½"
        st.metric(label="MACD Histogram", value=f"{macd_hist:.2f}", delta=macd_signal)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("# ğŸš€ ì„¤ì •")
    
    # ìºì‹œ ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("ğŸ”„", help="ë°ì´í„° ìºì‹œ ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            st.success("âœ… ìºì‹œ í´ë¦¬ì–´!")
            st.rerun()
    with col1:
        st.caption("ğŸ“ˆ ë°ì´í„° ìºì‹± í™œì„±")
    
    st.markdown("---")
    
    # v2.6.0: Fear & Greed Index
    st.markdown("### ğŸ˜± ì‹œì¥ ì‹¬ë¦¬")
    try:
        fg_data = get_fear_greed_index()
        if fg_data:
            current_value = fg_data['current_value']
            classification = fg_data['current_classification']
            
            # í•œê¸€ ë²ˆì—­ ë§µ
            korean_map = {
                'Extreme Fear': 'ê·¹ë„ì˜ ê³µí¬',
                'Fear': 'ê³µí¬',
                'Neutral': 'ì¤‘ë¦½',
                'Greed': 'íƒìš•',
                'Extreme Greed': 'ê·¹ë„ì˜ íƒìš•'
            }
            korean_classification = korean_map.get(classification, classification)
            
            color_map = {
                'Extreme Fear': '#e74c3c',
                'Fear': '#e67e22',
                'Neutral': '#f39c12',
                'Greed': '#2ecc71',
                'Extreme Greed': '#27ae60'
            }
            color = color_map.get(classification, 'gray')
            
            st.markdown(f"""
            <div style='background: linear-gradient(135deg, {color}aa, {color}); 
                        padding:20px; border-radius:15px; text-align:center; 
                        box-shadow: 0 4px 6px rgba(0,0,0,0.1); margin-bottom:20px;'>
                <h1 style='margin:0; color:white; font-size:48px;'>{current_value}</h1>
                <p style='margin:5px 0 0 0; color:white; font-size:18px; font-weight:bold;'>{korean_classification}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if current_value < 25:
                st.success("ğŸŸ¢ ê·¹ë„ì˜ ê³µí¬ â†’ ë§¤ìˆ˜ ê¸°íšŒ")
            elif current_value > 75:
                st.warning("ğŸ”´ ê·¹ë„ì˜ íƒìš• â†’ ë§¤ë„ ê³ ë ¤")
        else:
            st.info("â„¹ï¸ Fear & Greed ë°ì´í„° ë¡œë”© ì¤‘...")
    except Exception as e:
        pass
    
    st.markdown("---")
    
    # TA-Lib ìƒíƒœ í‘œì‹œ
    if TALIB_AVAILABLE:
        st.success("âœ… TA-Lib ì‚¬ìš© ê°€ëŠ¥ (61ê°œ íŒ¨í„´)")
    else:
        st.warning("âš ï¸ TA-Lib ë¯¸ì„¤ì¹˜ (ê¸°ë³¸ 3ê°œ íŒ¨í„´)")
    
    st.markdown("## 1ï¸âƒ£ ì‹œê°„ ì„ íƒ")
    resolution_choice = st.selectbox(
        "ğŸ“ˆ ì‹œê°„ í”„ë ˆì„",
        list(RESOLUTION_MAP.keys()),
        index=3,
        help="ì§§ì€ ê¸°ê°„ì¼ìˆ˜ë¡ ìµœì‹  ë°ì´í„°ë§Œ ì œê³µë©ë‹ˆë‹¤"
    )
    interval = RESOLUTION_MAP[resolution_choice]
    interval_name = resolution_choice
    
    interval_info = {
        '1m': 'â±ï¸ 1ë¶„ë´‰: ìµœê·¼ **7ì¼**ë§Œ ì§€ì› (ì´ˆë‹¨íƒ€ ë§¤ë§¤ìš©)',
        '5m': 'â±ï¸ 5ë¶„ë´‰: ìµœê·¼ **60ì¼**ë§Œ ì§€ì› (ë‹¨íƒ€ ë§¤ë§¤ìš©)',
        '1h': 'â±ï¸ 1ì‹œê°„ë´‰: ìµœê·¼ **2ë…„**ë§Œ ì§€ì› (ìŠ¤ìœ™ íŠ¸ë ˆì´ë”©ìš©)',
        '1d': 'â±ï¸ 1ì¼ë´‰: **ì „ì²´ ê¸°ê°„** ì§€ì› (ì¤‘ì¥ê¸° íˆ¬ììš©)'
    }
    
    st.info(interval_info.get(interval, ''))
    
    st.markdown("---")
    st.markdown("## 2ï¸âƒ£ ì½”ì¸ ì„ íƒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì½”ì¸ ì„ íƒ ìœ ì§€ìš©)
    if 'selected_crypto' not in st.session_state:
        st.session_state.selected_crypto = "BTCUSDT"
    if 'coin_input_method' not in st.session_state:
        st.session_state.coin_input_method = "ê¸°ë³¸ ëª©ë¡"
    
    coin_input_method = st.radio(
        "ğŸ”§ ì…ë ¥ ë°©ì‹",
        ["ê¸°ë³¸ ëª©ë¡", "ì „ì²´ ì½”ì¸ ê²€ìƒ‰ (ë°”ì´ë‚¸ìŠ¤)", "ì§ì ‘ ì…ë ¥"],
        horizontal=True,
        key='coin_input_method'
    )
    
    if coin_input_method == "ê¸°ë³¸ ëª©ë¡":
        # í˜„ì¬ ì„ íƒëœ ì½”ì¸ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°
        crypto_list = list(CRYPTO_MAP.keys())
        try:
            current_index = 0
            for idx, (name, symbol) in enumerate(CRYPTO_MAP.items()):
                if symbol == st.session_state.selected_crypto:
                    current_index = idx
                    break
        except:
            current_index = 0
        
        crypto_choice = st.selectbox(
            "ğŸ’ ì•”í˜¸í™”í",
            crypto_list,
            index=current_index
        )
        st.session_state.selected_crypto = CRYPTO_MAP[crypto_choice]
    
    elif coin_input_method == "ì „ì²´ ì½”ì¸ ê²€ìƒ‰ (ë°”ì´ë‚¸ìŠ¤)":
        with st.spinner("ğŸ” ë°”ì´ë‚¸ìŠ¤ì—ì„œ ì½”ì¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            all_pairs = get_all_binance_usdt_pairs()
        
        search_query = st.text_input(
            "ğŸ” ì½”ì¸ ê²€ìƒ‰",
            value="",
            placeholder="ì½”ì¸ ì´ë¦„ ë˜ëŠ” ì‹¬ë³¼ ì…ë ¥ (ì˜ˆ: BTC, ë¹„íŠ¸ì½”ì¸, SOL)"
        )
        
        if search_query:
            search_upper = search_query.upper()
            filtered_pairs = [
                pair for pair in all_pairs 
                if search_upper in pair[0].upper() or search_upper in pair[1].upper()
            ]
        else:
            filtered_pairs = all_pairs
        
        if filtered_pairs:
            st.caption(f"ğŸ“Š ì´ {len(filtered_pairs)}ê°œ ì½”ì¸ í‘œì‹œ ì¤‘ (Binance USDT í˜ì–´)")
            
            # í˜„ì¬ ì„ íƒëœ ì½”ì¸ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            display_names = [pair[0] for pair in filtered_pairs]
            current_index = 0
            for idx, pair in enumerate(filtered_pairs):
                if pair[1] == st.session_state.selected_crypto:
                    current_index = idx
                    break
            
            selected_display = st.selectbox(
                "ğŸ’ ì½”ì¸ ì„ íƒ",
                display_names,
                index=current_index,
                key="binance_coin_select"
            )
            
            for pair in filtered_pairs:
                if pair[0] == selected_display:
                    st.session_state.selected_crypto = pair[1]
                    break
            
            st.success(f"âœ… ì„ íƒë¨: **{st.session_state.selected_crypto}**")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            st.session_state.selected_crypto = "BTCUSDT"
    
    else:  # "ì§ì ‘ ì…ë ¥"
        st.info("ğŸ’¡ íŒ: ì‹¬ë³¼(ì˜ˆ: BTC, ETHUSDT) ë˜ëŠ” ì½”ì¸ëª…(ì˜ˆ: ë¹„íŠ¸ì½”ì¸, ì´ë”ë¦¬ì›„) ì…ë ¥ ê°€ëŠ¥")
        
        # ë°”ì´ë‚¸ìŠ¤ ì „ì²´ ì½”ì¸ ëª©ë¡ ë¡œë“œ (ìºì‹±ë¨)
        with st.spinner("ğŸ” ì½”ì¸ ëª©ë¡ ë¡œë”© ì¤‘..."):
            all_pairs = get_all_binance_usdt_pairs()
        
        # í†µí•© ê²€ìƒ‰ ì…ë ¥ì°½
        search_input = st.text_input(
            "ğŸ’ ì½”ì¸ ê²€ìƒ‰ ë˜ëŠ” ì‹¬ë³¼ ì…ë ¥",
            key='unified_search_input',
            placeholder="ì˜ˆ: BTC, ë¹„íŠ¸ì½”ì¸, ETHUSDT, ì´ë”ë¦¬ì›„",
            help="ì‹¬ë³¼ ë˜ëŠ” ì½”ì¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"
        ).upper().strip()
        
        if search_input:
            # ì •í™•í•œ USDT í˜ì–´ ì‹¬ë³¼ì¸ì§€ í™•ì¸
            exact_match = None
            if search_input.endswith("USDT"):
                for pair in all_pairs:
                    if pair[1] == search_input:
                        exact_match = pair
                        break
            
            # ì •í™•í•œ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ì„ íƒ
            if exact_match:
                st.session_state.selected_crypto = exact_match[1]
                st.success(f"âœ… ì„ íƒë¨: **{exact_match[0]}** ({exact_match[1]})")
            
            else:
                # USDT ì—†ì´ ì…ë ¥í•œ ê²½ìš° ìë™ ì¶”ê°€ ì‹œë„
                search_upper = search_input
                if not search_input.endswith("USDT"):
                    potential_symbol = search_input + "USDT"
                    for pair in all_pairs:
                        if pair[1] == potential_symbol:
                            exact_match = pair
                            break
                
                if exact_match:
                    st.session_state.selected_crypto = exact_match[1]
                    st.success(f"âœ… ìë™ ë§¤ì¹­: **{exact_match[0]}** ({exact_match[1]})")
                
                else:
                    # ê²€ìƒ‰ ê²°ê³¼
                    filtered_pairs = [
                        pair for pair in all_pairs 
                        if search_upper in pair[0].upper() or search_upper in pair[1].upper()
                    ]
                    
                    if filtered_pairs:
                        st.caption(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(filtered_pairs)}ê°œ ì½”ì¸")
                        
                        # í˜„ì¬ ì„ íƒ ìœ ì§€
                        display_names = [pair[0] for pair in filtered_pairs]
                        current_index = 0
                        for idx, pair in enumerate(filtered_pairs):
                            if pair[1] == st.session_state.selected_crypto:
                                current_index = idx
                                break
                        
                        selected_display = st.selectbox(
                            "ğŸ’ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì„ íƒ",
                            display_names,
                            index=current_index,
                            key="unified_search_select"
                        )
                        
                        for pair in filtered_pairs:
                            if pair[0] == selected_display:
                                st.session_state.selected_crypto = pair[1]
                                break
                        
                        st.success(f"âœ… ì„ íƒë¨: **{st.session_state.selected_crypto}**")
                    
                    else:
                        st.warning(f"âš ï¸ '{search_input}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        else:
            # ì…ë ¥ ì—†ì„ ë•Œ í˜„ì¬ ì„ íƒ í‘œì‹œ
            st.info(f"í˜„ì¬ ì„ íƒ: **{st.session_state.selected_crypto}**")
    
    # ì´í›„ ì½”ë“œì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜
    selected_crypto = st.session_state.selected_crypto
    
    st.markdown("---")
    st.markdown("## 3ï¸âƒ£ ë¶„ì„ ê¸°ê°„")
    
    period_choice = st.radio(
        "ğŸ“… ê¸°ê°„ ì„¤ì •",
        ["ìë™", "ìˆ˜ë™ ì„¤ì •"],
        help="ìë™ ëª¨ë“œëŠ” ë¶„í•´ëŠ¥ë³„ ì œí•œì„ ìë™ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤"
    )
    
    if period_choice == "ìë™":
        today = datetime.date.today()
        
        interval_periods = {
            '1m': 7,
            '5m': 60,
            '1h': 730,
            '1d': 365 * 5
        }
        
        days_back = interval_periods.get(interval, 180)
        START = today - datetime.timedelta(days=days_back)
        
        listing_dates = {
            "BTCUSDT": datetime.date(2017, 8, 17),
            "ETHUSDT": datetime.date(2017, 8, 17),
            "XRPUSDT": datetime.date(2018, 5, 14),
            "DOGEUSDT": datetime.date(2021, 5, 6),
            "ADAUSDT": datetime.date(2018, 4, 17),
            "SOLUSDT": datetime.date(2021, 8, 11)
        }
        
        listing_date = listing_dates.get(selected_crypto, START)
        
        if START < listing_date:
            START = listing_date
        
        END = today
        st.info(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {START} ~ {END} ({(END - START).days}ì¼)")
    else:
        col_s, col_e = st.columns(2)
        with col_s:
            START = st.date_input(
                "ì‹œì‘ì¼",
                value=datetime.date.today() - datetime.timedelta(days=180)
            )
        with col_e:
            END = st.date_input(
                "ì¢…ë£Œì¼",
                value=datetime.date.today()
            )
        
        if START >= END:
            st.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()
    
    st.markdown("---")
    st.markdown("## 4ï¸âƒ£ íˆ¬ì ì„¤ì •")
    
    
    # ì˜ˆì¸¡ ì¼ìˆ˜ ì„¤ì •
    forecast_days = st.slider(
        "ğŸ”® ì˜ˆì¸¡ ê¸°ê°„",
        min_value=1,
        max_value=30,
        value=3,
        step=1,
        help="ëª‡ ì¼ í›„ì˜ ê°€ê²©ì„ ì˜ˆì¸¡í• ì§€ ì„ íƒí•˜ì„¸ìš”"
    )
    st.session_state['forecast_days'] = forecast_days

    # ì„¸ì…˜ ìƒíƒœì— íˆ¬ì ê¸ˆì•¡ ì €ì¥
    if 'investment_amount' not in st.session_state:
        st.session_state.investment_amount = 1000.0
    
    investment_amount = st.number_input(
        "ğŸ’° íˆ¬ì ê¸ˆì•¡ (USDT)",
        min_value=1.0,
        value=st.session_state.investment_amount,
        step=50.0,
        key='investment_amount_input'
    )
    
    # ê°’ì´ ë³€ê²½ë˜ë©´ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
    st.session_state.investment_amount = investment_amount
    
    risk_per_trade_pct = st.slider(
        "âš ï¸ ë¦¬ìŠ¤í¬ ë¹„ìœ¨ (%)",
        min_value=0.5,
        max_value=5.0,
        value=2.0,
        step=0.5,
        help="í•œ ê±°ë˜ë‹¹ ìµœëŒ€ ì†ì‹¤ í—ˆìš© í¼ì„¼íŠ¸"
    ) / 100.0
    
    stop_loss_k = st.number_input(
        "ğŸ›‘ ì†ì ˆ ë°°ìˆ˜ (Ïƒ ê¸°ì¤€)",
        min_value=1.0,
        max_value=3.0,
        value=2.0,
        step=0.5
    )
    
    default_max_lev = MAX_LEVERAGE_MAP.get(selected_crypto, 50)
    leverage_ceiling = st.number_input(
        "ğŸ“Š ìµœëŒ€ ë ˆë²„ë¦¬ì§€",
        min_value=1,
        max_value=500,
        value=int(default_max_lev),
        step=1
    )
    
    st.markdown("---")
    bt = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

# ë©”ì¸ ë¡œì§
if bt:
    try:
        progress_placeholder = st.empty()
        status_text = st.empty()
        
        progress_placeholder.markdown(render_progress_bar(1, 6), unsafe_allow_html=True)
        status_text.info(f"ğŸ” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘... (ë¶„í•´ëŠ¥: {interval_name})")
        
        raw_df = load_crypto_data(selected_crypto, START, END, interval)
        
        if raw_df.empty:
            yf_ticker = selected_crypto[:-4] + "-USD"
            st.error(f"âŒ {yf_ticker} ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.warning(f"""
            **ê°€ëŠ¥í•œ ì›ì¸**:
            - ì„ íƒí•œ ê¸°ê°„({START} ~ {END})ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤
            - ë¶„í•´ëŠ¥({interval_name})ì´ í•´ë‹¹ ê¸°ê°„ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
            - yfinance API ì¼ì‹œì  ì˜¤ë¥˜
            
            **í•´ê²° ë°©ë²•**:
            1. ë” ìµœê·¼ ê¸°ê°„ ì„ íƒ
            2. ë¶„í•´ëŠ¥ì„ 1ì¼ë´‰ìœ¼ë¡œ ë³€ê²½
            3. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
            4. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
            """)
            
            if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™” í›„ ì¬ì‹œë„"):
                st.cache_data.clear()
                st.rerun()
            st.stop()
        
        min_required = 20
        if len(raw_df) < min_required:
            st.error(f"âŒ ìµœì†Œ {min_required} ê¸°ê°„ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. (í˜„ì¬: {len(raw_df)})")
            st.warning("""
            **í•´ê²° ë°©ë²•**:
            1. ë” ê¸´ ê¸°ê°„ ì„ íƒ
            2. ë‹¤ë¥¸ ë¶„í•´ëŠ¥ ì„ íƒ (1ì¼ë´‰ ê¶Œì¥)
            3. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
            """)
            st.stop()
        
        progress_placeholder.markdown(render_progress_bar(2, 6), unsafe_allow_html=True)
        status_text.info("ğŸ“Š ì ì‘í˜• ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” ì¤‘...")
        
        df = calculate_indicators_wilders(raw_df)
        
        if df.empty:
            st.error("âŒ ì§€í‘œ ê³„ì‚° í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.warning(f"""
            **ë¬¸ì œ ë¶„ì„**:
            - ì›ë³¸ ë°ì´í„°: {len(raw_df)}ê°œ
            - ì§€í‘œ ê³„ì‚° í›„: {len(df)}ê°œ (ëª¨ë‘ NaN ì œê±°ë¨)
            
            **í•´ê²° ë°©ë²•**:
            1. ë” ê¸´ ê¸°ê°„ ì„ íƒ (ìµœì†Œ 50ê°œ ì´ìƒ ê¶Œì¥)
            2. 1ì¼ë´‰ ì„ íƒ (ë” ë§ì€ ë°ì´í„° í™•ë³´)
            """)
            st.stop()
        
        if len(df) < 10:
            st.warning(f"""
            âš ï¸ ìœ íš¨í•œ ë°ì´í„°ê°€ ë§¤ìš° ì ìŠµë‹ˆë‹¤ ({len(df)}ê°œ).
            
            ë¶„ì„ì€ ì§„í–‰ë˜ì§€ë§Œ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            ë” ê¸´ ê¸°ê°„ì„ ì„ íƒí•˜ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
            """)
        
        progress_placeholder.markdown(render_progress_bar(3, 6), unsafe_allow_html=True)
        status_text.info("ğŸ¤– ì•™ìƒë¸” ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ì¤‘...")
        
        close_series = df['Close']
        
        if len(close_series) < 10:
            st.error("âŒ ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            st.stop()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # v2.5.0: ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ (ì‹œê°„ í”„ë ˆì„ ê¸°ë°˜ ìë™ ì„ íƒ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            ensemble_models, ensemble_config = train_ensemble_models(
                data=close_series,
                features_df=df,
                interval=interval,
                forecast_days=forecast_days
            )
            
            if not ensemble_models:
                st.error("âŒ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()
            
            st.success(f"âœ… ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {ensemble_config['description']}")
            
        except Exception as e:
            st.error(f"âŒ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            st.text(traceback.format_exc())
            st.stop()
        
        close_series = df['Close']
        
        if len(close_series) < 10:
            st.error("âŒ ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            st.stop()
        
        # [ê°œì„ ë¨] v2.4.0: ê°•ê±´í•œ ëª¨ë¸ í•™ìŠµ ë° ìë™ ê³„ì ˆì„± ê°ì§€
        try:
            hw_model, seasonality_info, window_size = fit_hw_model_robust(
                close_series, 
                max_window=500  # ìµœì‹  500ê°œ ë°ì´í„°ë§Œ ì‚¬ìš© (ì„±ëŠ¥ ê°œì„ )
            )
            
            # ê³„ì ˆì„± ì •ë³´ í‘œì‹œ
            if seasonality_info['detected']:
                st.info(f"âœ… ê³„ì ˆì„± ê°ì§€: ì£¼ê¸° {seasonality_info['period']}, "
                       f"íƒ€ì… {seasonality_info['type']}, "
                       f"í•™ìŠµ ë°ì´í„°: {window_size}ê°œ")
            else:
                st.info(f"â„¹ï¸ ë¹„ê³„ì ˆ ëª¨ë¸ ì‚¬ìš© (í•™ìŠµ ë°ì´í„°: {window_size}ê°œ)")
        
        except Exception as e:
            st.error(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {str(e)}")
            st.warning("""
            **í•´ê²° ë°©ë²•**:
            1. ë” ê¸´ ê¸°ê°„ ì„ íƒ
            2. 1ì¼ë´‰ìœ¼ë¡œ ë³€ê²½
            3. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
            """)
            st.stop()
        
        pred_in_sample = hw_model.fittedvalues
        
        # [ê°œì„ ë¨] v2.4.0: ì˜¤í”„ì…‹ ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡
        forecast_steps = min(30, len(close_series) // 2)
        last_actual_value = close_series.iloc[-1]
        
        # ìµœê·¼ ì¶”ì„¸ ê³„ì‚° (ìµœê·¼ 20ê°œ ë°ì´í„°ì˜ ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°)
        recent_window = min(20, len(close_series))
        recent_prices = close_series.iloc[-recent_window:].values
        recent_trend = np.polyfit(range(recent_window), recent_prices, 1)[0]
        
        future_forecast = forecast_with_offset_scaling(
            hw_model, 
            forecast_steps, 
            last_actual_value, 
            recent_trend
        )
        
        last_date = df.index[-1]
        future_dates = [last_date + pd.Timedelta(days=i + 1) for i in range(forecast_steps)]
        future_df = pd.DataFrame({'ì˜ˆì¸¡ ì¢…ê°€': future_forecast.values}, index=future_dates)
        
        progress_placeholder.markdown(render_progress_bar(4, 6), unsafe_allow_html=True)
        status_text.info("ğŸ•¯ï¸ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì¤‘...")
        
        patterns = detect_candlestick_patterns(df)
        
        progress_placeholder.markdown(render_progress_bar(5, 6), unsafe_allow_html=True)
        status_text.info("âœ… ëª¨ë¸ì„ ê²€ì¦í•˜ëŠ” ì¤‘...")
        
        cv_results = perform_timeseries_cv(df, n_splits=min(5, len(df) // 20))
        
        progress_placeholder.markdown(render_progress_bar(6, 6), unsafe_allow_html=True)
        status_text.info("ğŸ¯ ë§¤ë§¤ ì „ëµì„ ìƒì„±í•˜ëŠ” ì¤‘...")
        
        current_price = df['Close'].iloc[-1]
        atr = df['ATR14'].iloc[-1]
        volatility = df['Volatility30d'].iloc[-1]
        atr_ratio = atr / current_price if current_price != 0 else 0.01
        
        hw_confidence = 75.0
        
        # [ìˆ˜ì •ë¨] v2.3.0: ë ˆë²„ë¦¬ì§€ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°›ìŒ
        leverage_info = calculate_optimized_leverage(
            investment_amount=investment_amount,
            volatility=volatility,
            atr_ratio=atr_ratio,
            confidence=hw_confidence,
            max_leverage=leverage_ceiling,
            crypto_name=selected_crypto  # [ì¶”ê°€ë¨] ì½”ì¸ ì´ë¦„ ì „ë‹¬
        )
        
        entry_price = current_price
        
        # [ì¶”ê°€ë¨] v2.7.2: AI ì˜ˆì¸¡ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ í¬ì§€ì…˜ íƒ€ì… ê²°ì •
        # (AI ì˜ˆì¸¡ ì½”ë“œëŠ” ì•„ë˜ì—ì„œ ì‹¤í–‰ë˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ LONG ê°€ì •)
        # ì‹¤ì œë¡œëŠ” AI ì˜ˆì¸¡ í›„ ë‹¤ì‹œ ê³„ì‚°í•´ì•¼ í•¨
        position_type = 'LONG'  # ê¸°ë³¸ê°’, AI ì˜ˆì¸¡ í›„ ì—…ë°ì´íŠ¸
        
        # [ìˆ˜ì •ë¨] v2.7.2: ë¡±/ìˆ êµ¬ë¶„í•˜ì—¬ Stop Loss & Take Profit ê³„ì‚°
        if position_type == 'LONG':
            stop_loss = entry_price - (atr * stop_loss_k)
            take_profit = entry_price + (atr * stop_loss_k * 2)
        else:  # SHORT
            stop_loss = entry_price + (atr * stop_loss_k)
            take_profit = entry_price - (atr * stop_loss_k * 2)
        
        # [ì¶”ê°€ë¨] v2.7.2: ê°€ê²© ìœ íš¨ì„± ê²€ì¦
        if position_type == 'LONG':
            if stop_loss >= entry_price:
                stop_loss = entry_price * 0.95  # 5% ì•„ë˜ë¡œ ê°•ì œ ì¡°ì •
                st.warning("âš ï¸ Stop Lossê°€ ì§„ì…ê°€ë³´ë‹¤ ë†’ì•„ 5% ì•„ë˜ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if take_profit <= entry_price:
                take_profit = entry_price * 1.10  # 10% ìœ„ë¡œ ê°•ì œ ì¡°ì •
        else:  # SHORT
            if stop_loss <= entry_price:
                stop_loss = entry_price * 1.05  # 5% ìœ„ë¡œ ê°•ì œ ì¡°ì •
                st.warning("âš ï¸ Stop Lossê°€ ì§„ì…ê°€ë³´ë‹¤ ë‚®ì•„ 5% ìœ„ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if take_profit >= entry_price:
                take_profit = entry_price * 0.90  # 10% ì•„ë˜ë¡œ ê°•ì œ ì¡°ì •
        
        # [ìˆ˜ì •ë¨] v2.7.2: Position Size ê³„ì‚° ì˜¤ë¥˜ ìˆ˜ì • (CRITICAL FIX)
        # ê¸°ì¡´: (risk_amount * leverage) / stop_loss_distance â†’ ë ˆë²„ë¦¬ì§€ë§Œí¼ ë¦¬ìŠ¤í¬ ì¦í­ âŒ
        # ìˆ˜ì •: risk_amount / stop_loss_distance â†’ ë ˆë²„ë¦¬ì§€ëŠ” ì¦ê±°ê¸ˆì—ë§Œ ì˜í–¥ âœ“
        risk_amount = investment_amount * risk_per_trade_pct
        stop_loss_distance = abs(entry_price - stop_loss)
        
        # [ì¶”ê°€ë¨] v2.7.2: 0 ë‚˜ëˆ„ê¸° ë³´í˜¸
        if stop_loss_distance < entry_price * 0.001:  # 0.1% ìµœì†Œê°’
            stop_loss_distance = entry_price * 0.01  # 1%ë¡œ ì¡°ì •
            st.warning("âš ï¸ Stop Loss ê±°ë¦¬ê°€ ë„ˆë¬´ ì‘ì•„ 1%ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì˜¬ë°”ë¥¸ Position Size ê³µì‹ (Fixed Fractional Method)
        position_size = risk_amount / stop_loss_distance
        
        # [ì¶”ê°€ë¨] v2.7.2: í•„ìš” ì¦ê±°ê¸ˆ ê³„ì‚°
        position_value = position_size * entry_price
        required_margin = position_value / leverage_info['recommended']
        
        # [ì¶”ê°€ë¨] v2.7.2: ì¦ê±°ê¸ˆ ë¶€ì¡± ì²´í¬
        if required_margin > investment_amount:
            st.error(f"âŒ ì¦ê±°ê¸ˆ ë¶€ì¡±: ${required_margin:,.2f} í•„ìš” (ë³´ìœ : ${investment_amount:,.2f})")
            # ì‚¬ìš© ê°€ëŠ¥í•œ ìµœëŒ€ í¬ì§€ì…˜ìœ¼ë¡œ ì¡°ì •
            position_size = (investment_amount * leverage_info['recommended']) / entry_price
            position_value = position_size * entry_price
            required_margin = investment_amount
            st.info(f"â†’ í¬ì§€ì…˜ í¬ê¸°ë¥¼ {position_size:.6f} ì½”ì¸ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
        
        rr_ratio = calculate_rr_ratio(entry_price, take_profit, stop_loss)
        
        # ë§¤ë„ ì „ëµ ê³„ì‚° (interval íŒŒë¼ë¯¸í„° ì¶”ê°€)
        exit_strategy = calculate_exit_strategy(df, entry_price, atr, investment_amount, leverage_info['recommended'], interval)
        
        progress_placeholder.empty()
        status_text.empty()
        
        st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ê²°ê³¼ ì¶œë ¥
        render_data_summary(df, selected_crypto, interval_name)
        render_ai_forecast(future_df, hw_confidence)
        render_patterns(patterns)
        render_technical_indicators(df)
        # render_validation_results(cv_results)  # ì‚­ì œë¨
        # [ì¶”ê°€ë¨] v2.2.1: AI ì˜ˆì¸¡ì— í•„ìš”í•œ ë³€ìˆ˜ ì¶”ì¶œ
        ema_short = df['EMA50'].iloc[-1]
        ema_long = df['EMA200'].iloc[-1]
        rsi = df['RSI14'].iloc[-1]
        macd = df['MACD'].iloc[-1]
        macd_signal = df['MACD_Signal'].iloc[-1]
        
        # [ì¶”ê°€ë¨] AI ì˜ˆì¸¡ ì‹¤í–‰
        ai_prediction = predict_trend_with_ai(
            df=df,
            current_price=current_price,
            ema_short=ema_short,
            ema_long=ema_long,
            rsi=rsi,
            macd=macd,
            macd_signal=macd_signal
        )
        
        # [ì¶”ê°€ë¨] AI ì˜ˆì¸¡ ê²°ê³¼ ë Œë”ë§ (ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë‹¤ìŒ)
        render_ai_prediction(ai_prediction, current_price)
        
        # [ì¶”ê°€ë¨] í¬ì§€ì…˜ ì¶”ì²œ ê³„ì‚°
        position_recommendation = recommend_position(
            ai_prediction=ai_prediction,
            current_price=current_price,
            stop_loss=stop_loss,
            take_profit=take_profit,
            volatility=volatility
        )
        
        render_trading_strategy(current_price, leverage_info, entry_price,
                               stop_loss, take_profit, position_size,
                               rr_ratio, investment_amount)
        
        # [ì¶”ê°€ë¨] í¬ì§€ì…˜ ì¶”ì²œ ë Œë”ë§ (ë§¤ë§¤ ì „ëµ ì§í›„)
        render_position_recommendation(position_recommendation)
        
        # [ì¶”ê°€ë¨] v2.8.0: ê³ ê¸‰ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë¶„ì„
        st.markdown("---")
        st.markdown("<div class='section-title'>ğŸ›¡ï¸ ê³ ê¸‰ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë¶„ì„</div>", unsafe_allow_html=True)
        
        # 1. Kelly Criterion ë¶„ì„
        kelly_result = calculate_kelly_criterion(
            ai_confidence=ai_prediction['confidence'],
            rr_ratio=rr_ratio,
            kelly_fraction=0.5  # Half Kelly
        )
        render_kelly_analysis(kelly_result, position_size, entry_price, investment_amount)
        
        # 3. Monte Carlo ì‹œë®¬ë ˆì´ì…˜
        st.markdown("---")

        # 3. ì‹¤ì‹œê°„ ê¸€ë¡œë²Œ ë°ì´í„° í†µí•© ë¶„ì„ (v2.9.0)
        st.markdown('---')
        render_exit_strategy(exit_strategy, entry_price, investment_amount, leverage_info['recommended'])
        
        # v2.6.0: í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ (ì„ íƒí•œ ì½”ì¸ì— ëŒ€í•´ ìë™ ì‹¤í–‰)
        st.markdown("---")
        st.markdown("<div class='section-title'>ğŸ¯ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ (ì„ íƒ ê¸°ê°„ë³„ íˆ¬ì ì„±ê³¼ ì¢…í•© ë¶„ì„)</div>", unsafe_allow_html=True)
        
        # ì„ íƒí•œ ì½”ì¸ì— ëŒ€í•´ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ìë™ ì‹¤í–‰ (raw_df ì‚¬ìš©)
        render_portfolio_backtest(raw_df, selected_crypto)
        
        # ê°€ê²© ì°¨íŠ¸
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ì°¨íŠ¸")
        
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¹ ìº”ë“¤ìŠ¤í‹±", "ğŸ“Š ê±°ë˜ëŸ‰", "ğŸ”µ RSI", "ğŸ“‰ MACD"])
        
        with tab1:
            fig = create_candlestick_chart(df, selected_crypto)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            fig = create_volume_chart(df)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab3:
            fig = create_rsi_chart(df)
            st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            fig = create_macd_chart(df)
            st.plotly_chart(fig, use_container_width=True)
        
        # v2.9.4: ì‹¤ì‹œê°„ ë¶„ì„
        st.markdown("---")
        st.markdown("<div class='section-title'>ğŸš€ v2.9.4 ì‹¤ì‹œê°„ ë¶„ì„</div>", unsafe_allow_html=True)
        
        analysis_tabs = st.tabs(["ğŸ¯ ì‹ í˜¸ ì ìˆ˜", "ğŸ“Š ì‹¤ì‹œê°„ í˜„í™©"])
        
        with analysis_tabs[0]:
            st.markdown("#### ì¢…í•© ì‹ í˜¸ ì ìˆ˜ ì‹œìŠ¤í…œ")
            try:
                current_price = df['Close'].iloc[-1]
                score_result = calculate_signal_score(df, current_price)
                render_signal_score(score_result)
            except Exception as e:
                st.error(f"âŒ ì‹ í˜¸ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        
        with analysis_tabs[1]:
            st.markdown("#### ì‹¤ì‹œê°„ ë§¤ë§¤ ë¹„ìœ¨ & ê¸°ê°„ë³„ ìˆ˜ìµë¥ ")
            try:
                trading_metrics = calculate_trading_metrics(selected_crypto)
                render_trading_metrics(trading_metrics)
            except Exception as e:
                st.error(f"âŒ ì‹¤ì‹œê°„ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”¬ ê³ ê¸‰ ë‹¤ì°¨ì› ë¶„ì„ (v2.9.4 Advanced)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        st.markdown("---")
        st.markdown("<div class='section-title'>ğŸ”¬ ê³ ê¸‰ ë‹¤ì°¨ì› ë¶„ì„</div>", unsafe_allow_html=True)
        st.caption("íŒ¨í„´(ë¡œì»¬) + ë ˆì§(ê¸€ë¡œë²Œ) + ì»¨í…ìŠ¤íŠ¸(ì˜¨ì²´ì¸/íŒŒìƒ/ì‹œê°„)")
        
        advanced_tabs = st.tabs([
            "ğŸ¯ í†µí•© ì‹œê·¸ë„",
            "ğŸ“Š íŒ¨í„´ ë¶„ì„",
            "ğŸŒ ë ˆì§ ë¶„ë¥˜",
            "ğŸ“ˆ ì»¨í…ìŠ¤íŠ¸",
            "âœ… ê²€ì¦"
        ])
        
        # íƒ­ 1: í†µí•© ì‹œê·¸ë„
        with advanced_tabs[0]:
            st.markdown("### ğŸ¯ ë‹¤ì°¨ì› í†µí•© ì‹œê·¸ë„")
            st.info("â„¹ï¸ ì´ë²¤íŠ¸ì„± íŒ¨í„´(Squeeze/NR7/Inside Bar)ì€ ë°©í–¥ì„± í•„í„°ì™€ ê²°í•©í•˜ì—¬ ì‚¬ìš©")
            
            try:
                integrated = generate_integrated_signal(df, selected_crypto)
                
                signal = integrated['signal']
                confidence = integrated['confidence']
                
                if signal == 'BUY':
                    st.success(f"### ğŸŸ¢ ë§¤ìˆ˜ ì‹œê·¸ë„ (ì‹ ë¢°ë„: {confidence:.1f}%)")
                elif signal == 'SELL':
                    st.error(f"### ğŸ”´ ë§¤ë„ ì‹œê·¸ë„ (ì‹ ë¢°ë„: {confidence:.1f}%)")
                elif signal == 'WAIT':
                    st.warning(f"### â¸ï¸ ëŒ€ê¸° (íŒ¨í„´ ê°ì§€, ë°©í–¥ ë¶ˆëª…í™•)")
                else:
                    st.info(f"### âšª ì¤‘ë¦½ (ì‹ ë¢°ë„: {confidence:.1f}%)")
                
                st.markdown("#### ğŸ“‹ ë¶„ì„ ê·¼ê±°")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**ë°©í–¥ì„± í•„í„°**")
                    directional = integrated['directional']
                    st.metric("ì¶”ì„¸ ì ìˆ˜", f"{directional['trend']:.0f}/100")
                    st.metric("ëª¨ë©˜í…€ (RSI)", f"{directional['momentum']:.0f}")
                    st.metric("ë°©í–¥", directional['direction'])
                
                with col2:
                    st.markdown("**ì‹œì¥ ë ˆì§**")
                    regime = integrated['market_regime']
                    st.metric("ë ˆì§", regime['regime'])
                    st.metric("ì‹ ë¢°ë„", f"{regime['confidence']:.0f}%")
                    st.metric("ë³€ë™ì„±", f"{regime['volatility']:.2%}")
                
            except Exception as e:
                st.error(f"âŒ í†µí•© ì‹œê·¸ë„ ìƒì„± ì˜¤ë¥˜: {str(e)}")
                st.exception(e)
        
        # íƒ­ 2: íŒ¨í„´ ë¶„ì„
        with advanced_tabs[1]:
            st.markdown("### ğŸ“Š ì´ë²¤íŠ¸ì„± íŒ¨í„´ ê°ì§€")
            st.caption("âš ï¸ ì£¼ì˜: ì´ íŒ¨í„´ë“¤ì€ í™•ë¥  ì¤‘ë¦½ì ì´ë©° ë°©í–¥ì„± í•„í„°ì™€ ê²°í•© í•„ìˆ˜")
            
            try:
                squeeze = detect_squeeze_pattern(df)
                with st.expander("ğŸ”¹ Bollinger Band Squeeze", expanded=squeeze['detected']):
                    if squeeze['detected']:
                        st.success(f"âœ… Squeeze ê°ì§€! (ê°•ë„: {squeeze['strength']:.1f}%)")
                        st.write(f"BB í­: {squeeze['bb_width']:.2f}%")
                        st.warning("âš ï¸ ë°©í–¥ ì¤‘ë¦½ - ë°©í–¥ì„± í•„í„° í™•ì¸ í•„ìš”")
                    else:
                        st.info("Squeeze ë¯¸ê°ì§€")
                
                nr7 = detect_nr7_pattern(df)
                with st.expander("ğŸ”¹ NR7 (Narrowest Range 7)", expanded=nr7['detected']):
                    if nr7['detected']:
                        st.success(f"âœ… NR7 íŒ¨í„´ ê°ì§€! (ê°•ë„: {nr7['strength']:.1f}%)")
                        st.write(f"í˜„ì¬ Range: {nr7['range']:.2f}")
                        st.write(f"í‰ê·  Range: {nr7['avg_range']:.2f}")
                        st.warning("âš ï¸ ë¸Œë ˆì´í¬ì•„ì›ƒ ëŒ€ê¸° - ë°©í–¥ ë¯¸ì •")
                    else:
                        st.info("NR7 ë¯¸ê°ì§€")
                
                inside = detect_inside_bar(df)
                with st.expander("ğŸ”¹ Inside Bar", expanded=inside['detected']):
                    if inside['detected']:
                        st.success(f"âœ… Inside Bar ê°ì§€! (íƒ€ì´íŠ¸í•¨: {inside['tightness']:.1f}%)")
                        st.warning("âš ï¸ ë¸Œë ˆì´í¬ì•„ì›ƒ ëŒ€ê¸°")
                    else:
                        st.info("Inside Bar ë¯¸ê°ì§€")
                
                triangle = detect_triangle_convergence(df)
                with st.expander("ğŸ”¹ ì‚¼ê° ìˆ˜ë ´ íŒ¨í„´", expanded=triangle['detected']):
                    if triangle['detected']:
                        st.success(f"âœ… ì‚¼ê° ìˆ˜ë ´ ê°ì§€! (ê°•ë„: {triangle['strength']:.1f}%)")
                        st.write(f"ê³ ì  ì¶”ì„¸: {triangle['high_trend']:.4f}")
                        st.write(f"ì €ì  ì¶”ì„¸: {triangle['low_trend']:.4f}")
                    else:
                        st.info("ì‚¼ê° ìˆ˜ë ´ ë¯¸ê°ì§€")
                
            except Exception as e:
                st.error(f"âŒ íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # íƒ­ 3: ë ˆì§ ë¶„ë¥˜
        with advanced_tabs[2]:
            st.markdown("### ğŸŒ ì‹œì¥ & ì‹œê°„ ë ˆì§")
            
            try:
                market_regime = classify_market_regime(df)
                time_regime = calculate_time_regime(df)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ“ˆ ì‹œì¥ ë ˆì§")
                    
                    regime = market_regime['regime']
                    if regime == 'TRENDING':
                        st.success(f"âœ… **ì¶”ì„¸ì¥** (ì‹ ë¢°ë„: {market_regime['confidence']:.0f}%)")
                        direction = "ìƒìŠ¹" if market_regime['trend_direction'] > 0 else "í•˜ë½"
                        st.write(f"ë°©í–¥: {direction}")
                    elif regime == 'HIGH_VOLATILITY':
                        st.warning(f"âš ï¸ **ê³ ë³€ë™ì„±** (ë³€ë™ì„±: {market_regime['volatility']:.1%})")
                    else:
                        st.info(f"ğŸ“Š **ë ˆì¸ì§€ì¥** (ì‹ ë¢°ë„: {market_regime['confidence']:.0f}%)")
                    
                    st.metric("ATR", f"{market_regime['atr']:.2f}")
                
                with col2:
                    st.markdown("#### â° ì‹œê°„ ë ˆì§")
                    
                    session = time_regime['session']
                    vol_mult = time_regime['volatility_multiplier']
                    
                    st.write(f"**ì„¸ì…˜**: {session}")
                    st.write(f"**ì‹œê°„** (UTC): {time_regime['hour_utc']}ì‹œ")
                    st.metric("ë³€ë™ì„± ë°°ìˆ˜", f"{vol_mult:.1f}x")
                    
                    if vol_mult > 1.2:
                        st.success("âœ… ë†’ì€ í™œë™ì„± ê¸°ëŒ€")
                    elif vol_mult < 0.8:
                        st.info("â„¹ï¸ ë‚®ì€ í™œë™ì„± ì˜ˆìƒ")
                
            except Exception as e:
                st.error(f"âŒ ë ˆì§ ë¶„ë¥˜ ì˜¤ë¥˜: {str(e)}")
        
        # íƒ­ 4: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        with advanced_tabs[3]:
            st.markdown("### ğŸ“ˆ íŒŒìƒìƒí’ˆ & ì£¼ë¬¸íë¦„")
            
            try:
                derivatives = analyze_derivatives_context(df)
                order_flow = analyze_order_flow(df)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### ğŸ“Š íŒŒìƒìƒí’ˆ ì§€í‘œ")
                    
                    st.metric("í€ë”©ë¹„ (ì¶”ì •)", f"{derivatives['funding_rate']:.3f}%")
                    st.metric("OI ë³€í™”", f"{derivatives['oi_change']:+.1f}%")
                    st.metric("ë¡±/ìˆ ë¹„ìœ¨", f"{derivatives['long_short_ratio']:.0f}%")
                    
                    signal = derivatives['signal']
                    if signal == 'OVERLEVERAGED_LONG':
                        st.warning("âš ï¸ ë¡± ê³¼ì—´ - ì¡°ì • ë¦¬ìŠ¤í¬")
                    elif signal == 'OVERLEVERAGED_SHORT':
                        st.warning("âš ï¸ ìˆ ê³¼ì—´ - ì‡¼íŠ¸ ìŠ¤í€„ì¦ˆ ë¦¬ìŠ¤í¬")
                    else:
                        st.success("âœ… ê· í˜• ìƒíƒœ")
                
                with col2:
                    st.markdown("#### ğŸ“Š ì£¼ë¬¸íë¦„ ë¶„ì„")
                    
                    st.metric("ë§¤ìˆ˜ ì••ë ¥", f"{order_flow['buy_pressure']:.0f}%")
                    st.metric("ë§¤ë„ ì••ë ¥", f"{order_flow['sell_pressure']:.0f}%")
                    
                    imbalance = order_flow['imbalance']
                    if imbalance > 10:
                        st.success(f"âœ… ë§¤ìˆ˜ ìš°ì„¸ ({imbalance:+.1f}%)")
                    elif imbalance < -10:
                        st.error(f"ğŸ”´ ë§¤ë„ ìš°ì„¸ ({imbalance:+.1f}%)")
                    else:
                        st.info(f"âšª ê· í˜• ({imbalance:+.1f}%)")
                    
                    st.metric("ê°•ë„", order_flow['strength'])
                
            except Exception as e:
                st.error(f"âŒ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        
        # íƒ­ 5: Walk-Forward ê²€ì¦
        with advanced_tabs[4]:
            st.markdown("### âœ… Walk-Forward ê²€ì¦")
            st.caption("ë°ì´í„° ëˆ„ìˆ˜ & ìŠ¤ëˆ„í•‘ ë°©ì§€ ê²€ì¦")
            
            st.info("""
            **ê²€ì¦ ë°©ë²•**:
            1. ê³¼ê±° ë°ì´í„°ë¡œ íŒŒë¼ë¯¸í„° ìµœì í™” (í›ˆë ¨)
            2. ë¯¸ë˜ ë°ì´í„°ë¡œ Out-of-Sample í…ŒìŠ¤íŠ¸
            3. ì‹œê°„ ìˆœìœ¼ë¡œ ì•ìœ¼ë¡œ ì´ë™í•˜ë©° ë°˜ë³µ
            
            âš ï¸ **ë¯¸ë˜ ë°ì´í„° ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€**
            """)
            
            if st.button("ğŸ”¬ ê²€ì¦ ì‹œì‘", type="primary"):
                with st.spinner("Walk-Forward ê²€ì¦ ì§„í–‰ ì¤‘..."):
                    try:
                        validation_result = walk_forward_validation(
                            df,
                            train_size=1000,
                            test_size=100,
                            step=50
                        )
                        
                        if validation_result['status'] == 'COMPLETED':
                            st.success("âœ… ê²€ì¦ ì™„ë£Œ!")
                            
                            accuracy = validation_result['accuracy']
                            total = validation_result['total_signals']
                            correct = validation_result['correct_signals']
                            
                            col1, col2, col3 = st.columns(3)
                            
                            with col1:
                                st.metric("ì´ ì‹œê·¸ë„", total)
                            
                            with col2:
                                st.metric("ì •í™•í•œ ì‹œê·¸ë„", correct)
                            
                            with col3:
                                st.metric("ì •í™•ë„", f"{accuracy:.1f}%")
                            
                            if accuracy > 55:
                                st.success("ğŸ¯ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥")
                            elif accuracy > 50:
                                st.info("ğŸ“Š ì•½ê°„ì˜ ì˜ˆì¸¡ë ¥ ìˆìŒ")
                            else:
                                st.warning("âš ï¸ ì˜ˆì¸¡ë ¥ ë¶€ì¡± - íŒŒë¼ë¯¸í„° ì¬ì¡°ì • í•„ìš”")
                            
                            st.markdown("#### ìµœê·¼ 10ê°œ ì‹œê·¸ë„ ê²°ê³¼")
                            results_df = pd.DataFrame(validation_result['results'])
                            st.dataframe(results_df)
                        
                        else:
                            st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê²€ì¦ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    except Exception as e:
                        st.error(f"âŒ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
                        st.exception(e)
        
    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.warning("""
        **ì¼ë°˜ì ì¸ í•´ê²° ë°©ë²•**:
        1. ìºì‹œ ì´ˆê¸°í™” í›„ ì¬ì‹œë„
        2. ë” ê¸´ ê¸°ê°„ ì„ íƒ (ìµœì†Œ 30ì¼ ì´ìƒ)
        3. 1ì¼ë´‰ìœ¼ë¡œ ë³€ê²½
        4. ë‹¤ë¥¸ ì½”ì¸ ì„ íƒ
        5. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„
        """)
        
        if st.button("ğŸ”„ ìºì‹œ ì´ˆê¸°í™”"):
            st.cache_data.clear()
            st.rerun()
        
        with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´ (ê°œë°œììš©)"):
            st.code(str(e))
            import traceback
            st.code(traceback.format_exc())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2.9.0: ì‹¤ì‹œê°„ ë°ì´í„° UI ë Œë”ë§ í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def render_news_analysis(news_analysis: Dict, news_data: Dict):
    """ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
    st.markdown("### ğŸ“¡ ì‹¤ì‹œê°„ ê¸€ë¡œë²Œ ë‰´ìŠ¤ ë¶„ì„")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        sentiment = news_analysis['overall_sentiment']
        emoji = "ğŸŸ¢" if sentiment == 'Bullish' else ("ğŸ”´" if sentiment == 'Bearish' else "ğŸŸ¡")
        st.metric(
            label="ì „ì²´ ì„¼í‹°ë¨¼íŠ¸",
            value=f"{emoji} {sentiment}",
            help="ë‰´ìŠ¤ ì „ì²´ì˜ ì‹œì¥ ì‹¬ë¦¬"
        )
    
    with col2:
        confidence = news_analysis['confidence']
        st.metric(
            label="ì‹ ë¢°ë„",
            value=f"{confidence:.1%}",
            help="ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ì˜ ì‹ ë¢°ë„"
        )
    
    with col3:
        impact = news_analysis['market_impact']
        impact_emoji = {"High": "ğŸ”¥", "Medium": "âš–ï¸", "Low": "ğŸ’¤"}
        st.metric(
            label="ì‹œì¥ ì˜í–¥ë„",
            value=f"{impact_emoji.get(impact, '')} {impact}",
            help="ë‰´ìŠ¤ê°€ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì˜ í¬ê¸°"
        )
    
    # ì£¼ìš” ë‰´ìŠ¤ í‘œì‹œ
    if news_data.get('news'):
        st.markdown("#### ğŸ“° ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤ (Top 3)")
        for i, news in enumerate(news_data['news'][:3], 1):
            sentiment_emoji = {
                'positive': 'ğŸ‘',
                'negative': 'ğŸ‘',
                'neutral': 'ğŸ˜'
            }
            emoji = sentiment_emoji.get(news['sentiment'], 'ğŸ“°')
            st.markdown(f"{emoji} **[{news['title']}]({news['url']})**")
            st.caption(f"ì¶œì²˜: {news['source']} | {news['published_at'][:10]}")
    
    st.markdown(f"**ğŸ’¡ ì¶”ì²œ:** {news_analysis['recommendation']}")


def render_economic_indicators(fred_data: Dict):
    """ê²½ì œ ì§€í‘œ ë Œë”ë§"""
    st.markdown("### ğŸ¤– ì‹¤ì‹œê°„ ê²½ì œ ì§€í‘œ (FRED)")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ìµœì‹  CPI",
            value=f"{fred_data['latest_value']:.2f}",
            help="ë¯¸êµ­ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ (Consumer Price Index)"
        )
    
    with col2:
        change_mom = fred_data['change_mom']
        color = "ğŸ”´" if change_mom > 0 else "ğŸ”µ"
        st.metric(
            label="MoM ë³€í™”",
            value=f"{color} {change_mom:+.2f}%",
            help="ì „ì›” ëŒ€ë¹„ ë³€í™”ìœ¨ (Month-over-Month)"
        )
    
    with col3:
        change_yoy = fred_data['change_yoy']
        color = "ğŸ”´" if change_yoy > 0 else "ğŸ”µ"
        st.metric(
            label="YoY ë³€í™”",
            value=f"{color} {change_yoy:+.2f}%",
            help="ì „ë…„ ëŒ€ë¹„ ë³€í™”ìœ¨ (Year-over-Year)"
        )
    
    with col4:
        trend = fred_data['trend']
        trend_emoji = {"Rising": "ğŸ“ˆ", "Falling": "ğŸ“‰", "Stable": "â¡ï¸"}
        st.metric(
            label="íŠ¸ë Œë“œ",
            value=f"{trend_emoji.get(trend, '')} {trend}",
            help="í˜„ì¬ ê²½ì œ ì§€í‘œ ì¶”ì„¸"
        )
    
    # í•´ì„
    if trend == 'Rising':
        st.info("ğŸ“Š ì¸í”Œë ˆì´ì…˜ ìƒìŠ¹ ì¤‘ â†’ ì•”í˜¸í™”í í—¤ì§€ ìˆ˜ìš” ì¦ê°€ ê°€ëŠ¥")
    elif trend == 'Falling':
        st.success("ğŸ“Š ì¸í”Œë ˆì´ì…˜ í•˜ë½ ì¤‘ â†’ ë§¤í¬ë¡œ ë¦¬ìŠ¤í¬ ê°ì†Œ")
    else:
        st.info("ğŸ“Š ì•ˆì •ì ì¸ ê²½ì œ í™˜ê²½ ìœ ì§€")


def render_onchain_metrics(dominance_data: Dict, kimchi_data: Dict, funding_data: Dict):
    """ì˜¨ì²´ì¸ ë©”íŠ¸ë¦­ ë Œë”ë§"""
    st.markdown("### ğŸ“Š ì˜¨ì²´ì¸ ë©”íŠ¸ë¦­ìŠ¤")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸª™ BTC ë„ë¯¸ë„ŒìŠ¤")
        if dominance_data.get('status') == 'success':
            dominance = dominance_data['dominance']
            st.metric(
                label="ì‹œê°€ì´ì•¡ ì ìœ ìœ¨",
                value=f"{dominance:.2f}%",
                help="ì „ì²´ ì•”í˜¸í™”í ì‹œê°€ì´ì•¡ ì¤‘ ë¹„íŠ¸ì½”ì¸ ë¹„ìœ¨"
            )
            
            if dominance > 45:
                st.success("âœ… BTC ê°•ì„¸ â†’ ì•ˆì •ì  ì‹œì¥")
            elif dominance > 40:
                st.info("âš–ï¸ ê· í˜• ìƒíƒœ")
            else:
                st.warning("âš ï¸ ì•ŒíŠ¸ì½”ì¸ ì‹œì¦Œ â†’ ë³€ë™ì„± ì£¼ì˜")
        else:
            st.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    with col2:
        st.markdown("#### ğŸ‡°ğŸ‡· ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„")
        if kimchi_data.get('status') == 'success':
            premium = kimchi_data['premium']
            st.metric(
                label="í•œêµ­ vs ê¸€ë¡œë²Œ",
                value=f"{premium:+.2f}%",
                help="í•œêµ­ ê±°ë˜ì†Œì™€ ê¸€ë¡œë²Œ ê±°ë˜ì†Œì˜ ê°€ê²© ì°¨ì´"
            )
            
            if premium > 3:
                st.success(f"âœ… ê¸ì •ì  í”„ë¦¬ë¯¸ì—„ â†’ í•œêµ­ íˆ¬ì ì‹¬ë¦¬ ì¢‹ìŒ")
            elif premium < -3:
                st.error(f"âš ï¸ ë„¤ê±°í‹°ë¸Œ í”„ë¦¬ë¯¸ì—„ â†’ í•œêµ­ íˆ¬ì ì‹¬ë¦¬ ì•…í™”")
            else:
                st.info("âš–ï¸ ì •ìƒ ë²”ìœ„")
        else:
            st.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    with col3:
        st.markdown("#### ğŸ’° í€ë”©ë¹„ (Funding Rate)")
        if funding_data.get('status') == 'success':
            funding = funding_data['funding_rate']
            st.metric(
                label="ì„ ë¬¼ í€ë”©ë¹„",
                value=f"{funding:+.4f}%",
                help="ì„ ë¬¼ ì‹œì¥ì˜ ë¡±/ìˆ ê· í˜• ì§€í‘œ"
            )
            
            if funding > 0.1:
                st.warning("âš ï¸ ë¡± ê³¼ì—´ â†’ ì²­ì‚° ë¦¬ìŠ¤í¬")
            elif funding < -0.05:
                st.info("ğŸ’¡ ìˆ ìš°ì„¸ â†’ ìˆ ìŠ¤í€´ì¦ˆ ê°€ëŠ¥")
            else:
                st.success("âœ… ê· í˜• ì¡íŒ ìƒíƒœ")
        else:
            st.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")


def render_comprehensive_analysis(analysis: Dict):
    """ì¢…í•© ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
    st.markdown("### ğŸ¯ ì¢…í•© ì‹œì¥ ë¶„ì„")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        score = analysis['overall_score']
        st.metric(
            label="ì¢…í•© ì ìˆ˜",
            value=f"{score:.0f}/100",
            help="ëª¨ë“  ì§€í‘œë¥¼ ì¢…í•©í•œ ì‹œì¥ ì ìˆ˜"
        )
        # ì ìˆ˜ ë°” í‘œì‹œ
        bar_length = int(score / 10)
        bar = "â–ˆ" * bar_length + "â–‘" * (10 - bar_length)
        st.text(bar)
    
    with col2:
        recommendation = analysis['recommendation']
        rec_emoji = {
            "Strong Buy": "ğŸ’ª",
            "Buy": "ğŸ‘",
            "Hold": "ğŸ¤",
            "Sell": "ğŸ‘",
            "Strong Sell": "ğŸš¨"
        }
        rec_color = {
            "Strong Buy": "success",
            "Buy": "info",
            "Hold": "warning",
            "Sell": "warning",
            "Strong Sell": "error"
        }
        
        st.metric(
            label="ì¶”ì²œ ë“±ê¸‰",
            value=f"{rec_emoji.get(recommendation, '')} {recommendation}",
            help="ì¢…í•© ë¶„ì„ ê¸°ë°˜ íˆ¬ì ì¶”ì²œ"
        )
    
    with col3:
        risk_level = analysis['risk_level']
        risk_emoji = {
            "Low": "ğŸŸ¢",
            "Medium": "ğŸŸ¡",
            "High": "ğŸŸ ",
            "Very High": "ğŸ”´"
        }
        st.metric(
            label="ë¦¬ìŠ¤í¬ ë ˆë²¨",
            value=f"{risk_emoji.get(risk_level, '')} {risk_level}",
            help="í˜„ì¬ ì‹œì¥ì˜ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€"
        )
    
    # ì£¼ìš” ë¶„ì„ ìš”ì¸
    st.markdown("#### ğŸ“‹ ì£¼ìš” ë¶„ì„ ìš”ì¸")
    for factor in analysis['key_factors']:
        st.markdown(f"- {factor}")
    
    st.markdown(f"**ì‹ ë¢°ë„:** {analysis['confidence']:.1%}")
    st.caption(f"ë¶„ì„ ì‹œê°„: {analysis['timestamp'][:19]}")
    
    # ì¶”ì²œì— ë”°ë¥¸ ë©”ì‹œì§€
    if recommendation in ["Strong Buy", "Buy"]:
        st.success(f"ğŸ’¡ {analysis['summary']}")
    elif recommendation == "Hold":
        st.info(f"ğŸ’¡ {analysis['summary']}")
    else:
        st.warning(f"ğŸ’¡ {analysis['summary']}")


# ==============================================================================
# v2.9.2: Open Interest ë°ì´í„° ìˆ˜ì§‘
# ==============================================================================

def fetch_open_interest(symbol: str = 'BTCUSDT') -> Dict:
    """
    Binance ì„ ë¬¼ ë¯¸ê²°ì œì•½ì • ë°ì´í„° ìˆ˜ì§‘
    
    Returns:
        dict: {'open_interest': float, 'symbol': str, 'status': str}
    """
    try:
        url = f"https://fapi.binance.com/fapi/v1/openInterest?symbol={symbol}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            return {
                'open_interest': float(data.get('openInterest', 0)),
                'symbol': data.get('symbol', symbol),
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
        else:
            return {
                'open_interest': 0.0,
                'symbol': symbol,
                'status': 'error',
                'message': 'API unavailable'
            }
    except Exception as e:
        return {
            'open_interest': 0.0,
            'symbol': symbol,
            'status': 'error',
            'error': str(e)
        }


def calculate_dual_timeframe_ema(df_main: pd.DataFrame, df_4h: pd.DataFrame = None) -> Dict:
    """
    ë“€ì–¼ íƒ€ì„í”„ë ˆì„ EMA ê³„ì‚°
    
    Parameters:
        df_main: ë©”ì¸ íƒ€ì„í”„ë ˆì„ ë°ì´í„°
        df_4h: 4ì‹œê°„ë´‰ ë°ì´í„° (ì„ íƒ)
    
    Returns:
        dict: {'ema20_main': float, 'ema20_4h': float, 'trend': str}
    """
    result = {
        'ema20_main': 0.0,
        'ema20_4h': 0.0,
        'ema50_4h': 0.0,
        'trend': 'Unknown'
    }
    
    # ë©”ì¸ íƒ€ì„í”„ë ˆì„ EMA20
    if not df_main.empty and len(df_main) >= 20:
        result['ema20_main'] = df_main['Close'].ewm(span=20, adjust=False).mean().iloc[-1]
    
    # 4ì‹œê°„ë´‰ EMA20, EMA50
    if df_4h is not None and not df_4h.empty and len(df_4h) >= 50:
        ema20_4h = df_4h['Close'].ewm(span=20, adjust=False).mean()
        ema50_4h = df_4h['Close'].ewm(span=50, adjust=False).mean()
        
        result['ema20_4h'] = ema20_4h.iloc[-1]
        result['ema50_4h'] = ema50_4h.iloc[-1]
        
        # ì¶”ì„¸ íŒë‹¨
        current_price = df_main['Close'].iloc[-1] if not df_main.empty else 0
        
        if current_price > result['ema20_4h'] and result['ema20_4h'] > result['ema50_4h']:
            result['trend'] = 'Strong Uptrend'
        elif current_price > result['ema20_4h']:
            result['trend'] = 'Uptrend'
        elif current_price < result['ema20_4h'] and result['ema20_4h'] < result['ema50_4h']:
            result['trend'] = 'Strong Downtrend'
        elif current_price < result['ema20_4h']:
            result['trend'] = 'Downtrend'
        else:
            result['trend'] = 'Sideways'
    
    return result


def calculate_high_reward_levels(entry_price: float, position_type: str = 'LONG',
                                   tp_percent: float = 4.0, sl_percent: float = 0.7) -> Dict:
    """
    ê³ ìœ„í—˜-ê³ ìˆ˜ìµ ì§„ì…/ì²­ì‚° ë ˆë²¨ ê³„ì‚° (DeepSeek ìŠ¤íƒ€ì¼)
    
    Parameters:
        entry_price: ì§„ì… ê°€ê²©
        position_type: 'LONG' ë˜ëŠ” 'SHORT'
        tp_percent: ëª©í‘œê°€ ë¹„ìœ¨ (ê¸°ë³¸ 4%)
        sl_percent: ì†ì ˆê°€ ë¹„ìœ¨ (ê¸°ë³¸ 0.7%)
    
    Returns:
        dict: {'take_profit': float, 'stop_loss': float, 'rr_ratio': float}
    """
    if position_type.upper() == 'LONG':
        take_profit = entry_price * (1 + tp_percent / 100)
        stop_loss = entry_price * (1 - sl_percent / 100)
    else:  # SHORT
        take_profit = entry_price * (1 - tp_percent / 100)
        stop_loss = entry_price * (1 + sl_percent / 100)
    
    risk = abs(entry_price - stop_loss)
    reward = abs(take_profit - entry_price)
    rr_ratio = reward / risk if risk > 0 else 0
    
    return {
        'take_profit': round(take_profit, 2),
        'stop_loss': round(stop_loss, 2),
        'rr_ratio': round(rr_ratio, 2),
        'tp_percent': tp_percent,
        'sl_percent': sl_percent
    }


"""
v2.9.2 ì‹ ê·œ ê¸°ëŠ¥ êµ¬í˜„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

# ==============================================================================
# 1. ë“€ì–¼ íƒ€ì„í”„ë ˆì„ ë°ì´í„° ìë™ ë¡œë“œ
# ==============================================================================

def load_dual_timeframe_data(symbol: str, days_3m: int = 7, days_4h: int = 30):
    """
    3ë¶„ë´‰ê³¼ 4ì‹œê°„ë´‰ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œ
    
    Parameters:
        symbol: Yahoo Finance ì‹¬ë³¼ (ì˜ˆ: 'BTC-USD')
        days_3m: 3ë¶„ë´‰ ë°ì´í„° ê¸°ê°„ (ê¸°ë³¸ 7ì¼)
        days_4h: 4ì‹œê°„ë´‰ ë°ì´í„° ê¸°ê°„ (ê¸°ë³¸ 30ì¼)
    
    Returns:
        tuple: (df_3m, df_4h)
    """
    try:
        # 3ë¶„ë´‰ ë°ì´í„°
        df_3m = yf.download(
            symbol,
            period='7d',
            interval='3m',
            progress=False
        )
        
        # 4ì‹œê°„ë´‰ ë°ì´í„°
        df_4h = yf.download(
            symbol,
            period=f'{days_4h}d',
            interval='4h',
            progress=False
        )
        
        # MultiIndex ì²˜ë¦¬
        if isinstance(df_3m.columns, pd.MultiIndex):
            df_3m.columns = df_3m.columns.get_level_values(0)
        if isinstance(df_4h.columns, pd.MultiIndex):
            df_4h.columns = df_4h.columns.get_level_values(0)
        
        return df_3m, df_4h
    
    except Exception as e:
        st.warning(f"âš ï¸ ë“€ì–¼ íƒ€ì„í”„ë ˆì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), pd.DataFrame()


# ==============================================================================
# 2. Open Interest íˆìŠ¤í† ë¦¬ ë°ì´í„° ìˆ˜ì§‘
# ==============================================================================

def fetch_open_interest_history(symbol: str = 'BTCUSDT', limit: int = 100):
    """
    Open Interest ì‹œê³„ì—´ ë°ì´í„° ìˆ˜ì§‘
    
    Parameters:
        symbol: Binance ì‹¬ë³¼
        limit: ë°ì´í„° ê°œìˆ˜ (ìµœëŒ€ 500)
    
    Returns:
        pd.DataFrame: ì‹œê³„ì—´ Open Interest ë°ì´í„°
    """
    try:
        # BinanceëŠ” Open Interest íˆìŠ¤í† ë¦¬ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
        # ëŒ€ì‹  í˜„ì¬ ê°’ë§Œ ë°˜ë³µ ìˆ˜ì§‘í•˜ì—¬ ë¡œì»¬ ì €ì¥ í•„ìš”
        # ì—¬ê¸°ì„œëŠ” ë”ë¯¸ ë°ì´í„°ë¡œ ì‹œì—°
        
        url = f"https://fapi.binance.com/fapi/v1/openInterest?symbol={symbol}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            current_oi = float(data.get('openInterest', 0))
            current_time = datetime.now()
            
            # ë”ë¯¸ íˆìŠ¤í† ë¦¬ ìƒì„± (ì‹¤ì œë¡œëŠ” DBì— ì €ì¥ í•„ìš”)
            dates = pd.date_range(end=current_time, periods=limit, freq='4H')
            oi_values = [current_oi * (1 + np.random.uniform(-0.1, 0.1)) for _ in range(limit)]
            
            df = pd.DataFrame({
                'timestamp': dates,
                'open_interest': oi_values
            })
            df.set_index('timestamp', inplace=True)
            
            return df
        else:
            return pd.DataFrame()
    
    except Exception as e:
        st.warning(f"âš ï¸ Open Interest íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()


# ==============================================================================
# 3. Chain-of-Thought ë¶„ì„ í•¨ìˆ˜
# ==============================================================================

def analyze_with_chain_of_thought(df: pd.DataFrame, current_price: float, 
                                    df_4h: pd.DataFrame = None,
                                    funding_rate: float = 0.0,
                                    open_interest: float = 0.0) -> Dict:
    """
    Chain-of-Thought ìŠ¤íƒ€ì¼ ìƒì„¸ ë¶„ì„
    
    Parameters:
        df: ë©”ì¸ íƒ€ì„í”„ë ˆì„ ë°ì´í„°
        current_price: í˜„ì¬ ê°€ê²©
        df_4h: 4ì‹œê°„ë´‰ ë°ì´í„°
        funding_rate: í€ë”©ë¹„
        open_interest: ë¯¸ê²°ì œì•½ì •
    
    Returns:
        dict: {
            'reasoning_steps': List[str],  # ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì •
            'signal': str,  # 'LONG', 'SHORT', 'NEUTRAL'
            'confidence': float,  # 0-100
            'summary': str  # ìµœì¢… ìš”ì•½
        }
    """
    
    reasoning_steps = []
    bullish_signals = 0
    bearish_signals = 0
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 1ë‹¨ê³„: ì¥ê¸° ì¶”ì„¸ ë¶„ì„ (4ì‹œê°„ë´‰)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    reasoning_steps.append("ğŸ” **1ë‹¨ê³„: ì¥ê¸° ì¶”ì„¸ ë¶„ì„ (4ì‹œê°„ë´‰)**")
    
    if df_4h is not None and not df_4h.empty and len(df_4h) >= 50:
        ema20_4h = df_4h['Close'].ewm(span=20, adjust=False).mean().iloc[-1]
        ema50_4h = df_4h['Close'].ewm(span=50, adjust=False).mean().iloc[-1]
        
        reasoning_steps.append(f"- í˜„ì¬ ê°€ê²©: ${current_price:,.2f}")
        reasoning_steps.append(f"- EMA20 (4H): ${ema20_4h:,.2f}")
        reasoning_steps.append(f"- EMA50 (4H): ${ema50_4h:,.2f}")
        
        if current_price > ema20_4h and ema20_4h > ema50_4h:
            bullish_signals += 2
            reasoning_steps.append(f"  âœ… **ê°•í•œ ìƒìŠ¹ ì¶”ì„¸** (ê°€ê²© > EMA20 > EMA50) [+2 bullish]")
        elif current_price > ema20_4h:
            bullish_signals += 1
            reasoning_steps.append(f"  âœ… ìƒìŠ¹ ì¶”ì„¸ (ê°€ê²© > EMA20) [+1 bullish]")
        elif current_price < ema20_4h and ema20_4h < ema50_4h:
            bearish_signals += 2
            reasoning_steps.append(f"  âŒ **ê°•í•œ í•˜ë½ ì¶”ì„¸** (ê°€ê²© < EMA20 < EMA50) [+2 bearish]")
        elif current_price < ema20_4h:
            bearish_signals += 1
            reasoning_steps.append(f"  âŒ í•˜ë½ ì¶”ì„¸ (ê°€ê²© < EMA20) [+1 bearish]")
        else:
            reasoning_steps.append(f"  âšª íš¡ë³´ ì¶”ì„¸ [ì¤‘ë¦½]")
    else:
        reasoning_steps.append("  âš ï¸ 4ì‹œê°„ë´‰ ë°ì´í„° ë¶€ì¡±")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 2ë‹¨ê³„: ë‹¨ê¸° ëª¨ë©˜í…€ ë¶„ì„
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    reasoning_steps.append("\nğŸ“Š **2ë‹¨ê³„: ë‹¨ê¸° ëª¨ë©˜í…€ ë¶„ì„**")
    
    if not df.empty and len(df) >= 20:
        # RSI
        rsi = df['RSI'].iloc[-1] if 'RSI' in df.columns else 50
        reasoning_steps.append(f"- RSI: {rsi:.2f}")
        
        if rsi < 30:
            bullish_signals += 1
            reasoning_steps.append(f"  âœ… RSI ê³¼ë§¤ë„ êµ¬ê°„ [+1 bullish]")
        elif rsi > 70:
            bearish_signals += 1
            reasoning_steps.append(f"  âŒ RSI ê³¼ë§¤ìˆ˜ êµ¬ê°„ [+1 bearish]")
        
        # MACD
        macd = df['MACD'].iloc[-1] if 'MACD' in df.columns else 0
        signal_line = df['Signal_Line'].iloc[-1] if 'Signal_Line' in df.columns else 0
        
        reasoning_steps.append(f"- MACD: {macd:.2f}")
        reasoning_steps.append(f"- Signal: {signal_line:.2f}")
        
        if macd > signal_line and macd > 0:
            bullish_signals += 1
            reasoning_steps.append(f"  âœ… MACD ê³¨ë“ í¬ë¡œìŠ¤ [+1 bullish]")
        elif macd < signal_line and macd < 0:
            bearish_signals += 1
            reasoning_steps.append(f"  âŒ MACD ë°ë“œí¬ë¡œìŠ¤ [+1 bearish]")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 3ë‹¨ê³„: íŒŒìƒìƒí’ˆ ì‹œì¥ ë¶„ì„
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    reasoning_steps.append("\nâ›“ï¸ **3ë‹¨ê³„: íŒŒìƒìƒí’ˆ ì‹œì¥ ë¶„ì„**")
    reasoning_steps.append(f"- í€ë”©ë¹„: {funding_rate:.4f}%")
    reasoning_steps.append(f"- ë¯¸ê²°ì œì•½ì •: ${open_interest:,.0f}")
    
    if funding_rate > 0.05:
        bearish_signals += 1
        reasoning_steps.append(f"  âš ï¸ ë†’ì€ ë¡± í¬ì§€ì…˜ (ì²­ì‚° ë¦¬ìŠ¤í¬) [+1 bearish]")
    elif funding_rate < -0.05:
        bullish_signals += 1
        reasoning_steps.append(f"  âš ï¸ ë†’ì€ ìˆ í¬ì§€ì…˜ (ìˆìŠ¤í€´ì¦ˆ ê°€ëŠ¥) [+1 bullish]")
    else:
        reasoning_steps.append(f"  âœ… ì¤‘ë¦½ì  í€ë”©ë¹„ [ê· í˜•]")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 4ë‹¨ê³„: ì‹ í˜¸ ì¢…í•© ë° ê²°ë¡ 
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    reasoning_steps.append("\nğŸ¯ **4ë‹¨ê³„: ì‹ í˜¸ ì¢…í•©**")
    reasoning_steps.append(f"- Bullish Signals: **{bullish_signals}**")
    reasoning_steps.append(f"- Bearish Signals: **{bearish_signals}**")
    
    total_signals = bullish_signals + bearish_signals
    
    if total_signals == 0:
        signal = 'NEUTRAL'
        confidence = 0
        summary = "ğŸ“Š ì‹ í˜¸ ë¶€ì¡±, ê´€ë§ ê¶Œì¥"
    elif bullish_signals > bearish_signals:
        signal = 'LONG'
        confidence = min(100, (bullish_signals / total_signals) * 100)
        summary = f"ğŸš€ LONG ì§„ì… ê¶Œì¥ (ì‹ ë¢°ë„ {confidence:.0f}%)"
    elif bearish_signals > bullish_signals:
        signal = 'SHORT'
        confidence = min(100, (bearish_signals / total_signals) * 100)
        summary = f"ğŸ“‰ SHORT ì§„ì… ê¶Œì¥ (ì‹ ë¢°ë„ {confidence:.0f}%)"
    else:
        signal = 'NEUTRAL'
        confidence = 50
        summary = "ğŸ¤ ì‹ í˜¸ í˜¼ì¬, ì‹ ì¤‘í•œ ì ‘ê·¼ í•„ìš”"
    
    reasoning_steps.append(f"\nğŸ’¡ **ìµœì¢… ê²°ë¡ **: {summary}")
    
    return {
        'reasoning_steps': reasoning_steps,
        'signal': signal,
        'confidence': confidence,
        'summary': summary,
        'bullish_signals': bullish_signals,
        'bearish_signals': bearish_signals
    }


# ==============================================================================
# 4. DeepSeek ìŠ¤íƒ€ì¼ ë°±í…ŒìŠ¤íŒ…
# ==============================================================================

def backtest_deepseek_strategy(df: pd.DataFrame, initial_capital: float = 10000,
                                tp_percent: float = 4.0, sl_percent: float = 0.7,
                                position_size_pct: float = 0.02) -> Dict:
    """
    DeepSeek ìŠ¤íƒ€ì¼ ë°±í…ŒìŠ¤íŒ… (ê³ R/R ì „ëµ)
    
    Parameters:
        df: ê°€ê²© ë°ì´í„°
        initial_capital: ì´ˆê¸° ìë³¸
        tp_percent: ëª©í‘œê°€ ë¹„ìœ¨ (ê¸°ë³¸ 4%)
        sl_percent: ì†ì ˆê°€ ë¹„ìœ¨ (ê¸°ë³¸ 0.7%)
        position_size_pct: í¬ì§€ì…˜ í¬ê¸° (ìë³¸ ëŒ€ë¹„ %, ê¸°ë³¸ 2%)
    
    Returns:
        dict: ë°±í…ŒìŠ¤íŒ… ê²°ê³¼
    """
    
    if df.empty or len(df) < 50:
        return {'status': 'error', 'message': 'ë°ì´í„° ë¶€ì¡±'}
    
    capital = initial_capital
    trades = []
    
    # ì‹ í˜¸ ìƒì„± (ê°„ë‹¨í•œ MACD ê¸°ë°˜)
    df_copy = df.copy()
    
    if 'MACD' not in df_copy.columns:
        ema12 = df_copy['Close'].ewm(span=12, adjust=False).mean()
        ema26 = df_copy['Close'].ewm(span=26, adjust=False).mean()
        df_copy['MACD'] = ema12 - ema26
        df_copy['Signal_Line'] = df_copy['MACD'].ewm(span=9, adjust=False).mean()
    
    position = None
    
    for i in range(50, len(df_copy)):
        current_price = df_copy['Close'].iloc[i]
        
        # í¬ì§€ì…˜ì´ ì—†ì„ ë•Œ ì§„ì… ì‹ í˜¸ í™•ì¸
        if position is None:
            macd = df_copy['MACD'].iloc[i]
            signal = df_copy['Signal_Line'].iloc[i]
            prev_macd = df_copy['MACD'].iloc[i-1]
            prev_signal = df_copy['Signal_Line'].iloc[i-1]
            
            # ê³¨ë“ í¬ë¡œìŠ¤: LONG ì§„ì…
            if prev_macd <= prev_signal and macd > signal:
                position_value = capital * position_size_pct
                shares = position_value / current_price
                
                # DeepSeek ìŠ¤íƒ€ì¼ TP/SL
                tp_price = current_price * (1 + tp_percent / 100)
                sl_price = current_price * (1 - sl_percent / 100)
                
                position = {
                    'entry_price': current_price,
                    'shares': shares,
                    'tp_price': tp_price,
                    'sl_price': sl_price,
                    'entry_index': i,
                    'type': 'LONG'
                }
        
        # í¬ì§€ì…˜ì´ ìˆì„ ë•Œ ì²­ì‚° ì¡°ê±´ í™•ì¸
        elif position is not None:
            # TP ë„ë‹¬
            if current_price >= position['tp_price']:
                profit = (position['tp_price'] - position['entry_price']) * position['shares']
                capital += profit
                
                trades.append({
                    'entry_price': position['entry_price'],
                    'exit_price': position['tp_price'],
                    'profit': profit,
                    'profit_pct': tp_percent,
                    'result': 'WIN',
                    'hold_periods': i - position['entry_index']
                })
                
                position = None
            
            # SL ë„ë‹¬
            elif current_price <= position['sl_price']:
                loss = (position['entry_price'] - position['sl_price']) * position['shares']
                capital -= loss
                
                trades.append({
                    'entry_price': position['entry_price'],
                    'exit_price': position['sl_price'],
                    'profit': -loss,
                    'profit_pct': -sl_percent,
                    'result': 'LOSS',
                    'hold_periods': i - position['entry_index']
                })
                
                position = None
    
    # ê²°ê³¼ í†µê³„
    if not trades:
        return {
            'status': 'no_trades',
            'message': 'ê±°ë˜ ì‹ í˜¸ ì—†ìŒ'
        }
    
    total_trades = len(trades)
    wins = len([t for t in trades if t['result'] == 'WIN'])
    losses = len([t for t in trades if t['result'] == 'LOSS'])
    win_rate = (wins / total_trades) * 100 if total_trades > 0 else 0
    
    total_profit = sum([t['profit'] for t in trades])
    total_return = ((capital - initial_capital) / initial_capital) * 100
    
    avg_win = np.mean([t['profit'] for t in trades if t['result'] == 'WIN']) if wins > 0 else 0
    avg_loss = abs(np.mean([t['profit'] for t in trades if t['result'] == 'LOSS'])) if losses > 0 else 0
    
    return {
        'status': 'success',
        'initial_capital': initial_capital,
        'final_capital': capital,
        'total_return_pct': total_return,
        'total_trades': total_trades,
        'wins': wins,
        'losses': losses,
        'win_rate': win_rate,
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'profit_factor': (avg_win * wins) / (avg_loss * losses) if losses > 0 else 0,
        'trades': trades,
        'tp_percent': tp_percent,
        'sl_percent': sl_percent
    }


# ==============================================================================
# 5. UI ë Œë”ë§ í•¨ìˆ˜ë“¤
# ==============================================================================

def render_4h_ema_chart(df_4h: pd.DataFrame):
    """4ì‹œê°„ë´‰ EMA ì°¨íŠ¸"""
    if df_4h.empty or len(df_4h) < 50:
        st.warning("âš ï¸ 4ì‹œê°„ë´‰ ë°ì´í„° ë¶€ì¡±")
        return
    
    fig = go.Figure()
    
    # ìº”ë“¤ìŠ¤í‹±
    fig.add_trace(go.Candlestick(
        x=df_4h.index,
        open=df_4h['Open'],
        high=df_4h['High'],
        low=df_4h['Low'],
        close=df_4h['Close'],
        name='4H Candles'
    ))
    
    # EMA20
    ema20 = df_4h['Close'].ewm(span=20, adjust=False).mean()
    fig.add_trace(go.Scatter(
        x=df_4h.index,
        y=ema20,
        name='EMA20 (4H)',
        line=dict(color='orange', width=2)
    ))
    
    # EMA50
    ema50 = df_4h['Close'].ewm(span=50, adjust=False).mean()
    fig.add_trace(go.Scatter(
        x=df_4h.index,
        y=ema50,
        name='EMA50 (4H)',
        line=dict(color='purple', width=2)
    ))
    
    fig.update_layout(
        title="ğŸ“Š 4ì‹œê°„ë´‰ ì°¨íŠ¸ (ì¥ê¸° ì¶”ì„¸)",
        xaxis_title="ì‹œê°„",
        yaxis_title="ê°€ê²© (USD)",
        height=500,
        template='plotly_dark'
    )
    
    st.plotly_chart(fig, use_container_width=True)


def render_open_interest_chart(df_oi: pd.DataFrame):
    """Open Interest ì°¨íŠ¸"""
    if df_oi.empty:
        st.warning("âš ï¸ Open Interest ë°ì´í„° ì—†ìŒ")
        return
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df_oi.index,
        y=df_oi['open_interest'],
        mode='lines+markers',
        name='Open Interest',
        line=dict(color='cyan', width=2),
        fill='tozeroy',
        fillcolor='rgba(0, 255, 255, 0.1)'
    ))
    
    # ê¸‰ì¦/ê¸‰ê° ê°ì§€
    oi_change = df_oi['open_interest'].pct_change()
    
    # ê¸‰ì¦ (5% ì´ìƒ ì¦ê°€)
    surge_points = df_oi[oi_change > 0.05]
    if not surge_points.empty:
        fig.add_trace(go.Scatter(
            x=surge_points.index,
            y=surge_points['open_interest'],
            mode='markers',
            name='ê¸‰ì¦ (>5%)',
            marker=dict(color='lime', size=10, symbol='triangle-up')
        ))
    
    # ê¸‰ê° (5% ì´ìƒ ê°ì†Œ)
    drop_points = df_oi[oi_change < -0.05]
    if not drop_points.empty:
        fig.add_trace(go.Scatter(
            x=drop_points.index,
            y=drop_points['open_interest'],
            mode='markers',
            name='ê¸‰ê° (<-5%)',
            marker=dict(color='red', size=10, symbol='triangle-down')
        ))
    
    fig.update_layout(
        title="â›“ï¸ ë¯¸ê²°ì œì•½ì • (Open Interest) ì¶”ì´",
        xaxis_title="ì‹œê°„",
        yaxis_title="Open Interest",
        height=400,
        template='plotly_dark'
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # ì•Œë¦¼
    recent_change = oi_change.iloc[-1] * 100 if len(oi_change) > 0 else 0
    if recent_change > 5:
        st.warning(f"âš ï¸ **ìµœê·¼ ë¯¸ê²°ì œì•½ì • ê¸‰ì¦**: +{recent_change:.2f}% (ì²­ì‚° ë¦¬ìŠ¤í¬ ì¦ê°€)")
    elif recent_change < -5:
        st.info(f"â„¹ï¸ **ìµœê·¼ ë¯¸ê²°ì œì•½ì • ê¸‰ê°**: {recent_change:.2f}% (í¬ì§€ì…˜ ì²­ì‚° ì§„í–‰ ì¤‘)")


def render_chain_of_thought(cot_result: Dict):
    """Chain-of-Thought ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.markdown("### ğŸ§  ìƒì„¸ ë¶„ì„ ê³¼ì • (Chain-of-Thought)")
    
    with st.expander("ğŸ“ ë‹¨ê³„ë³„ ì‚¬ê³  ê³¼ì • ë³´ê¸°", expanded=True):
        for step in cot_result['reasoning_steps']:
            st.markdown(step)
    
    # ìš”ì•½
    st.success(f"**âœ¨ ìµœì¢… ê²°ë¡ **: {cot_result['summary']}")
    
    # ì‹ í˜¸ ê°•ë„
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="ğŸŸ¢ Bullish Signals",
            value=cot_result['bullish_signals']
        )
    
    with col2:
        st.metric(
            label="ğŸ”´ Bearish Signals",
            value=cot_result['bearish_signals']
        )
    
    with col3:
        st.metric(
            label="ğŸ“Š ì‹ ë¢°ë„",
            value=f"{cot_result['confidence']:.0f}%"
        )


def render_deepseek_backtest_results(result: Dict, comparison_result: Dict = None):
    """DeepSeek ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ í‘œì‹œ"""
    st.markdown("### ğŸ“Š DeepSeek ìŠ¤íƒ€ì¼ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼")
    
    if result['status'] != 'success':
        st.error(f"âŒ {result.get('message', 'ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨')}")
        return
    
    # ë©”ì¸ ì§€í‘œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ì´ ìˆ˜ìµë¥ ",
            value=f"{result['total_return_pct']:.2f}%",
            delta=f"${result['final_capital'] - result['initial_capital']:,.0f}"
        )
    
    with col2:
        st.metric(
            label="ìŠ¹ë¥ ",
            value=f"{result['win_rate']:.1f}%",
            help="ì „ì²´ ê±°ë˜ ì¤‘ ìˆ˜ìµ ê±°ë˜ ë¹„ìœ¨"
        )
    
    with col3:
        st.metric(
            label="ì´ ê±°ë˜",
            value=result['total_trades'],
            delta=f"ìŠ¹: {result['wins']} / íŒ¨: {result['losses']}"
        )
    
    with col4:
        st.metric(
            label="Profit Factor",
            value=f"{result['profit_factor']:.2f}",
            help="ì´ ì´ìµ / ì´ ì†ì‹¤"
        )
    
    # ìƒì„¸ í†µê³„
    with st.expander("ğŸ“ˆ ìƒì„¸ í†µê³„", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            **ìˆ˜ìµ ê±°ë˜**
            - íšŸìˆ˜: {result['wins']}íšŒ
            - í‰ê·  ìˆ˜ìµ: ${result['avg_win']:,.2f}
            - TP ì„¤ì •: +{result['tp_percent']}%
            """)
        
        with col2:
            st.markdown(f"""
            **ì†ì‹¤ ê±°ë˜**
            - íšŸìˆ˜: {result['losses']}íšŒ
            - í‰ê·  ì†ì‹¤: ${result['avg_loss']:,.2f}
            - SL ì„¤ì •: -{result['sl_percent']}%
            """)
    
    # ë¹„êµ (ì¼ë°˜ ì „ëµ vs DeepSeek ì „ëµ)
    if comparison_result and comparison_result['status'] == 'success':
        st.markdown("---")
        st.markdown("### ğŸ”„ ì „ëµ ë¹„êµ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ì¼ë°˜ ì „ëµ (TP 2% / SL 1%)**")
            st.metric("ìˆ˜ìµë¥ ", f"{comparison_result['total_return_pct']:.2f}%")
            st.metric("ìŠ¹ë¥ ", f"{comparison_result['win_rate']:.1f}%")
            st.metric("Profit Factor", f"{comparison_result['profit_factor']:.2f}")
        
        with col2:
            st.markdown("**DeepSeek ì „ëµ (TP 4% / SL 0.7%)**")
            st.metric("ìˆ˜ìµë¥ ", f"{result['total_return_pct']:.2f}%")
            st.metric("ìŠ¹ë¥ ", f"{result['win_rate']:.1f}%")
            st.metric("Profit Factor", f"{result['profit_factor']:.2f}")
        
        # ê²°ë¡ 
        if result['total_return_pct'] > comparison_result['total_return_pct']:
            st.success("âœ… DeepSeek ì „ëµì´ ë” ë†’ì€ ìˆ˜ìµë¥ ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤!")
        else:
            st.info("â„¹ï¸ ì¼ë°˜ ì „ëµì´ ë” ì•ˆì •ì ì¸ ìˆ˜ìµë¥ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.")
"""
ê³ ê¸‰ ë‹¤ì°¨ì› ë¶„ì„ í”„ë ˆì„ì›Œí¬
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

êµ¬ì¡°: íŒ¨í„´(ë¡œì»¬) + ë ˆì§(ê¸€ë¡œë²Œ) + ì»¨í…ìŠ¤íŠ¸(ì˜¨ì²´ì¸/íŒŒìƒ/ì‹œê°„)

í•µì‹¬ ì›ì¹™:
1. ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ë¯¸ë˜ ë°ì´í„°ë¥¼ í˜„ì¬ ê²°ì •ì— ì‚¬ìš© ê¸ˆì§€
2. ë°ì´í„° ìŠ¤ëˆ„í•‘ ë°©ì§€: Walk-forward ê²€ì¦, Out-of-sample í…ŒìŠ¤íŠ¸
3. ì´ë²¤íŠ¸ì„± íŒ¨í„´ì€ ë°©í–¥ì„± í•„í„°ì™€ ê²°í•©
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from datetime import datetime, timedelta


# ==============================================================================
# 1. ë¡œì»¬ íŒ¨í„´ ê°ì§€ (ì´ë²¤íŠ¸ì„± íŒ¨í„´ - í™•ë¥  ì¤‘ë¦½)
# ==============================================================================

def detect_squeeze_pattern(df: pd.DataFrame, lookback: int = 20) -> Dict:
    """
    Bollinger Band Squeeze ê°ì§€
    
    ì£¼ì˜: ì´ íŒ¨í„´ì€ ë°©í–¥ ì¤‘ë¦½ì ! ë°˜ë“œì‹œ ë°©í–¥ì„± í•„í„°ì™€ ê²°í•© í•„ìš”
    """
    if len(df) < lookback + 5:
        return {'detected': False, 'strength': 0, 'direction': None}
    
    # BB ê³„ì‚° (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ - ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©)
    close = df['Close'].iloc[:-1]  # í˜„ì¬ ìº”ë“¤ ì œì™¸
    sma = close.rolling(window=20).mean()
    std = close.rolling(window=20).std()
    bb_upper = sma + (2 * std)
    bb_lower = sma - (2 * std)
    bb_width = ((bb_upper - bb_lower) / sma * 100).iloc[-1]
    
    # Squeeze ì¡°ê±´: BB í­ì´ ìµœê·¼ lookback ê¸°ê°„ ì¤‘ ìµœì†Œ
    recent_widths = ((bb_upper - bb_lower) / sma * 100).iloc[-lookback:]
    is_squeeze = bb_width <= recent_widths.quantile(0.2)
    
    # ê°•ë„ ì¸¡ì •
    strength = 0
    if is_squeeze:
        strength = (1 - (bb_width / recent_widths.max())) * 100
    
    return {
        'detected': bool(is_squeeze),
        'strength': float(strength),
        'bb_width': float(bb_width),
        'direction': None  # ë°©í–¥ ì¤‘ë¦½!
    }


def detect_nr7_pattern(df: pd.DataFrame) -> Dict:
    """
    NR7 (Narrowest Range 7) íŒ¨í„´ ê°ì§€
    
    ì£¼ì˜: ë¸Œë ˆì´í¬ì•„ì›ƒ ëŒ€ê¸° íŒ¨í„´ - ë°©í–¥ ë¯¸ì •
    """
    if len(df) < 8:
        return {'detected': False, 'strength': 0}
    
    # ìµœê·¼ 7ê°œ ìº”ë“¤ì˜ Range ê³„ì‚° (í˜„ì¬ ì œì™¸)
    ranges = (df['High'] - df['Low']).iloc[-8:-1]
    current_range = ranges.iloc[-1]
    
    # NR7 ì¡°ê±´
    is_nr7 = current_range == ranges.min()
    
    # ê°•ë„: í˜„ì¬ rangeê°€ í‰ê·  ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ì‘ì€ì§€
    strength = 0
    if is_nr7:
        strength = (1 - (current_range / ranges.mean())) * 100
    
    return {
        'detected': bool(is_nr7),
        'strength': float(strength),
        'range': float(current_range),
        'avg_range': float(ranges.mean())
    }


def detect_inside_bar(df: pd.DataFrame) -> Dict:
    """
    Inside Bar íŒ¨í„´ ê°ì§€
    
    ì •ì˜: í˜„ì¬ ìº”ë“¤ì´ ì´ì „ ìº”ë“¤ ë²”ìœ„ ë‚´ë¶€ì— ì™„ì „íˆ í¬í•¨
    """
    if len(df) < 3:
        return {'detected': False}
    
    current = df.iloc[-1]
    previous = df.iloc[-2]
    
    is_inside = (
        current['High'] <= previous['High'] and
        current['Low'] >= previous['Low']
    )
    
    # íƒ€ì´íŠ¸í•¨ ì¸¡ì •
    tightness = 0
    if is_inside:
        current_range = current['High'] - current['Low']
        previous_range = previous['High'] - previous['Low']
        tightness = (1 - (current_range / previous_range)) * 100
    
    return {
        'detected': bool(is_inside),
        'tightness': float(tightness)
    }


def detect_triangle_convergence(df: pd.DataFrame, lookback: int = 20) -> Dict:
    """
    ì‚¼ê° ìˆ˜ë ´ íŒ¨í„´ ê°ì§€
    
    ë°©ë²•: ê³ ì ì€ ë‚®ì•„ì§€ê³  ì €ì ì€ ë†’ì•„ì§€ëŠ” íŒ¨í„´
    """
    if len(df) < lookback:
        return {'detected': False, 'strength': 0}
    
    recent = df.iloc[-lookback:]
    
    # ê³ ì  ì¶”ì„¸ (í•˜ë½í•´ì•¼ í•¨)
    highs = recent['High'].values
    high_trend = np.polyfit(range(len(highs)), highs, 1)[0]
    
    # ì €ì  ì¶”ì„¸ (ìƒìŠ¹í•´ì•¼ í•¨)
    lows = recent['Low'].values
    low_trend = np.polyfit(range(len(lows)), lows, 1)[0]
    
    # ìˆ˜ë ´ ì¡°ê±´
    is_converging = high_trend < 0 and low_trend > 0
    
    # ìˆ˜ë ´ ê°•ë„
    strength = 0
    if is_converging:
        range_compression = (highs[-1] - lows[-1]) / (highs[0] - lows[0])
        strength = (1 - range_compression) * 100
    
    return {
        'detected': bool(is_converging),
        'strength': float(strength),
        'high_trend': float(high_trend),
        'low_trend': float(low_trend)
    }


# ==============================================================================
# 2. ê¸€ë¡œë²Œ ë ˆì§ ë¶„ë¥˜
# ==============================================================================

def classify_market_regime(df: pd.DataFrame, lookback: int = 100) -> Dict:
    """
    ì‹œì¥ ë ˆì§ ë¶„ë¥˜: ì¶”ì„¸/ë ˆì¸ì§€/ë³€ë™ì„±
    
    ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ê³¼ê±° lookback ë°ì´í„°ë§Œ ì‚¬ìš©
    """
    if len(df) < lookback + 5:
        return {'regime': 'UNKNOWN', 'confidence': 0}
    
    # ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš© (í˜„ì¬ ìº”ë“¤ ì œì™¸)
    recent = df.iloc[-(lookback+1):-1]
    returns = recent['Close'].pct_change().dropna()
    
    # 1. ì¶”ì„¸ ê°•ë„ (ADX ë°©ì‹)
    high_low = recent['High'] - recent['Low']
    high_close = abs(recent['High'] - recent['Close'].shift(1))
    low_close = abs(recent['Low'] - recent['Close'].shift(1))
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    atr = tr.rolling(14).mean().iloc[-1]
    
    # 2. ì¶”ì„¸ ë°©í–¥
    ema_fast = recent['Close'].ewm(span=20).mean().iloc[-1]
    ema_slow = recent['Close'].ewm(span=50).mean().iloc[-1]
    trend_direction = 1 if ema_fast > ema_slow else -1
    
    # 3. ë³€ë™ì„± ë ˆì§
    volatility = returns.std() * np.sqrt(252)  # ì—°ìœ¨í™”
    
    # 4. ë ˆì¸ì§€ vs ì¶”ì„¸ íŒë‹¨
    close_prices = recent['Close'].values
    price_range = close_prices.max() - close_prices.min()
    trend_strength = abs(close_prices[-1] - close_prices[0]) / price_range
    
    # ë ˆì§ ë¶„ë¥˜
    if trend_strength > 0.6:
        regime = 'TRENDING'
        confidence = trend_strength * 100
    elif volatility > 0.5:
        regime = 'HIGH_VOLATILITY'
        confidence = volatility * 100
    else:
        regime = 'RANGING'
        confidence = (1 - trend_strength) * 100
    
    return {
        'regime': regime,
        'confidence': float(confidence),
        'trend_direction': int(trend_direction),
        'volatility': float(volatility),
        'atr': float(atr)
    }


def calculate_time_regime(df: pd.DataFrame) -> Dict:
    """
    ì‹œê°„ì„± ë ˆì§: ê±°ë˜ ì‹œê°„ëŒ€ë³„ íŠ¹ì„±
    
    - ì•„ì‹œì•„ ì‹œê°„: ë‚®ì€ ë³€ë™ì„±
    - ìœ ëŸ½ ì‹œê°„: ì¤‘ê°„ ë³€ë™ì„±
    - ë¯¸êµ­ ì‹œê°„: ë†’ì€ ë³€ë™ì„±
    - ì˜¤ë²„ë©: ë§¤ìš° ë†’ì€ ë³€ë™ì„±
    """
    if df.empty:
        return {'session': 'UNKNOWN', 'volatility_multiplier': 1.0}
    
    # í˜„ì¬ ì‹œê°„ (UTC ê¸°ì¤€)
    current_time = datetime.utcnow()
    hour = current_time.hour
    
    # ì„¸ì…˜ ë¶„ë¥˜
    if 0 <= hour < 8:
        session = 'ASIA'
        vol_mult = 0.7
    elif 8 <= hour < 13:
        session = 'EUROPE'
        vol_mult = 1.0
    elif 13 <= hour < 17:
        session = 'OVERLAP'  # ìœ ëŸ½+ë¯¸êµ­
        vol_mult = 1.5
    elif 17 <= hour < 22:
        session = 'US'
        vol_mult = 1.2
    else:
        session = 'LATE_US'
        vol_mult = 0.8
    
    return {
        'session': session,
        'volatility_multiplier': vol_mult,
        'hour_utc': hour
    }


# ==============================================================================
# 3. ì»¨í…ìŠ¤íŠ¸: ì˜¨ì²´ì¸ / íŒŒìƒìƒí’ˆ / ì£¼ë¬¸íë¦„
# ==============================================================================

def analyze_onchain_context(symbol: str) -> Dict:
    """
    ì˜¨ì²´ì¸ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
    
    ì‹¤ì œ êµ¬í˜„ ì‹œ Glassnode, CryptoQuant ë“± API ì‚¬ìš©
    ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    """
    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ
    # exchange_balance = get_exchange_balance(symbol)
    # whale_transactions = get_whale_transactions(symbol)
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    return {
        'exchange_netflow': 0,  # ì–‘ìˆ˜: ê±°ë˜ì†Œ ìœ ì… (ë§¤ë„ ì••ë ¥)
        'whale_activity': 'NEUTRAL',  # LOW / NEUTRAL / HIGH
        'active_addresses': 0,
        'confidence': 0  # ë°ì´í„° í’ˆì§ˆ
    }


def analyze_derivatives_context(df: pd.DataFrame) -> Dict:
    """
    íŒŒìƒìƒí’ˆ ì»¨í…ìŠ¤íŠ¸: í€ë”©ë¹„, Open Interest
    
    ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©
    """
    if len(df) < 20:
        return {
            'funding_rate': 0,
            'oi_change': 0,
            'long_short_ratio': 50,
            'signal': 'NEUTRAL'
        }
    
    # ì‹¤ì œë¡œëŠ” ê±°ë˜ì†Œ APIì—ì„œ ê°€ì ¸ì˜´
    # ì—¬ê¸°ì„œëŠ” ë³¼ë¥¨ìœ¼ë¡œ ì¶”ì •
    recent_volume = df['Volume'].iloc[-5:].mean()
    avg_volume = df['Volume'].iloc[-20:].mean()
    
    # OI ë³€í™” ì¶”ì • (ë³¼ë¥¨ ë³€í™”ë¡œ)
    oi_change = ((recent_volume / avg_volume) - 1) * 100
    
    # í€ë”©ë¹„ ì¶”ì • (ê°€ê²© ëª¨ë©˜í…€ìœ¼ë¡œ)
    price_change = df['Close'].pct_change(5).iloc[-1] * 100
    funding_rate = price_change * 0.01  # ê°„ë‹¨í•œ ì¶”ì •
    
    # ë¡±/ìˆ ë¹„ìœ¨ ì¶”ì •
    if price_change > 0:
        long_short_ratio = 55 + min(price_change, 10)
    else:
        long_short_ratio = 45 + max(price_change, -10)
    
    # ì‹œê·¸ë„ ìƒì„±
    if funding_rate > 0.1 and oi_change > 10:
        signal = 'OVERLEVERAGED_LONG'
    elif funding_rate < -0.1 and oi_change > 10:
        signal = 'OVERLEVERAGED_SHORT'
    else:
        signal = 'NEUTRAL'
    
    return {
        'funding_rate': float(funding_rate),
        'oi_change': float(oi_change),
        'long_short_ratio': float(long_short_ratio),
        'signal': signal
    }


def analyze_order_flow(df: pd.DataFrame, lookback: int = 20) -> Dict:
    """
    ì£¼ë¬¸íë¦„ ë¶„ì„: ì²´ê²° ê°•ë„, ë§¤ìˆ˜/ë§¤ë„ ì••ë ¥
    
    ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©
    """
    if len(df) < lookback + 1:
        return {
            'buy_pressure': 50,
            'sell_pressure': 50,
            'imbalance': 0,
            'strength': 'NEUTRAL'
        }
    
    recent = df.iloc[-(lookback+1):-1]
    
    # ìƒìŠ¹ ìº”ë“¤ vs í•˜ë½ ìº”ë“¤ ë¹„ìœ¨
    up_candles = (recent['Close'] > recent['Open']).sum()
    down_candles = (recent['Close'] < recent['Open']).sum()
    
    buy_pressure = (up_candles / lookback) * 100
    sell_pressure = (down_candles / lookback) * 100
    
    # ê±°ë˜ëŸ‰ ê°€ì¤‘ ì„ë°¸ëŸ°ìŠ¤
    recent['volume_imbalance'] = (
        recent['Volume'] * 
        np.where(recent['Close'] > recent['Open'], 1, -1)
    )
    imbalance = recent['volume_imbalance'].sum() / recent['Volume'].sum() * 100
    
    # ê°•ë„ ë¶„ë¥˜
    if abs(imbalance) > 20:
        strength = 'STRONG'
    elif abs(imbalance) > 10:
        strength = 'MODERATE'
    else:
        strength = 'WEAK'
    
    return {
        'buy_pressure': float(buy_pressure),
        'sell_pressure': float(sell_pressure),
        'imbalance': float(imbalance),
        'strength': strength
    }


# ==============================================================================
# 4. ë°©í–¥ì„± í•„í„° (ì´ë²¤íŠ¸ íŒ¨í„´ê³¼ ê²°í•©ìš©)
# ==============================================================================

def calculate_directional_filters(df: pd.DataFrame) -> Dict:
    """
    ë°©í–¥ì„± í•„í„°: ì¶”ì„¸, ëª¨ë©˜í…€, ì²´ê²° ê°•ë„
    
    ì´ë²¤íŠ¸ì„± íŒ¨í„´(Squeeze, NR7 ë“±)ê³¼ ê²°í•©í•˜ì—¬ ë°©í–¥ ê²°ì •
    """
    if len(df) < 50:
        return {
            'trend': 0,
            'momentum': 0,
            'strength': 0,
            'direction': 'NEUTRAL'
        }
    
    recent = df.iloc[-50:]
    
    # 1. ì¶”ì„¸ í•„í„° (EMA ì •ë ¬)
    ema20 = recent['Close'].ewm(span=20).mean().iloc[-1]
    ema50 = recent['Close'].ewm(span=50).mean().iloc[-1]
    current_price = recent['Close'].iloc[-1]
    
    if current_price > ema20 > ema50:
        trend_score = 100
        trend_dir = 'UP'
    elif current_price < ema20 < ema50:
        trend_score = 0
        trend_dir = 'DOWN'
    else:
        trend_score = 50
        trend_dir = 'NEUTRAL'
    
    # 2. ëª¨ë©˜í…€ í•„í„° (RSI)
    delta = recent['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    momentum_score = rsi.iloc[-1]
    
    # 3. ì²´ê²° ê°•ë„ (ê±°ë˜ëŸ‰ ì¶”ì„¸)
    volume_sma = recent['Volume'].rolling(20).mean()
    current_vol = recent['Volume'].iloc[-5:].mean()
    volume_strength = (current_vol / volume_sma.iloc[-1]) * 100
    
    # ì¢…í•© ë°©í–¥ ê²°ì •
    if trend_score > 60 and momentum_score > 50:
        direction = 'BULLISH'
        confidence = (trend_score + momentum_score) / 2
    elif trend_score < 40 and momentum_score < 50:
        direction = 'BEARISH'
        confidence = (100 - trend_score + (100 - momentum_score)) / 2
    else:
        direction = 'NEUTRAL'
        confidence = 50
    
    return {
        'trend': float(trend_score),
        'momentum': float(momentum_score),
        'volume_strength': float(volume_strength),
        'direction': direction,
        'confidence': float(confidence)
    }


# ==============================================================================
# 5. í†µí•© ì‹œê·¸ë„ ìƒì„± (ëˆ„ìˆ˜ ë°©ì§€ ê²€ì¦ í¬í•¨)
# ==============================================================================

def generate_integrated_signal(df: pd.DataFrame, symbol: str = 'BTCUSDT') -> Dict:
    """
    ë‹¤ì°¨ì› í†µí•© ì‹œê·¸ë„ ìƒì„±
    
    êµ¬ì¡°: íŒ¨í„´(ë¡œì»¬) + ë ˆì§(ê¸€ë¡œë²Œ) + ì»¨í…ìŠ¤íŠ¸
    
    ê²€ì¦:
    - Walk-forward: ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©
    - No future data leakage
    """
    
    # ë°ì´í„° ì¶©ë¶„ì„± ê²€ì¦
    if len(df) < 100:
        return {
            'signal': 'INSUFFICIENT_DATA',
            'confidence': 0,
            'details': 'Need at least 100 candles'
        }
    
    # === 1ë‹¨ê³„: ë¡œì»¬ íŒ¨í„´ ê°ì§€ ===
    patterns = {
        'squeeze': detect_squeeze_pattern(df),
        'nr7': detect_nr7_pattern(df),
        'inside_bar': detect_inside_bar(df),
        'triangle': detect_triangle_convergence(df)
    }
    
    # ì´ë²¤íŠ¸ì„± íŒ¨í„´ ê°ì§€ ì—¬ë¶€
    event_detected = any([p['detected'] for p in patterns.values() if 'detected' in p])
    
    # === 2ë‹¨ê³„: ê¸€ë¡œë²Œ ë ˆì§ ë¶„ë¥˜ ===
    market_regime = classify_market_regime(df)
    time_regime = calculate_time_regime(df)
    
    # === 3ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ===
    # onchain = analyze_onchain_context(symbol)  # ì‹¤ì œ í™˜ê²½ì—ì„œë§Œ
    derivatives = analyze_derivatives_context(df)
    order_flow = analyze_order_flow(df)
    
    # === 4ë‹¨ê³„: ë°©í–¥ì„± í•„í„° ===
    directional = calculate_directional_filters(df)
    
    # === 5ë‹¨ê³„: í†µí•© ì‹œê·¸ë„ ìƒì„± ===
    
    # ê·œì¹™ 1: ì´ë²¤íŠ¸ íŒ¨í„´ì´ ê°ì§€ë˜ë©´ ë°©í–¥ì„± í•„í„°ì™€ ê²°í•©
    if event_detected:
        # ê°€ì¥ ê°•í•œ íŒ¨í„´ ì„ íƒ
        strongest_pattern = max(
            [p for p in patterns.values() if p.get('detected')],
            key=lambda x: x.get('strength', 0)
        )
        
        # ë°©í–¥ì„±ê³¼ ê²°í•©
        if directional['direction'] == 'BULLISH' and directional['confidence'] > 60:
            signal = 'BUY'
            confidence = (strongest_pattern.get('strength', 0) + directional['confidence']) / 2
        elif directional['direction'] == 'BEARISH' and directional['confidence'] > 60:
            signal = 'SELL'
            confidence = (strongest_pattern.get('strength', 0) + directional['confidence']) / 2
        else:
            signal = 'WAIT'  # íŒ¨í„´ì€ ìˆì§€ë§Œ ë°©í–¥ ë¶ˆëª…í™•
            confidence = 30
    
    # ê·œì¹™ 2: ë ˆì§ ê¸°ë°˜ ì¡°ì •
    else:
        if market_regime['regime'] == 'TRENDING':
            if directional['direction'] == 'BULLISH':
                signal = 'BUY'
                confidence = directional['confidence']
            elif directional['direction'] == 'BEARISH':
                signal = 'SELL'
                confidence = directional['confidence']
            else:
                signal = 'NEUTRAL'
                confidence = 40
        else:
            signal = 'NEUTRAL'
            confidence = 30
    
    # ê·œì¹™ 3: íŒŒìƒìƒí’ˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ë¦¬ìŠ¤í¬ ì¡°ì •
    if derivatives['signal'] == 'OVERLEVERAGED_LONG' and signal == 'BUY':
        confidence *= 0.7  # ë¡± ê³¼ì—´ ì‹œ ë§¤ìˆ˜ ì‹ ë¢°ë„ í•˜ë½
    elif derivatives['signal'] == 'OVERLEVERAGED_SHORT' and signal == 'SELL':
        confidence *= 0.7  # ìˆ ê³¼ì—´ ì‹œ ë§¤ë„ ì‹ ë¢°ë„ í•˜ë½
    
    # ê·œì¹™ 4: ì‹œê°„ì„± ì¡°ì •
    confidence *= time_regime['volatility_multiplier']
    confidence = min(100, confidence)  # ìƒí•œ 100
    
    return {
        'signal': signal,
        'confidence': float(confidence),
        'patterns': patterns,
        'market_regime': market_regime,
        'time_regime': time_regime,
        'derivatives': derivatives,
        'order_flow': order_flow,
        'directional': directional,
        'timestamp': datetime.now().isoformat()
    }


# ==============================================================================
# 6. ê²€ì¦ í”„ë ˆì„ì›Œí¬ (ë°ì´í„° ìŠ¤ëˆ„í•‘ ë°©ì§€)
# ==============================================================================

def walk_forward_validation(df: pd.DataFrame, 
                            train_size: int = 1000,
                            test_size: int = 100,
                            step: int = 50) -> Dict:
    """
    Walk-Forward ê²€ì¦
    
    ë°©ë²•:
    1. í›ˆë ¨ ê¸°ê°„ìœ¼ë¡œ íŒŒë¼ë¯¸í„° ìµœì í™”
    2. í…ŒìŠ¤íŠ¸ ê¸°ê°„ìœ¼ë¡œ Out-of-Sample ê²€ì¦
    3. ì•ìœ¼ë¡œ ì´ë™í•˜ë©° ë°˜ë³µ
    
    ë°ì´í„° ìŠ¤ëˆ„í•‘ ë°©ì§€: ë¯¸ë˜ ë°ì´í„° ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
    """
    
    results = []
    
    for i in range(0, len(df) - train_size - test_size, step):
        # í›ˆë ¨ ë°ì´í„° (ê³¼ê±°)
        train_df = df.iloc[i:i+train_size]
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë¯¸ë˜ - í•˜ì§€ë§Œ ì‹œë®¬ë ˆì´ì…˜ ì‹œì ì—ì„œëŠ” "ì•Œ ìˆ˜ ì—†ëŠ”" ë°ì´í„°)
        test_df = df.iloc[i+train_size:i+train_size+test_size]
        
        # í›ˆë ¨ ë°ì´í„°ë¡œ ì‹œê·¸ë„ ìƒì„± (íŒŒë¼ë¯¸í„° ìµœì í™”ëŠ” ì—¬ê¸°ì„œ)
        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ì „ëµ íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•¨
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ê²€ì¦
        for j in range(len(test_df)):
            # ê° í…ŒìŠ¤íŠ¸ ì‹œì ì—ì„œ ê³¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©
            historical = pd.concat([train_df, test_df.iloc[:j+1]])
            signal = generate_integrated_signal(historical)
            
            # ë‹¤ìŒ ìº”ë“¤ì˜ ì‹¤ì œ ìˆ˜ìµë¥  (ì´ê²ƒì´ "ë¯¸ë˜" ë°ì´í„°)
            if j < len(test_df) - 1:
                next_return = (test_df['Close'].iloc[j+1] / test_df['Close'].iloc[j] - 1)
                
                results.append({
                    'signal': signal['signal'],
                    'confidence': signal['confidence'],
                    'actual_return': next_return,
                    'correct': (
                        (signal['signal'] == 'BUY' and next_return > 0) or
                        (signal['signal'] == 'SELL' and next_return < 0)
                    )
                })
    
    # ê²°ê³¼ ì§‘ê³„
    if not results:
        return {'status': 'INSUFFICIENT_DATA'}
    
    total = len(results)
    correct = sum([1 for r in results if r['correct']])
    accuracy = (correct / total) * 100
    
    return {
        'status': 'COMPLETED',
        'total_signals': total,
        'correct_signals': correct,
        'accuracy': accuracy,
        'results': results[-10:]  # ìµœê·¼ 10ê°œë§Œ ë°˜í™˜
    }

